{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prediction method for ABSA (ATE+APC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nexus_ai.ABSA.arabic.bert import bert_ATE, bert_APC\n",
    "from nexus_ai.ABSA.arabic.dataset import pred_dataset_ATE\n",
    "from nexus_ai.sentence_sentiment_analysis.preprocessing import pad_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "from camel_tools.utils.normalize import normalize_unicode, normalize_alef_maksura_ar, normalize_alef_ar, normalize_teh_marbuta_ar\n",
    "from camel_tools.utils.dediac import dediac_ar\n",
    "from camel_tools.tokenizers.word import simple_word_tokenize\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bert_ATE(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30000, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=768, out_features=3, bias=True)\n",
       "  (loss_fn): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "pretrain_model_name = \"../../sentence_sentiment_analysis/arabic/models/bert_pretrained_01_acc_90.50\"\n",
    "# pretrain_model_name = \"CAMeL-Lab/bert-base-arabic-camelbert-msa\"\n",
    "tokenizer = BertTokenizer.from_pretrained(\"CAMeL-Lab/bert-base-arabic-camelbert-msa\")\n",
    "# tokenizer = tokenizer(padding=\"max_length\", truncation=True, max_length=128)\n",
    "model_APC = bert_APC(pretrain_model_name).to(DEVICE)\n",
    "model_APC.load_state_dict(torch.load('models/bert_APC.pt'))\n",
    "model_APC.eval()\n",
    "model_ATE = bert_ATE(pretrain_model_name).to(DEVICE)\n",
    "model_ATE.load_state_dict(torch.load('models/bert_ATE.pt'))\n",
    "model_ATE.eval() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_subtoken(word):\n",
    "    if word[:2] == \"##\":\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocessing(text):\n",
    "    \n",
    "    text = normalize_unicode(text)\n",
    "    # Normalizing alef variants to (ا)\n",
    "    text = normalize_alef_ar(text)\n",
    "    # Normalizing alef maksura (ى) to yeh (ي)\n",
    "    text = normalize_alef_maksura_ar(text)\n",
    "    # Normalizing teh marbuta (ة) to heh (ه)\n",
    "    text = normalize_teh_marbuta_ar(text)\n",
    "    # removing Arabic diacritical marks\n",
    "    text = dediac_ar(text)\n",
    "    # split the text  into tokens\n",
    "    text = simple_word_tokenize(text)  \n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mini_batch_ATE(samples):\n",
    "    ids_tensors = [s[0] for s in samples]\n",
    "\n",
    "    ids_tensors = torch.Tensor(pad_features(ids_tensors, 128)).long()\n",
    "\n",
    "    masks_tensors = torch.zeros(ids_tensors.shape, dtype=torch.long)\n",
    "    masks_tensors = masks_tensors.masked_fill(ids_tensors != 0, 1)\n",
    "\n",
    "    return ids_tensors, masks_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_model_APC(tokens, aspect):\n",
    "\n",
    "    aspect = tokenizer.tokenize(aspect)\n",
    "\n",
    "    word_pieces = ['[cls]']\n",
    "    word_pieces += tokens\n",
    "    word_pieces += ['[sep]']\n",
    "    word_pieces += aspect\n",
    "\n",
    "    segment = [0] + [0]*len(tokens) + [0] + [1]*len(aspect)\n",
    "    segment_2d = []\n",
    "    segment_2d.append(segment)\n",
    "\n",
    "    ids = tokenizer.convert_tokens_to_ids(word_pieces)\n",
    "    ids_2d = []\n",
    "    ids_2d.append(ids)\n",
    "    input_tensor = torch.Tensor(pad_features(ids_2d, 128)).long()\n",
    "    segment_tensor = torch.Tensor(pad_features(segment_2d, 128)).long()\n",
    "\n",
    "    masks_tensor = torch.zeros(input_tensor.shape, dtype=torch.long)\n",
    "    masks_tensor = input_tensor.masked_fill(input_tensor != 0, 1)  \n",
    "\n",
    "    input_tensor = input_tensor.to(DEVICE)\n",
    "    segment_tensor = segment_tensor.to(DEVICE)\n",
    "    masks_tensor = masks_tensor.to(DEVICE)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model_APC(input_tensor, None, masks_tensor, segment_tensor)\n",
    "        predictions = F.softmax(outputs, dim=1).max(dim=1)[1].cpu().tolist()[0]\n",
    "\n",
    "    return predictions\n",
    "\n",
    "def predict_model_ATE(pred_loader):\n",
    "\n",
    "    for data in pred_loader:\n",
    "        ids_tensors, mask_tensors = data\n",
    "        ids_tensors = ids_tensors.to(DEVICE)\n",
    "        mask_tensors = mask_tensors.to(DEVICE)\n",
    "        outputs = model_ATE(ids_tensors, None, mask_tensors)\n",
    "        _, predictions = torch.max(outputs, dim=2)\n",
    "\n",
    "\n",
    "    return predictions.tolist()\n",
    "\n",
    "def arabic_ABSA(reviews):\n",
    "    logging.basicConfig(format='%(levelname)s: %(message)s', level=logging.DEBUG)\n",
    "\n",
    "    reviews = [text_preprocessing(review) for review in reviews] \n",
    "\n",
    "    pred_ds = pred_dataset_ATE(reviews, tokenizer)\n",
    "    tokens = [sample[1] for sample in pred_ds]\n",
    "    pred_loader = DataLoader(pred_ds, batch_size=100, collate_fn=create_mini_batch_ATE)\n",
    "    \n",
    "    tags = predict_model_ATE(pred_loader)\n",
    "    restored_tokens = []\n",
    "    restored_tags = []\n",
    "    # detokinize the results\n",
    "    for review_tokens_idx in range(len(tokens)):\n",
    "        review_restore_tokens = []\n",
    "        review_restore_tags = []\n",
    "        for token_idx in range(len(tokens[review_tokens_idx])):\n",
    "            if not is_subtoken(tokens[review_tokens_idx][token_idx]) and (token_idx+1)<len(tokens[review_tokens_idx]) and is_subtoken(tokens[review_tokens_idx][token_idx+1]):\n",
    "                review_restore_tokens.append(tokens[review_tokens_idx][token_idx] + tokens[review_tokens_idx][token_idx+1][2:])  \n",
    "                j = 2\n",
    "                while(len(tokens[review_tokens_idx]+[token_idx+j])<len(tokens) and is_subtoken(tokens[review_tokens_idx][token_idx+j])):\n",
    "                    restored_tokens[-1] = restored_tokens[-1] + tokens[review_tokens_idx][token_idx+j][2:]\n",
    "                    j += 1\n",
    "                review_restore_tags.append(tags[review_tokens_idx][token_idx]) \n",
    "            elif not is_subtoken(tokens[review_tokens_idx][token_idx]):\n",
    "                review_restore_tokens.append(tokens[review_tokens_idx][token_idx])      \n",
    "                review_restore_tags.append(tags[review_tokens_idx][token_idx]) \n",
    "                \n",
    "        restored_tokens.append(review_restore_tokens)\n",
    "        restored_tags.append(review_restore_tags)\n",
    "    \n",
    "    aspects = []\n",
    "    # extract terms/aspects\n",
    "    for review_tags in range(len(restored_tags)):\n",
    "        review_aspects = []\n",
    "        # if no tags was found using ATE model add an empty array to the list\n",
    "        if all(tag == 0 for tag in restored_tags[review_tags]):\n",
    "            aspects.append(review_aspects)\n",
    "            continue\n",
    "        for tags in range(len(restored_tags[review_tags])):\n",
    "            if restored_tags[review_tags][tags] == 1:\n",
    "                review_aspects.append(restored_tokens[review_tags][tags])\n",
    "            if restored_tags[review_tags][tags] == 2:\n",
    "                if len(review_aspects) != 0:\n",
    "                    review_aspects[-1] = review_aspects[-1] + restored_tokens[review_tags][tags]\n",
    "                else:\n",
    "                    review_aspects.append(restored_tokens[review_tags][tags])\n",
    "        aspects.append(review_aspects)\n",
    "\n",
    "    if len(tokens) != len(aspects):\n",
    "        logging.warning('irregular output in arabic ABSA (ATE model)')\n",
    "        return None\n",
    "\n",
    "    aspects_polarity = []\n",
    "    for review_aspects_idx in range(len(aspects)):\n",
    "            review_aspects_polarity = []\n",
    "            review_aspects = aspects[review_aspects_idx]\n",
    "            if len(review_aspects) == 0:\n",
    "                aspects_polarity.append(review_aspects_polarity)\n",
    "                continue\n",
    "            for aspect in review_aspects:\n",
    "                pred= predict_model_APC(tokens[review_aspects_idx], aspect)\n",
    "                review_aspects_polarity.append(pred)\n",
    "            aspects_polarity.append(review_aspects_polarity)    \n",
    "\n",
    "    # dummy empty aspcets descriptions\n",
    "    aspects_description = [[] for i in range(len(aspects))]\n",
    "\n",
    "    results_dict = {'aspects' : aspects, 'aspects_sentiment': aspects_polarity, 'aspects_description': aspects_description}\n",
    "\n",
    "    return results_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'aspects': [['الاسعار'], []],\n",
       " 'aspects_sentiment': [[0], []],\n",
       " 'aspects_description': [[], []]}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews = [\n",
    "    \"لا بأس بالقهوة لكن الأسعار جدا غالية مقارنة مع الجودة\",\n",
    "    \"لا بأس\"\n",
    "]\n",
    "arabic_ABSA(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f1d4d6eb2abe3fb4049954bd206a32ef86aac931501ef1b113439c6e56c2b586"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
