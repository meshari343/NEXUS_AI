{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nexus_ai.ABSA.arabic.bert import bert_ATE, bert_APC\n",
    "from nexus_ai.ABSA.arabic.dataset import dataset_ATE, dataset_APC\n",
    "from nexus_ai.sentence_sentiment_analysis.preprocessing import pad_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import BertTokenizer\n",
    "import torch\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "from IPython.utils import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# for debugin\n",
    "# DEVICE = \"cpu\"\n",
    "pretrain_model_name = \"../../sentence_sentiment_analysis/arabic/models/bert_pretrained_01_acc_90.50\"\n",
    "# pretrain_model_name = \"CAMeL-Lab/bert-base-arabic-camelbert-msa\"\n",
    "tokenizer = BertTokenizer.from_pretrained(\"CAMeL-Lab/bert-base-arabic-camelbert-msa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evl_time(t):\n",
    "    min, sec= divmod(t, 60)\n",
    "    hr, min = divmod(min, 60)\n",
    "    return int(hr), int(min), int(sec)\n",
    "\n",
    "def load_model(model, path):\n",
    "    model.load_state_dict(torch.load(path))\n",
    "    return model\n",
    "    \n",
    "def save_model(model, name):\n",
    "    torch.save(model.state_dict(), name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed_value=12):\n",
    "    \"\"\"Set seed for reproducibility.\n",
    "    \"\"\"\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    torch.cuda.manual_seed_all(seed_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acpect Term Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = dataset_ATE(pd.read_csv(\"dataset/arabic_train.csv\"), tokenizer)\n",
    "test_ds = dataset_ATE(pd.read_csv(\"dataset/arabic_test.csv\"), tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ساو', '##صي', 'بالت', '##اكيد', 'بموقع', 'المدينه', 'القديمه', 'الا', 'انه', 'عليك', 'الحذر', 'من', 'الاسعار', 'السياحي', '##ه', 'الاكثر', 'ارتفاعا', '.']\n",
      "18\n",
      "tensor([23065,  3389,  2619, 23131, 19176,  8322, 15121,  1915,  2615,  2898,\n",
      "        17133,  1908,  9384, 13931,  1028,  9442, 23596,    18])\n",
      "torch.Size([18])\n",
      "tensor([0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0])\n",
      "torch.Size([18])\n",
      "tensor([-1, -1, -1, -1, -1,  2,  2, -1, -1, -1, -1, -1,  2,  2,  2, -1, -1, -1])\n",
      "torch.Size([18])\n"
     ]
    }
   ],
   "source": [
    "w,x,y,z = train_ds.__getitem__(3)\n",
    "print(w)\n",
    "print(len(w))\n",
    "print(x)\n",
    "print(x.size())\n",
    "print(y)\n",
    "print(y.size())\n",
    "print(z)\n",
    "print(z.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<nexus_ai.ABSA.arabic.dataset.dataset_ATE object at 0x0000020A8B9A6640>\n"
     ]
    }
   ],
   "source": [
    "print(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mini_batch(samples):\n",
    "    print(samples)\n",
    "    ids_tensors = [s[1] for s in samples]\n",
    "    ids_tensors = torch.Tensor(pad_features(ids_tensors, 128)).long()\n",
    "\n",
    "    tags_tensors = [s[2] for s in samples]\n",
    "    tags_tensors = torch.Tensor(pad_features(tags_tensors, 128)).long()\n",
    "\n",
    "    pols_tensors = [s[3] for s in samples]\n",
    "    pols_tensors = torch.Tensor(pad_features(pols_tensors, 128)).long()\n",
    "    \n",
    "    masks_tensors = torch.zeros(ids_tensors.shape, dtype=torch.long)\n",
    "    masks_tensors = masks_tensors.masked_fill(ids_tensors != 0, 1)\n",
    "    \n",
    "    return ids_tensors, tags_tensors, pols_tensors, masks_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_ds, batch_size=16, collate_fn=create_mini_batch, shuffle = True)\n",
    "test_loader = DataLoader(test_ds, batch_size=50, collate_fn=create_mini_batch, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['موقع', 'جيد', '،', 'فندق', 'لطيف', '،', 'عامل', '##ون', 'ود', '##ودو', '##ن', 'لقد', 'قضي', '##نا', 'وقتا', 'رائعا', 'في', 'فوك', '##يت', 'لر', '##حله', 'ذكري', 'زواج', '##نا'], tensor([ 2867,  6842,   378,  7073, 14745,   378,  7780,  1922,  2557, 19189,\n",
      "         1006,  3863, 25218,  1914, 18313, 23526,  1912, 18068,  2034,  5165,\n",
      "        16801,  5721,  9000,  1914]), tensor([1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), tensor([ 2, -1, -1,  2, -1, -1,  2,  2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1])), (['مه', '##جور', 'الاسره', 'غير', 'مريح', '##ه', 'للغ', '##ايه', 'وهي', 'ليست', 'باس', '##ره', 'علي', 'الاطلاق', 'في', 'واقع', 'الامر', '–', 'اشبه', 'بالار', '##يك', '##ه', 'الكبيره', 'المت', '##ها', '##لكه'], tensor([ 3349, 16573, 19380,  2224, 24566,  1028,  4740, 11890,  2843,  3721,\n",
      "         6736,  2197,  1958, 19263,  1912,  6422,  5122,   616, 22606, 27857,\n",
      "         2434,  1028, 19318,  2087,  1913,  4194]), tensor([0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0]), tensor([-1, -1,  0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1])), (['ماكين', '##ه', 'تجهيز', 'السا', '##ئح', 'المظ', '##هر', 'الخارجي', 'الرائع', 'لهذا', 'الفندق', 'يجعلك', 'تعقد', 'عليه', 'اما', '##لا', 'عري', '##ضه', '،', 'لكنه', 'ليس', 'سوي', 'واجه', '##ه', 'لل', '##لام', '##بال', '##اه', 'والمست', '##وي', 'المتد', '##ني', '.'], tensor([21861,  1028, 12607, 14233, 21788,  9539,  2121, 11161, 13151,  4555,\n",
      "        11133, 14454, 16779,  2181,  3910,  1903, 16645,  5003,   378,  5760,\n",
      "         2618,  4871, 10760,  1028, 10391,  2025,  9646,  2030,  6345,  1971,\n",
      "        26803,  1974,    18]), tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0]), tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  2, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1])), (['الاكل', 'نظافه', 'عاليه', 'و', 'شيف', '##ات', 'خبره', 'عاليه', '-', 'البار', 'محترف', '##ين', 'في', 'عامل', 'الكوك', '##تيل', '##ات'], tensor([15990, 24143, 11273,   415, 15836,  1904, 20594, 11273,    17,  6211,\n",
      "        18561,  1911,  1912,  7780, 15546,  8702,  1904]), tensor([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), tensor([ 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1])), (['الشيء', 'الوحيد', 'الذي', 'تلا', '##ح', '##ظه', 'هو', 'انك', 'تدفع', '9', 'يورو', 'مقابل', 'الانترنت', 'اللاس', '##لكي', 'في', 'غرف', '##تك', '.'], tensor([ 7865,  5230,  2130,  6312,  1032,  3620,  2139,  2963, 11624,    29,\n",
      "         9518,  4357,  5811, 23055, 17119,  1912,  6471,  2348,    18]), tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0]), tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  2,  2,  2, -1, -1, -1,\n",
      "        -1])), (['يبعد', 'دقيقه', 'واحده', 'سيرا', 'علي', 'الاق', '##دام', 'من', 'وسط', 'ليك', '##ساي', '##د', '،', 'وها', '##د', '##ئ', 'تماما', 'وقر', '##يب', 'جدا', 'من', 'وسط', 'المدينه', '.', 'كما', 'ان', 'الموظفين', 'يتميز', '##ون', 'بال', '##لطف', 'ويقدم', '##ون', 'المساعد', '##ه', 'دائما', '!'], tensor([13589,  8816,  5861, 28720,  1958,  7955,  2718,  1908,  4008, 10209,\n",
      "        28379,  1016,   378,  8154,  1016,  1042,  5410, 12964,  2062,  2882,\n",
      "         1908,  4008,  8322,    18,  2306,  1939, 10481, 14779,  1922,  1951,\n",
      "        13692, 19723,  1922,  7748,  1028,  3357,     5]), tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1,  2, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1])), (['يقع', 'الفندق', 'في', 'مكان', 'غير', 'مريح', 'بالمر', '##ه', 'في', 'الدا', '##ئر', '##ه', 'الثانيه', '.'], tensor([ 7772, 11133,  1912,  3192,  2224, 24566, 11098,  1028,  1912,  6938,\n",
      "         7823,  1028,  9576,    18]), tensor([0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 2, 0]), tensor([-1, -1, -1,  0, -1, -1, -1, -1, -1,  0,  0,  0,  0, -1])), (['عندما', 'قمنا', 'باد', '##خال', 'امت', '##عتنا', 'في', 'الغرف', '##ه', '،', 'لم', 'يكن', 'بالام', '##كان', 'فتح', 'الباب', '-', 'انا', 'اعلم', 'انها', 'مدينه', 'نيويورك', 'حيث', 'الغرف', 'ليست', 'واسعه', 'ولكن', 'هذا', 'كان', 'كثيرا', 'بعض', 'الشيء', '!'], tensor([ 2805, 18568, 10024,  6802,  5033, 16746,  1912, 16135,  1028,   378,\n",
      "         2043,  3812,  8927,  2179,  4131,  4687,    17,  2315,  5554,  3550,\n",
      "         6934,  9039,  2455, 16135,  3721, 24280,  2637,  2085,  2055,  3810,\n",
      "         2346,  7865,     5]), tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0]), tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  0, -1, -1,\n",
      "        -1, -1, -1, -1, -1,  0, -1, -1, -1, -1, -1, -1, -1, -1, -1])), (['احد', 'افضل', 'التجارب', 'التي', 'خض', '##ناها', 'يا', 'له', 'من', 'مكان', 'مده', '##ش', 'للرا', '##حه', '.', 'طاقم', 'العمل', 'هناك', 'رائع', 'وبش', '##وش', 'للغ', '##ايه', '.'], tensor([ 2439,  2931, 12693,  2061, 11897,  7806,  2104,  2154,  1908,  3192,\n",
      "        13223,  1034, 14339,  2379,    18, 17333,  2854,  2671,  7018, 23082,\n",
      "         2937,  4740, 11890,    18]), tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0]), tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1,  2, -1, -1, -1, -1, -1,  2,  2, -1,\n",
      "        -1, -1, -1, -1, -1, -1])), (['وعلي', 'الرغم', 'من', 'اننا', 'كانت', 'لدينا', 'حج', '##وزات', 'الا', 'انهم', 'لم', 'يحترم', '##وها', '(', 'وصلنا', 'عده', 'دقائق', 'مبكرا', '-', 'بدون', 'عذر', ')', '.'], tensor([ 4126,  7363,  1908,  5839,  2431,  5344,  7617, 19974,  1915,  5507,\n",
      "         2043, 19608,  3736,    12, 18882, 14201,  4113, 19494,    17,  3279,\n",
      "        13710,    13,    18]), tensor([0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), tensor([-1, -1, -1, -1, -1, -1,  0,  0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1])), (['فضيحه', 'في', 'تاريخ', 'الفنادق', 'يفتقد', 'الي', 'اساسي', '##ات', 'الشقق', 'المفر', '##وشه', 'ما', 'بالك', 'بش', '##قق', 'فندق', '##يه', 'ذات', 'الاربع', 'نجوم', '.', 'استطيع', 'تسمي', '##ته', 'بش', '##قق', 'غير', 'مفرو', '##شه', 'قيمتها', 'الفعلي', '##ه', 'لا', 'تتع', '##دي', '#', '16', '##33', ';', '#', '16', '##37', ';', '#', '16', '##32', ';', 'ريال', 'للي', '##له', 'المب', '##ني', 'مت', '##هله', '##ل', 'معرض', 'لس', '##قوط', 'وانا', 'مستعد', 'اثبات', 'ذلك', 'ارجو', 'مراسل', '##تي', 'او', 'ارد', 'علي', 'التعليق', '.'], tensor([22615,  1912,  3173, 10938, 22347,  2002, 15703,  1904, 21326, 14719,\n",
      "        21815,  1972,  3906,  2331,  3295,  7073,  1988,  3492, 28564,  7166,\n",
      "           18, 14711, 16769,  2076,  2331,  3295,  2224, 16683,  3990, 11197,\n",
      "        25195,  1028,  1963, 16019,  1930,     7,  3367,  5118,    31,     7,\n",
      "         3367,  6553,    31,     7,  3367,  5782,    31,  3108,  4492,  1917,\n",
      "         3646,  1974,  2068, 16379,  1010,  4992,  2968,  6133,  3257, 19083,\n",
      "        25787,  2271, 11238, 14751,  2005,  2213,  5737,  1958,  9921,    18]), tensor([0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), tensor([-1, -1, -1,  0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1])), (['الحمدلله', 'رب', 'العالمين', '.', '.', 'الذي', 'وفق', '##نا', 'لاد', '##اء', 'العمر', '##ه', '،'], tensor([ 4062,  2512,  6074,    18,    18,  2130,  4863,  1914, 11862,  1954,\n",
      "         3867,  1028,   378]), tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1])), (['الغرف', 'صغيره', 'جدا', 'وغير', 'مريح', '##ه', '.'], tensor([16135, 12410,  2882,  3387, 24566,  1028,    18]), tensor([1, 0, 0, 0, 0, 0, 0]), tensor([ 0, -1, -1, -1, -1, -1, -1])), (['المج', '##مل', 'العام', 'الفندق', 'جيد', 'بالنسبه', 'الي', 'سعره', 'في', 'دبي', 'ولكن', 'بالمق', '##ارن', '##ه', 'بف', '##نادق', 'اسط', '##انب', '##ول', 'الاربع', 'نجوم', 'يعتبر', 'هذا', 'الفندق', 'نجوم'], tensor([ 2265,  2182,  2169, 11133,  6842, 11131,  2002, 28063,  1912,  4403,\n",
      "         2637, 23959, 16241,  1028,  4304,  5904, 15508,  3082,  1940, 28564,\n",
      "         7166,  5305,  2085, 11133,  7166]), tensor([0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0]), tensor([-1, -1, -1,  1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1])), (['ست', '##بد', '##ؤون', 'في', 'الفندق', 'بالتح', '##ضر', 'لر', '##حله', 'السف', '##اري', 'الصحراوي', '##ه', '.', 'ان', 'الفندق', 'بسيط', 'ولكنه', 'يمثل', 'نقطه', 'بدء', 'جيده', '.'], tensor([ 2333,  2041,  3977,  1912, 11133,  9387,  2511,  5165, 16801,  3840,\n",
      "         2140, 26949,  1028,    18,  1939, 11133,  9893,  7476,  6875, 12063,\n",
      "         6305, 20964,    18]), tensor([0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), tensor([-1, -1, -1, -1,  2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1])), (['سعداء', 'جدا', 'مع', 'الفندق', 'موقع', 'رائع', ',', 'خذ', 'الحا', '##فله', 'المت', '##جهه', 'الي', 'O', '##C', '##AT', 'من', 'K', '##I', '##X', 'واخر', '##ج', 'من', 'محطه', 'الحا', '##فلات', 'وسيكون', 'هناك', 'مباشره', '.'], tensor([22164,  2882,  1973, 11133,  2867,  7018,    16,  5390,  4325, 10816,\n",
      "         2087,  9655,  2002,    51,  1084,  9507,  1908,    47,  1062,  1116,\n",
      "        10336,  1041,  1908, 25435,  4325, 12979, 16407,  2671, 12817,    18]), tensor([0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0]), tensor([-1, -1, -1,  2,  2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]))]\n",
      "tensor([[ 2867,  6842,   378,  ...,     0,     0,     0],\n",
      "        [ 3349, 16573, 19380,  ...,     0,     0,     0],\n",
      "        [21861,  1028, 12607,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [ 2265,  2182,  2169,  ...,     0,     0,     0],\n",
      "        [ 2333,  2041,  3977,  ...,     0,     0,     0],\n",
      "        [22164,  2882,  1973,  ...,     0,     0,     0]])\n",
      "torch.Size([16, 128])\n",
      "tensor([[1, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 1,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]])\n",
      "torch.Size([16, 128])\n",
      "tensor([[ 2, -1, -1,  ...,  0,  0,  0],\n",
      "        [-1, -1,  0,  ...,  0,  0,  0],\n",
      "        [-1, -1, -1,  ...,  0,  0,  0],\n",
      "        ...,\n",
      "        [-1, -1, -1,  ...,  0,  0,  0],\n",
      "        [-1, -1, -1,  ...,  0,  0,  0],\n",
      "        [-1, -1, -1,  ...,  0,  0,  0]])\n",
      "torch.Size([16, 128])\n",
      "tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]])\n",
      "torch.Size([16, 128])\n"
     ]
    }
   ],
   "source": [
    "for batch in train_loader:\n",
    "    w,x,y,z = batch\n",
    "    print(w)\n",
    "    print(w.size())\n",
    "    print(x)\n",
    "    print(x.size())\n",
    "    print(y)\n",
    "    print(y.size())\n",
    "    print(z)\n",
    "    print(z.size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_ATE(loader, epochs):\n",
    "    all_data = len(loader)\n",
    "    for epoch in range(epochs):\n",
    "        finish_data = 0\n",
    "        losses = []\n",
    "        current_times = []\n",
    "        correct_predictions = 0\n",
    "        \n",
    "        for data in loader:\n",
    "            t0 = time.time()\n",
    "            ids_tensors, tags_tensors, _, masks_tensors = data\n",
    "            ids_tensors = ids_tensors.to(DEVICE)\n",
    "            tags_tensors = tags_tensors.to(DEVICE)\n",
    "            masks_tensors = masks_tensors.to(DEVICE)\n",
    "            \n",
    "            loss = model_ATE(ids_tensors=ids_tensors, tags_tensors=tags_tensors, masks_tensors=masks_tensors)\n",
    "            losses.append(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer_ATE.step()\n",
    "            optimizer_ATE.zero_grad()\n",
    "\n",
    "            finish_data += 1\n",
    "            current_times.append(round(time.time()-t0,3))\n",
    "            current = np.mean(current_times)\n",
    "            hr, min, sec = evl_time(current*(all_data-finish_data) + current*all_data*(epochs-epoch-1))\n",
    "            print('epoch:', epoch, \" batch:\", finish_data, \"/\" , all_data, \" loss:\", np.mean(losses), \" hr:\", hr, \" min:\", min,\" sec:\", sec)         \n",
    "\n",
    "        save_model(model_ATE, 'models/bert_ATE.pt')\n",
    "        \n",
    "def test_model_ATE(loader):\n",
    "    pred = []\n",
    "    trueth = []\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "\n",
    "            ids_tensors, tags_tensors, _, masks_tensors = data\n",
    "            ids_tensors = ids_tensors.to(DEVICE)\n",
    "            tags_tensors = tags_tensors.to(DEVICE)\n",
    "            masks_tensors = masks_tensors.to(DEVICE)\n",
    "\n",
    "            outputs = model_ATE(ids_tensors=ids_tensors, tags_tensors=None, masks_tensors=masks_tensors)\n",
    "\n",
    "            _, predictions = torch.max(outputs, dim=2)\n",
    "\n",
    "            pred += list([int(j) for i in predictions for j in i ])\n",
    "            trueth += list([int(j) for i in tags_tensors for j in i ])\n",
    "\n",
    "    return trueth, pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 11.8 s\n",
      "Wall time: 11.8 s\n",
      "learning rate: 0.0001\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99    116071\n",
      "           1       0.77      0.66      0.71      1791\n",
      "           2       0.56      0.57      0.56       410\n",
      "\n",
      "    accuracy                           0.99    118272\n",
      "   macro avg       0.77      0.74      0.76    118272\n",
      "weighted avg       0.99      0.99      0.99    118272\n",
      "\n",
      "CPU times: total: 11.7 s\n",
      "Wall time: 11.7 s\n",
      "learning rate: 0.0002\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99    116071\n",
      "           1       0.69      0.73      0.71      1791\n",
      "           2       0.48      0.67      0.56       410\n",
      "\n",
      "    accuracy                           0.99    118272\n",
      "   macro avg       0.72      0.80      0.75    118272\n",
      "weighted avg       0.99      0.99      0.99    118272\n",
      "\n",
      "CPU times: total: 11.7 s\n",
      "Wall time: 11.7 s\n",
      "learning rate: 0.0003\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99    116071\n",
      "           1       0.00      0.00      0.00      1791\n",
      "           2       0.00      0.00      0.00       410\n",
      "\n",
      "    accuracy                           0.98    118272\n",
      "   macro avg       0.33      0.33      0.33    118272\n",
      "weighted avg       0.96      0.98      0.97    118272\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\meshari\\nexus_ai\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\meshari\\nexus_ai\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\meshari\\nexus_ai\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 11.7 s\n",
      "Wall time: 11.7 s\n",
      "learning rate: 0.0004\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99    116071\n",
      "           1       0.00      0.00      0.00      1791\n",
      "           2       0.00      0.00      0.00       410\n",
      "\n",
      "    accuracy                           0.98    118272\n",
      "   macro avg       0.33      0.33      0.33    118272\n",
      "weighted avg       0.96      0.98      0.97    118272\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\meshari\\nexus_ai\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\meshari\\nexus_ai\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\meshari\\nexus_ai\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 11.7 s\n",
      "Wall time: 11.7 s\n",
      "learning rate: 0.0005\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99    116071\n",
      "           1       0.00      0.00      0.00      1791\n",
      "           2       0.00      0.00      0.00       410\n",
      "\n",
      "    accuracy                           0.98    118272\n",
      "   macro avg       0.33      0.33      0.33    118272\n",
      "weighted avg       0.96      0.98      0.97    118272\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\meshari\\nexus_ai\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\meshari\\nexus_ai\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\meshari\\nexus_ai\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 11.7 s\n",
      "Wall time: 11.7 s\n",
      "learning rate: 0.0006\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99    116071\n",
      "           1       0.00      0.00      0.00      1791\n",
      "           2       0.00      0.00      0.00       410\n",
      "\n",
      "    accuracy                           0.98    118272\n",
      "   macro avg       0.33      0.33      0.33    118272\n",
      "weighted avg       0.96      0.98      0.97    118272\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\meshari\\nexus_ai\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\meshari\\nexus_ai\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\meshari\\nexus_ai\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 11.7 s\n",
      "Wall time: 11.7 s\n",
      "learning rate: 0.0007\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99    116071\n",
      "           1       0.00      0.00      0.00      1791\n",
      "           2       0.00      0.00      0.00       410\n",
      "\n",
      "    accuracy                           0.98    118272\n",
      "   macro avg       0.33      0.33      0.33    118272\n",
      "weighted avg       0.96      0.98      0.97    118272\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\meshari\\nexus_ai\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\meshari\\nexus_ai\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\meshari\\nexus_ai\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 11.7 s\n",
      "Wall time: 11.7 s\n",
      "learning rate: 0.0008\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99    116071\n",
      "           1       0.00      0.00      0.00      1791\n",
      "           2       0.00      0.00      0.00       410\n",
      "\n",
      "    accuracy                           0.98    118272\n",
      "   macro avg       0.33      0.33      0.33    118272\n",
      "weighted avg       0.96      0.98      0.97    118272\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\meshari\\nexus_ai\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\meshari\\nexus_ai\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\meshari\\nexus_ai\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 11.7 s\n",
      "Wall time: 11.7 s\n",
      "learning rate: 0.0009\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99    116071\n",
      "           1       0.00      0.00      0.00      1791\n",
      "           2       0.00      0.00      0.00       410\n",
      "\n",
      "    accuracy                           0.98    118272\n",
      "   macro avg       0.33      0.33      0.33    118272\n",
      "weighted avg       0.96      0.98      0.97    118272\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\meshari\\nexus_ai\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\meshari\\nexus_ai\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\meshari\\nexus_ai\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 11.8 s\n",
      "Wall time: 11.8 s\n",
      "learning rate: 1e-05\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99    116071\n",
      "           1       0.78      0.44      0.57      1791\n",
      "           2       0.66      0.29      0.40       410\n",
      "\n",
      "    accuracy                           0.99    118272\n",
      "   macro avg       0.81      0.58      0.65    118272\n",
      "weighted avg       0.99      0.99      0.99    118272\n",
      "\n",
      "CPU times: total: 11.8 s\n",
      "Wall time: 11.8 s\n",
      "learning rate: 2e-05\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99    116071\n",
      "           1       0.72      0.65      0.68      1791\n",
      "           2       0.65      0.50      0.56       410\n",
      "\n",
      "    accuracy                           0.99    118272\n",
      "   macro avg       0.79      0.71      0.75    118272\n",
      "weighted avg       0.99      0.99      0.99    118272\n",
      "\n",
      "CPU times: total: 11.7 s\n",
      "Wall time: 11.7 s\n",
      "learning rate: 3e-05\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99    116071\n",
      "           1       0.78      0.62      0.69      1791\n",
      "           2       0.58      0.55      0.57       410\n",
      "\n",
      "    accuracy                           0.99    118272\n",
      "   macro avg       0.79      0.72      0.75    118272\n",
      "weighted avg       0.99      0.99      0.99    118272\n",
      "\n",
      "CPU times: total: 11.7 s\n",
      "Wall time: 11.7 s\n",
      "learning rate: 4e-05\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00    116071\n",
      "           1       0.74      0.70      0.72      1791\n",
      "           2       0.68      0.44      0.53       410\n",
      "\n",
      "    accuracy                           0.99    118272\n",
      "   macro avg       0.81      0.71      0.75    118272\n",
      "weighted avg       0.99      0.99      0.99    118272\n",
      "\n",
      "CPU times: total: 11.7 s\n",
      "Wall time: 11.7 s\n",
      "learning rate: 5e-05\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00    116071\n",
      "           1       0.81      0.64      0.71      1791\n",
      "           2       0.58      0.63      0.60       410\n",
      "\n",
      "    accuracy                           0.99    118272\n",
      "   macro avg       0.79      0.76      0.77    118272\n",
      "weighted avg       0.99      0.99      0.99    118272\n",
      "\n",
      "CPU times: total: 11.8 s\n",
      "Wall time: 11.7 s\n",
      "learning rate: 6e-05\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99    116071\n",
      "           1       0.80      0.60      0.69      1791\n",
      "           2       0.66      0.50      0.57       410\n",
      "\n",
      "    accuracy                           0.99    118272\n",
      "   macro avg       0.82      0.70      0.75    118272\n",
      "weighted avg       0.99      0.99      0.99    118272\n",
      "\n",
      "CPU times: total: 11.7 s\n",
      "Wall time: 11.7 s\n",
      "learning rate: 7e-05\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99    116071\n",
      "           1       0.64      0.77      0.70      1791\n",
      "           2       0.61      0.56      0.58       410\n",
      "\n",
      "    accuracy                           0.99    118272\n",
      "   macro avg       0.75      0.77      0.76    118272\n",
      "weighted avg       0.99      0.99      0.99    118272\n",
      "\n",
      "CPU times: total: 11.8 s\n",
      "Wall time: 11.7 s\n",
      "learning rate: 8e-05\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99    116071\n",
      "           1       0.88      0.52      0.65      1791\n",
      "           2       0.67      0.45      0.54       410\n",
      "\n",
      "    accuracy                           0.99    118272\n",
      "   macro avg       0.84      0.66      0.73    118272\n",
      "weighted avg       0.99      0.99      0.99    118272\n",
      "\n",
      "CPU times: total: 11.7 s\n",
      "Wall time: 11.7 s\n",
      "learning rate: 9e-05\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99    116071\n",
      "           1       0.69      0.78      0.73      1791\n",
      "           2       0.60      0.51      0.55       410\n",
      "\n",
      "    accuracy                           0.99    118272\n",
      "   macro avg       0.76      0.76      0.76    118272\n",
      "weighted avg       0.99      0.99      0.99    118272\n",
      "\n",
      "CPU times: total: 11.7 s\n",
      "Wall time: 11.7 s\n",
      "learning rate: 1e-06\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99    116071\n",
      "           1       0.00      0.00      0.00      1791\n",
      "           2       0.00      0.00      0.00       410\n",
      "\n",
      "    accuracy                           0.98    118272\n",
      "   macro avg       0.33      0.33      0.33    118272\n",
      "weighted avg       0.96      0.98      0.97    118272\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\meshari\\nexus_ai\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\meshari\\nexus_ai\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\meshari\\nexus_ai\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 11.7 s\n",
      "Wall time: 11.7 s\n",
      "learning rate: 2e-06\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99    116071\n",
      "           1       0.00      0.00      0.00      1791\n",
      "           2       0.00      0.00      0.00       410\n",
      "\n",
      "    accuracy                           0.98    118272\n",
      "   macro avg       0.33      0.33      0.33    118272\n",
      "weighted avg       0.96      0.98      0.97    118272\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\meshari\\nexus_ai\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\meshari\\nexus_ai\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\meshari\\nexus_ai\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 11.7 s\n",
      "Wall time: 11.7 s\n",
      "learning rate: 3e-06\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99    116071\n",
      "           1       0.00      0.00      0.00      1791\n",
      "           2       0.00      0.00      0.00       410\n",
      "\n",
      "    accuracy                           0.98    118272\n",
      "   macro avg       0.33      0.33      0.33    118272\n",
      "weighted avg       0.96      0.98      0.97    118272\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\meshari\\nexus_ai\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\meshari\\nexus_ai\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\meshari\\nexus_ai\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 11.7 s\n",
      "Wall time: 11.7 s\n",
      "learning rate: 4e-06\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99    116071\n",
      "           1       0.54      0.01      0.02      1791\n",
      "           2       0.00      0.00      0.00       410\n",
      "\n",
      "    accuracy                           0.98    118272\n",
      "   macro avg       0.51      0.34      0.34    118272\n",
      "weighted avg       0.97      0.98      0.97    118272\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\meshari\\nexus_ai\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\meshari\\nexus_ai\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\meshari\\nexus_ai\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 11.7 s\n",
      "Wall time: 11.7 s\n",
      "learning rate: 5e-06\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99    116071\n",
      "           1       0.59      0.12      0.19      1791\n",
      "           2       1.00      0.00      0.01       410\n",
      "\n",
      "    accuracy                           0.98    118272\n",
      "   macro avg       0.86      0.37      0.40    118272\n",
      "weighted avg       0.98      0.98      0.98    118272\n",
      "\n",
      "CPU times: total: 11.7 s\n",
      "Wall time: 11.7 s\n",
      "learning rate: 6e-06\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99    116071\n",
      "           1       0.60      0.32      0.42      1791\n",
      "           2       0.71      0.03      0.06       410\n",
      "\n",
      "    accuracy                           0.98    118272\n",
      "   macro avg       0.77      0.45      0.49    118272\n",
      "weighted avg       0.98      0.98      0.98    118272\n",
      "\n",
      "CPU times: total: 11.7 s\n",
      "Wall time: 11.7 s\n",
      "learning rate: 7e-06\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99    116071\n",
      "           1       0.68      0.45      0.54      1791\n",
      "           2       0.63      0.18      0.28       410\n",
      "\n",
      "    accuracy                           0.99    118272\n",
      "   macro avg       0.77      0.54      0.60    118272\n",
      "weighted avg       0.98      0.99      0.98    118272\n",
      "\n",
      "CPU times: total: 11.7 s\n",
      "Wall time: 11.7 s\n",
      "learning rate: 8e-06\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99    116071\n",
      "           1       0.62      0.30      0.40      1791\n",
      "           2       0.66      0.06      0.11       410\n",
      "\n",
      "    accuracy                           0.98    118272\n",
      "   macro avg       0.75      0.45      0.50    118272\n",
      "weighted avg       0.98      0.98      0.98    118272\n",
      "\n",
      "CPU times: total: 11.7 s\n",
      "Wall time: 11.7 s\n",
      "learning rate: 9e-06\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99    116071\n",
      "           1       0.63      0.33      0.43      1791\n",
      "           2       0.72      0.10      0.18       410\n",
      "\n",
      "    accuracy                           0.98    118272\n",
      "   macro avg       0.78      0.48      0.54    118272\n",
      "weighted avg       0.98      0.98      0.98    118272\n",
      "\n"
     ]
    }
   ],
   "source": [
    "set_seed(12)\n",
    "lr_list = [\n",
    "    1e-4, 2e-4, 3e-4, 4e-4, 5e-4, 6e-4, 7e-4, 8e-4, 9e-4,\n",
    "    1e-5, 2e-5, 3e-5, 4e-5, 5e-5, 6e-5, 7e-5, 8e-5, 9e-5,\n",
    "    1e-6, 2e-6, 3e-6, 4e-6, 5e-6, 6e-6, 7e-6, 8e-6, 9e-6,\n",
    "]\n",
    "for lr in lr_list:\n",
    "    torch.cuda.empty_cache()\n",
    "    with io.capture_output() as captured:\n",
    "        model_ATE = bert_ATE(pretrain_model_name, local_files_only=True).to(DEVICE)\n",
    "        optimizer_ATE = torch.optim.AdamW(model_ATE.parameters(), lr=lr)\n",
    "        train_model_ATE(train_loader, 2)\n",
    "    %time x, y = test_model_ATE(test_loader)\n",
    "    print(f'learning rate: {lr}')\n",
    "    print(classification_report(x, y, target_names=[str(i) for i in range(3)]))\n",
    "    torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 5e-5\n",
    "model_ATE = bert_ATE(pretrain_model_name).to(DEVICE)\n",
    "optimizer_ATE = torch.optim.AdamW(model_ATE.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0  batch: 1 / 226  loss: 1.0914989709854126  hr: 0  min: 0  sec: 46\n",
      "epoch: 0  batch: 2 / 226  loss: 0.702249675989151  hr: 0  min: 0  sec: 45\n",
      "epoch: 0  batch: 3 / 226  loss: 0.5087520902355512  hr: 0  min: 0  sec: 48\n",
      "epoch: 0  batch: 4 / 226  loss: 0.40624653920531273  hr: 0  min: 0  sec: 49\n",
      "epoch: 0  batch: 5 / 226  loss: 0.3497561901807785  hr: 0  min: 0  sec: 50\n",
      "epoch: 0  batch: 6 / 226  loss: 0.30826083322366077  hr: 0  min: 0  sec: 50\n",
      "epoch: 0  batch: 7 / 226  loss: 0.28083924842732294  hr: 0  min: 0  sec: 51\n",
      "epoch: 0  batch: 8 / 226  loss: 0.2630830826237798  hr: 0  min: 0  sec: 51\n",
      "epoch: 0  batch: 9 / 226  loss: 0.2494450898634063  hr: 0  min: 0  sec: 51\n",
      "epoch: 0  batch: 10 / 226  loss: 0.2309298887848854  hr: 0  min: 0  sec: 51\n",
      "epoch: 0  batch: 11 / 226  loss: 0.22354887832294812  hr: 0  min: 0  sec: 51\n",
      "epoch: 0  batch: 12 / 226  loss: 0.21553566182653108  hr: 0  min: 0  sec: 52\n",
      "epoch: 0  batch: 13 / 226  loss: 0.2079309901365867  hr: 0  min: 0  sec: 52\n",
      "epoch: 0  batch: 14 / 226  loss: 0.2023835437638419  hr: 0  min: 0  sec: 52\n",
      "epoch: 0  batch: 15 / 226  loss: 0.19649346669514975  hr: 0  min: 0  sec: 52\n",
      "epoch: 0  batch: 16 / 226  loss: 0.18989941384643316  hr: 0  min: 0  sec: 52\n",
      "epoch: 0  batch: 17 / 226  loss: 0.18623874643269708  hr: 0  min: 0  sec: 51\n",
      "epoch: 0  batch: 18 / 226  loss: 0.18125644905699623  hr: 0  min: 0  sec: 51\n",
      "epoch: 0  batch: 19 / 226  loss: 0.17553999823959252  hr: 0  min: 0  sec: 51\n",
      "epoch: 0  batch: 20 / 226  loss: 0.17366219870746136  hr: 0  min: 0  sec: 51\n",
      "epoch: 0  batch: 21 / 226  loss: 0.16960380297331584  hr: 0  min: 0  sec: 51\n",
      "epoch: 0  batch: 22 / 226  loss: 0.1665776361795989  hr: 0  min: 0  sec: 51\n",
      "epoch: 0  batch: 23 / 226  loss: 0.16377819977376773  hr: 0  min: 0  sec: 51\n",
      "epoch: 0  batch: 24 / 226  loss: 0.1626091447348396  hr: 0  min: 0  sec: 51\n",
      "epoch: 0  batch: 25 / 226  loss: 0.16117725104093553  hr: 0  min: 0  sec: 51\n",
      "epoch: 0  batch: 26 / 226  loss: 0.15937602032835668  hr: 0  min: 0  sec: 51\n",
      "epoch: 0  batch: 27 / 226  loss: 0.15751877647859078  hr: 0  min: 0  sec: 51\n",
      "epoch: 0  batch: 28 / 226  loss: 0.15538191476038524  hr: 0  min: 0  sec: 51\n",
      "epoch: 0  batch: 29 / 226  loss: 0.15324468396860977  hr: 0  min: 0  sec: 51\n",
      "epoch: 0  batch: 30 / 226  loss: 0.15126349553465843  hr: 0  min: 0  sec: 51\n",
      "epoch: 0  batch: 31 / 226  loss: 0.14963564180558728  hr: 0  min: 0  sec: 51\n",
      "epoch: 0  batch: 32 / 226  loss: 0.14816807629540563  hr: 0  min: 0  sec: 50\n",
      "epoch: 0  batch: 33 / 226  loss: 0.14649591233694192  hr: 0  min: 0  sec: 50\n",
      "epoch: 0  batch: 34 / 226  loss: 0.1451089973835384  hr: 0  min: 0  sec: 50\n",
      "epoch: 0  batch: 35 / 226  loss: 0.14299802844013487  hr: 0  min: 0  sec: 50\n",
      "epoch: 0  batch: 36 / 226  loss: 0.14184990918470752  hr: 0  min: 0  sec: 50\n",
      "epoch: 0  batch: 37 / 226  loss: 0.14019005624829112  hr: 0  min: 0  sec: 50\n",
      "epoch: 0  batch: 38 / 226  loss: 0.13945596371042102  hr: 0  min: 0  sec: 50\n",
      "epoch: 0  batch: 39 / 226  loss: 0.1378917369322899  hr: 0  min: 0  sec: 50\n",
      "epoch: 0  batch: 40 / 226  loss: 0.13738079443573953  hr: 0  min: 0  sec: 49\n",
      "epoch: 0  batch: 41 / 226  loss: 0.13615873274279805  hr: 0  min: 0  sec: 49\n",
      "epoch: 0  batch: 42 / 226  loss: 0.13489865742269017  hr: 0  min: 0  sec: 49\n",
      "epoch: 0  batch: 43 / 226  loss: 0.13372311359921166  hr: 0  min: 0  sec: 49\n",
      "epoch: 0  batch: 44 / 226  loss: 0.13287135823206467  hr: 0  min: 0  sec: 49\n",
      "epoch: 0  batch: 45 / 226  loss: 0.13169656313127942  hr: 0  min: 0  sec: 49\n",
      "epoch: 0  batch: 46 / 226  loss: 0.130311023119999  hr: 0  min: 0  sec: 49\n",
      "epoch: 0  batch: 47 / 226  loss: 0.12914644704854233  hr: 0  min: 0  sec: 49\n",
      "epoch: 0  batch: 48 / 226  loss: 0.1286721808525423  hr: 0  min: 0  sec: 49\n",
      "epoch: 0  batch: 49 / 226  loss: 0.1272913384042224  hr: 0  min: 0  sec: 49\n",
      "epoch: 0  batch: 50 / 226  loss: 0.1260604114085436  hr: 0  min: 0  sec: 48\n",
      "epoch: 0  batch: 51 / 226  loss: 0.12531723103979053  hr: 0  min: 0  sec: 48\n",
      "epoch: 0  batch: 52 / 226  loss: 0.12443243647710635  hr: 0  min: 0  sec: 48\n",
      "epoch: 0  batch: 53 / 226  loss: 0.12399770818510146  hr: 0  min: 0  sec: 48\n",
      "epoch: 0  batch: 54 / 226  loss: 0.1235501743439171  hr: 0  min: 0  sec: 48\n",
      "epoch: 0  batch: 55 / 226  loss: 0.12262582731517878  hr: 0  min: 0  sec: 48\n",
      "epoch: 0  batch: 56 / 226  loss: 0.12153608637994953  hr: 0  min: 0  sec: 48\n",
      "epoch: 0  batch: 57 / 226  loss: 0.12052066682984955  hr: 0  min: 0  sec: 48\n",
      "epoch: 0  batch: 58 / 226  loss: 0.11993294254202268  hr: 0  min: 0  sec: 47\n",
      "epoch: 0  batch: 59 / 226  loss: 0.11960290517594854  hr: 0  min: 0  sec: 47\n",
      "epoch: 0  batch: 60 / 226  loss: 0.11932768591990074  hr: 0  min: 0  sec: 47\n",
      "epoch: 0  batch: 61 / 226  loss: 0.11875165577550403  hr: 0  min: 0  sec: 47\n",
      "epoch: 0  batch: 62 / 226  loss: 0.11777877447105223  hr: 0  min: 0  sec: 47\n",
      "epoch: 0  batch: 63 / 226  loss: 0.11710650568443631  hr: 0  min: 0  sec: 47\n",
      "epoch: 0  batch: 64 / 226  loss: 0.11618873511906713  hr: 0  min: 0  sec: 47\n",
      "epoch: 0  batch: 65 / 226  loss: 0.11572063095294512  hr: 0  min: 0  sec: 47\n",
      "epoch: 0  batch: 66 / 226  loss: 0.11513831421281352  hr: 0  min: 0  sec: 47\n",
      "epoch: 0  batch: 67 / 226  loss: 0.11459895190018327  hr: 0  min: 0  sec: 46\n",
      "epoch: 0  batch: 68 / 226  loss: 0.11395035749849151  hr: 0  min: 0  sec: 46\n",
      "epoch: 0  batch: 69 / 226  loss: 0.11327607594970343  hr: 0  min: 0  sec: 46\n",
      "epoch: 0  batch: 70 / 226  loss: 0.11262593758957727  hr: 0  min: 0  sec: 46\n",
      "epoch: 0  batch: 71 / 226  loss: 0.11183475188806023  hr: 0  min: 0  sec: 46\n",
      "epoch: 0  batch: 72 / 226  loss: 0.11095107269162933  hr: 0  min: 0  sec: 46\n",
      "epoch: 0  batch: 73 / 226  loss: 0.11023813833112586  hr: 0  min: 0  sec: 46\n",
      "epoch: 0  batch: 74 / 226  loss: 0.1095338978779477  hr: 0  min: 0  sec: 46\n",
      "epoch: 0  batch: 75 / 226  loss: 0.10885583609342575  hr: 0  min: 0  sec: 46\n",
      "epoch: 0  batch: 76 / 226  loss: 0.10825703263674911  hr: 0  min: 0  sec: 45\n",
      "epoch: 0  batch: 77 / 226  loss: 0.10759789912731617  hr: 0  min: 0  sec: 45\n",
      "epoch: 0  batch: 78 / 226  loss: 0.10697217672490157  hr: 0  min: 0  sec: 45\n",
      "epoch: 0  batch: 79 / 226  loss: 0.10625502155928672  hr: 0  min: 0  sec: 45\n",
      "epoch: 0  batch: 80 / 226  loss: 0.10584549512714148  hr: 0  min: 0  sec: 45\n",
      "epoch: 0  batch: 81 / 226  loss: 0.10533588747551412  hr: 0  min: 0  sec: 45\n",
      "epoch: 0  batch: 82 / 226  loss: 0.10464074403592726  hr: 0  min: 0  sec: 45\n",
      "epoch: 0  batch: 83 / 226  loss: 0.10393661260604858  hr: 0  min: 0  sec: 45\n",
      "epoch: 0  batch: 84 / 226  loss: 0.10334862968219179  hr: 0  min: 0  sec: 44\n",
      "epoch: 0  batch: 85 / 226  loss: 0.10257690299083205  hr: 0  min: 0  sec: 44\n",
      "epoch: 0  batch: 86 / 226  loss: 0.10190088145954665  hr: 0  min: 0  sec: 44\n",
      "epoch: 0  batch: 87 / 226  loss: 0.10122332199551594  hr: 0  min: 0  sec: 44\n",
      "epoch: 0  batch: 88 / 226  loss: 0.10051298950036819  hr: 0  min: 0  sec: 44\n",
      "epoch: 0  batch: 89 / 226  loss: 0.09987911293178461  hr: 0  min: 0  sec: 44\n",
      "epoch: 0  batch: 90 / 226  loss: 0.09925860087904666  hr: 0  min: 0  sec: 44\n",
      "epoch: 0  batch: 91 / 226  loss: 0.09893812185951642  hr: 0  min: 0  sec: 44\n",
      "epoch: 0  batch: 92 / 226  loss: 0.09842420758112617  hr: 0  min: 0  sec: 43\n",
      "epoch: 0  batch: 93 / 226  loss: 0.09781337938001079  hr: 0  min: 0  sec: 43\n",
      "epoch: 0  batch: 94 / 226  loss: 0.09731798523918112  hr: 0  min: 0  sec: 43\n",
      "epoch: 0  batch: 95 / 226  loss: 0.09689570610460482  hr: 0  min: 0  sec: 43\n",
      "epoch: 0  batch: 96 / 226  loss: 0.09644226687184225  hr: 0  min: 0  sec: 43\n",
      "epoch: 0  batch: 97 / 226  loss: 0.09598626081169266  hr: 0  min: 0  sec: 43\n",
      "epoch: 0  batch: 98 / 226  loss: 0.09541335070923883  hr: 0  min: 0  sec: 43\n",
      "epoch: 0  batch: 99 / 226  loss: 0.09480564691352122  hr: 0  min: 0  sec: 43\n",
      "epoch: 0  batch: 100 / 226  loss: 0.09431372005492449  hr: 0  min: 0  sec: 42\n",
      "epoch: 0  batch: 101 / 226  loss: 0.0937950153383288  hr: 0  min: 0  sec: 42\n",
      "epoch: 0  batch: 102 / 226  loss: 0.09329688592868693  hr: 0  min: 0  sec: 42\n",
      "epoch: 0  batch: 103 / 226  loss: 0.09274027760601739  hr: 0  min: 0  sec: 42\n",
      "epoch: 0  batch: 104 / 226  loss: 0.09221108010611855  hr: 0  min: 0  sec: 42\n",
      "epoch: 0  batch: 105 / 226  loss: 0.09178511975776582  hr: 0  min: 0  sec: 42\n",
      "epoch: 0  batch: 106 / 226  loss: 0.09120091247671056  hr: 0  min: 0  sec: 42\n",
      "epoch: 0  batch: 107 / 226  loss: 0.09077936480535526  hr: 0  min: 0  sec: 42\n",
      "epoch: 0  batch: 108 / 226  loss: 0.0906561742088309  hr: 0  min: 0  sec: 42\n",
      "epoch: 0  batch: 109 / 226  loss: 0.09026787337770156  hr: 0  min: 0  sec: 41\n",
      "epoch: 0  batch: 110 / 226  loss: 0.08977740420536562  hr: 0  min: 0  sec: 41\n",
      "epoch: 0  batch: 111 / 226  loss: 0.08927887933211284  hr: 0  min: 0  sec: 41\n",
      "epoch: 0  batch: 112 / 226  loss: 0.0889239280950278  hr: 0  min: 0  sec: 41\n",
      "epoch: 0  batch: 113 / 226  loss: 0.08859287251809002  hr: 0  min: 0  sec: 41\n",
      "epoch: 0  batch: 114 / 226  loss: 0.08819783439761714  hr: 0  min: 0  sec: 41\n",
      "epoch: 0  batch: 115 / 226  loss: 0.08778030927414479  hr: 0  min: 0  sec: 41\n",
      "epoch: 0  batch: 116 / 226  loss: 0.08738084493911472  hr: 0  min: 0  sec: 41\n",
      "epoch: 0  batch: 117 / 226  loss: 0.08702212467025487  hr: 0  min: 0  sec: 40\n",
      "epoch: 0  batch: 118 / 226  loss: 0.0865517398816044  hr: 0  min: 0  sec: 40\n",
      "epoch: 0  batch: 119 / 226  loss: 0.08617330758887179  hr: 0  min: 0  sec: 40\n",
      "epoch: 0  batch: 120 / 226  loss: 0.08574273198222121  hr: 0  min: 0  sec: 40\n",
      "epoch: 0  batch: 121 / 226  loss: 0.08529143705040462  hr: 0  min: 0  sec: 40\n",
      "epoch: 0  batch: 122 / 226  loss: 0.08497340505423605  hr: 0  min: 0  sec: 40\n",
      "epoch: 0  batch: 123 / 226  loss: 0.0846179783253408  hr: 0  min: 0  sec: 40\n",
      "epoch: 0  batch: 124 / 226  loss: 0.08428744786989785  hr: 0  min: 0  sec: 40\n",
      "epoch: 0  batch: 125 / 226  loss: 0.08397295974195003  hr: 0  min: 0  sec: 40\n",
      "epoch: 0  batch: 126 / 226  loss: 0.0836431330720347  hr: 0  min: 0  sec: 39\n",
      "epoch: 0  batch: 127 / 226  loss: 0.0832940139551097  hr: 0  min: 0  sec: 39\n",
      "epoch: 0  batch: 128 / 226  loss: 0.08288847394578625  hr: 0  min: 0  sec: 39\n",
      "epoch: 0  batch: 129 / 226  loss: 0.08253060773650343  hr: 0  min: 0  sec: 39\n",
      "epoch: 0  batch: 130 / 226  loss: 0.0823179627983616  hr: 0  min: 0  sec: 39\n",
      "epoch: 0  batch: 131 / 226  loss: 0.08188722859925897  hr: 0  min: 0  sec: 39\n",
      "epoch: 0  batch: 132 / 226  loss: 0.08151617214422334  hr: 0  min: 0  sec: 39\n",
      "epoch: 0  batch: 133 / 226  loss: 0.08114292413780563  hr: 0  min: 0  sec: 39\n",
      "epoch: 0  batch: 134 / 226  loss: 0.08073976793006729  hr: 0  min: 0  sec: 38\n",
      "epoch: 0  batch: 135 / 226  loss: 0.0803061598153026  hr: 0  min: 0  sec: 38\n",
      "epoch: 0  batch: 136 / 226  loss: 0.0800210894907222  hr: 0  min: 0  sec: 38\n",
      "epoch: 0  batch: 137 / 226  loss: 0.07957307823056722  hr: 0  min: 0  sec: 38\n",
      "epoch: 0  batch: 138 / 226  loss: 0.07927859237120635  hr: 0  min: 0  sec: 38\n",
      "epoch: 0  batch: 139 / 226  loss: 0.07897954817405707  hr: 0  min: 0  sec: 38\n",
      "epoch: 0  batch: 140 / 226  loss: 0.07858192979225091  hr: 0  min: 0  sec: 38\n",
      "epoch: 0  batch: 141 / 226  loss: 0.0782016865142905  hr: 0  min: 0  sec: 38\n",
      "epoch: 0  batch: 142 / 226  loss: 0.07784348803664178  hr: 0  min: 0  sec: 38\n",
      "epoch: 0  batch: 143 / 226  loss: 0.0775127619036011  hr: 0  min: 0  sec: 37\n",
      "epoch: 0  batch: 144 / 226  loss: 0.07724564817423622  hr: 0  min: 0  sec: 37\n",
      "epoch: 0  batch: 145 / 226  loss: 0.07697818448831295  hr: 0  min: 0  sec: 37\n",
      "epoch: 0  batch: 146 / 226  loss: 0.0767665888910016  hr: 0  min: 0  sec: 37\n",
      "epoch: 0  batch: 147 / 226  loss: 0.07640757853938203  hr: 0  min: 0  sec: 37\n",
      "epoch: 0  batch: 148 / 226  loss: 0.07622292279139967  hr: 0  min: 0  sec: 37\n",
      "epoch: 0  batch: 149 / 226  loss: 0.07589505735359736  hr: 0  min: 0  sec: 37\n",
      "epoch: 0  batch: 150 / 226  loss: 0.07555227064838012  hr: 0  min: 0  sec: 37\n",
      "epoch: 0  batch: 151 / 226  loss: 0.07543123603508567  hr: 0  min: 0  sec: 36\n",
      "epoch: 0  batch: 152 / 226  loss: 0.07513497972027644  hr: 0  min: 0  sec: 36\n",
      "epoch: 0  batch: 153 / 226  loss: 0.07476841750877355  hr: 0  min: 0  sec: 36\n",
      "epoch: 0  batch: 154 / 226  loss: 0.0745650360288171  hr: 0  min: 0  sec: 36\n",
      "epoch: 0  batch: 155 / 226  loss: 0.07431886686432747  hr: 0  min: 0  sec: 36\n",
      "epoch: 0  batch: 156 / 226  loss: 0.07405271746504766  hr: 0  min: 0  sec: 36\n",
      "epoch: 0  batch: 157 / 226  loss: 0.07381805601962813  hr: 0  min: 0  sec: 36\n",
      "epoch: 0  batch: 158 / 226  loss: 0.07361961995499043  hr: 0  min: 0  sec: 36\n",
      "epoch: 0  batch: 159 / 226  loss: 0.07335467763104529  hr: 0  min: 0  sec: 35\n",
      "epoch: 0  batch: 160 / 226  loss: 0.0731348647037521  hr: 0  min: 0  sec: 35\n",
      "epoch: 0  batch: 161 / 226  loss: 0.07280864376829278  hr: 0  min: 0  sec: 35\n",
      "epoch: 0  batch: 162 / 226  loss: 0.07252307965155737  hr: 0  min: 0  sec: 35\n",
      "epoch: 0  batch: 163 / 226  loss: 0.07226445562451896  hr: 0  min: 0  sec: 35\n",
      "epoch: 0  batch: 164 / 226  loss: 0.07210733655204134  hr: 0  min: 0  sec: 35\n",
      "epoch: 0  batch: 165 / 226  loss: 0.07188990779898384  hr: 0  min: 0  sec: 35\n",
      "epoch: 0  batch: 166 / 226  loss: 0.07165845909930137  hr: 0  min: 0  sec: 34\n",
      "epoch: 0  batch: 167 / 226  loss: 0.07136811907152216  hr: 0  min: 0  sec: 34\n",
      "epoch: 0  batch: 168 / 226  loss: 0.07109596063604667  hr: 0  min: 0  sec: 34\n",
      "epoch: 0  batch: 169 / 226  loss: 0.07087322639731261  hr: 0  min: 0  sec: 34\n",
      "epoch: 0  batch: 170 / 226  loss: 0.07067233694388586  hr: 0  min: 0  sec: 34\n",
      "epoch: 0  batch: 171 / 226  loss: 0.07040048644425925  hr: 0  min: 0  sec: 34\n",
      "epoch: 0  batch: 172 / 226  loss: 0.07022047015773349  hr: 0  min: 0  sec: 34\n",
      "epoch: 0  batch: 173 / 226  loss: 0.06996976561585948  hr: 0  min: 0  sec: 34\n",
      "epoch: 0  batch: 174 / 226  loss: 0.06972105323668869  hr: 0  min: 0  sec: 33\n",
      "epoch: 0  batch: 175 / 226  loss: 0.06955165179712432  hr: 0  min: 0  sec: 33\n",
      "epoch: 0  batch: 176 / 226  loss: 0.06930969877761196  hr: 0  min: 0  sec: 33\n",
      "epoch: 0  batch: 177 / 226  loss: 0.0691163268171798  hr: 0  min: 0  sec: 33\n",
      "epoch: 0  batch: 178 / 226  loss: 0.06885707493494736  hr: 0  min: 0  sec: 33\n",
      "epoch: 0  batch: 179 / 226  loss: 0.0686440019238761  hr: 0  min: 0  sec: 33\n",
      "epoch: 0  batch: 180 / 226  loss: 0.06854142945052849  hr: 0  min: 0  sec: 33\n",
      "epoch: 0  batch: 181 / 226  loss: 0.06828975593105205  hr: 0  min: 0  sec: 32\n",
      "epoch: 0  batch: 182 / 226  loss: 0.06810587845169581  hr: 0  min: 0  sec: 32\n",
      "epoch: 0  batch: 183 / 226  loss: 0.06794075842926411  hr: 0  min: 0  sec: 32\n",
      "epoch: 0  batch: 184 / 226  loss: 0.06776432446001665  hr: 0  min: 0  sec: 32\n",
      "epoch: 0  batch: 185 / 226  loss: 0.06760553767954981  hr: 0  min: 0  sec: 32\n",
      "epoch: 0  batch: 186 / 226  loss: 0.06741392318039172  hr: 0  min: 0  sec: 32\n",
      "epoch: 0  batch: 187 / 226  loss: 0.06720950830986792  hr: 0  min: 0  sec: 32\n",
      "epoch: 0  batch: 188 / 226  loss: 0.06706677498097749  hr: 0  min: 0  sec: 32\n",
      "epoch: 0  batch: 189 / 226  loss: 0.06683891963351656  hr: 0  min: 0  sec: 31\n",
      "epoch: 0  batch: 190 / 226  loss: 0.06677517425268889  hr: 0  min: 0  sec: 31\n",
      "epoch: 0  batch: 191 / 226  loss: 0.06659000658513052  hr: 0  min: 0  sec: 31\n",
      "epoch: 0  batch: 192 / 226  loss: 0.06637286137750682  hr: 0  min: 0  sec: 31\n",
      "epoch: 0  batch: 193 / 226  loss: 0.06617865535802174  hr: 0  min: 0  sec: 31\n",
      "epoch: 0  batch: 194 / 226  loss: 0.06601316535595766  hr: 0  min: 0  sec: 31\n",
      "epoch: 0  batch: 195 / 226  loss: 0.06585626336626517  hr: 0  min: 0  sec: 31\n",
      "epoch: 0  batch: 196 / 226  loss: 0.0657467436881698  hr: 0  min: 0  sec: 30\n",
      "epoch: 0  batch: 197 / 226  loss: 0.06556324599320211  hr: 0  min: 0  sec: 30\n",
      "epoch: 0  batch: 198 / 226  loss: 0.06541569624096155  hr: 0  min: 0  sec: 30\n",
      "epoch: 0  batch: 199 / 226  loss: 0.06514444979534827  hr: 0  min: 0  sec: 30\n",
      "epoch: 0  batch: 200 / 226  loss: 0.06505497558508068  hr: 0  min: 0  sec: 30\n",
      "epoch: 0  batch: 201 / 226  loss: 0.06492330304889092  hr: 0  min: 0  sec: 30\n",
      "epoch: 0  batch: 202 / 226  loss: 0.06481471709851729  hr: 0  min: 0  sec: 30\n",
      "epoch: 0  batch: 203 / 226  loss: 0.06469133757330074  hr: 0  min: 0  sec: 30\n",
      "epoch: 0  batch: 204 / 226  loss: 0.06454743978603944  hr: 0  min: 0  sec: 29\n",
      "epoch: 0  batch: 205 / 226  loss: 0.06444426183020924  hr: 0  min: 0  sec: 29\n",
      "epoch: 0  batch: 206 / 226  loss: 0.06429018655755711  hr: 0  min: 0  sec: 29\n",
      "epoch: 0  batch: 207 / 226  loss: 0.06415449659191612  hr: 0  min: 0  sec: 29\n",
      "epoch: 0  batch: 208 / 226  loss: 0.06397812714567408  hr: 0  min: 0  sec: 29\n",
      "epoch: 0  batch: 209 / 226  loss: 0.06381463379327333  hr: 0  min: 0  sec: 29\n",
      "epoch: 0  batch: 210 / 226  loss: 0.06360214991672408  hr: 0  min: 0  sec: 29\n",
      "epoch: 0  batch: 211 / 226  loss: 0.06338337454415187  hr: 0  min: 0  sec: 29\n",
      "epoch: 0  batch: 212 / 226  loss: 0.06321036699227989  hr: 0  min: 0  sec: 28\n",
      "epoch: 0  batch: 213 / 226  loss: 0.0630082765489187  hr: 0  min: 0  sec: 28\n",
      "epoch: 0  batch: 214 / 226  loss: 0.06283338916722998  hr: 0  min: 0  sec: 28\n",
      "epoch: 0  batch: 215 / 226  loss: 0.06265035758098197  hr: 0  min: 0  sec: 28\n",
      "epoch: 0  batch: 216 / 226  loss: 0.06251558900759038  hr: 0  min: 0  sec: 28\n",
      "epoch: 0  batch: 217 / 226  loss: 0.06242654772586949  hr: 0  min: 0  sec: 28\n",
      "epoch: 0  batch: 218 / 226  loss: 0.06227848744190751  hr: 0  min: 0  sec: 28\n",
      "epoch: 0  batch: 219 / 226  loss: 0.062135005926874945  hr: 0  min: 0  sec: 28\n",
      "epoch: 0  batch: 220 / 226  loss: 0.06196728327142244  hr: 0  min: 0  sec: 27\n",
      "epoch: 0  batch: 221 / 226  loss: 0.06187287435289557  hr: 0  min: 0  sec: 27\n",
      "epoch: 0  batch: 222 / 226  loss: 0.06176067154166532  hr: 0  min: 0  sec: 27\n",
      "epoch: 0  batch: 223 / 226  loss: 0.06161658957416835  hr: 0  min: 0  sec: 27\n",
      "epoch: 0  batch: 224 / 226  loss: 0.06143039529394757  hr: 0  min: 0  sec: 27\n",
      "epoch: 0  batch: 225 / 226  loss: 0.061272420092589326  hr: 0  min: 0  sec: 27\n",
      "epoch: 0  batch: 226 / 226  loss: 0.06108142547226981  hr: 0  min: 0  sec: 27\n",
      "epoch: 1  batch: 1 / 226  loss: 0.02546204999089241  hr: 0  min: 0  sec: 14\n",
      "epoch: 1  batch: 2 / 226  loss: 0.021309168078005314  hr: 0  min: 0  sec: 20\n",
      "epoch: 1  batch: 3 / 226  loss: 0.02503433885673682  hr: 0  min: 0  sec: 23\n",
      "epoch: 1  batch: 4 / 226  loss: 0.025747633539140224  hr: 0  min: 0  sec: 24\n",
      "epoch: 1  batch: 5 / 226  loss: 0.022745001874864102  hr: 0  min: 0  sec: 24\n",
      "epoch: 1  batch: 6 / 226  loss: 0.022648620574424665  hr: 0  min: 0  sec: 24\n",
      "epoch: 1  batch: 7 / 226  loss: 0.022239848572228636  hr: 0  min: 0  sec: 24\n",
      "epoch: 1  batch: 8 / 226  loss: 0.022648568614386022  hr: 0  min: 0  sec: 25\n",
      "epoch: 1  batch: 9 / 226  loss: 0.022129718110793166  hr: 0  min: 0  sec: 25\n",
      "epoch: 1  batch: 10 / 226  loss: 0.021381564997136594  hr: 0  min: 0  sec: 25\n",
      "epoch: 1  batch: 11 / 226  loss: 0.020552309314635666  hr: 0  min: 0  sec: 25\n",
      "epoch: 1  batch: 12 / 226  loss: 0.019915239497398336  hr: 0  min: 0  sec: 25\n",
      "epoch: 1  batch: 13 / 226  loss: 0.01934645059876717  hr: 0  min: 0  sec: 25\n",
      "epoch: 1  batch: 14 / 226  loss: 0.019143365257020508  hr: 0  min: 0  sec: 25\n",
      "epoch: 1  batch: 15 / 226  loss: 0.019497149996459483  hr: 0  min: 0  sec: 25\n",
      "epoch: 1  batch: 16 / 226  loss: 0.02017394540598616  hr: 0  min: 0  sec: 25\n",
      "epoch: 1  batch: 17 / 226  loss: 0.02023729610749904  hr: 0  min: 0  sec: 24\n",
      "epoch: 1  batch: 18 / 226  loss: 0.02002973621711135  hr: 0  min: 0  sec: 24\n",
      "epoch: 1  batch: 19 / 226  loss: 0.02000629475438281  hr: 0  min: 0  sec: 24\n",
      "epoch: 1  batch: 20 / 226  loss: 0.020147433830425145  hr: 0  min: 0  sec: 24\n",
      "epoch: 1  batch: 21 / 226  loss: 0.020170255564153194  hr: 0  min: 0  sec: 24\n",
      "epoch: 1  batch: 22 / 226  loss: 0.020157189150764185  hr: 0  min: 0  sec: 24\n",
      "epoch: 1  batch: 23 / 226  loss: 0.020098977722227573  hr: 0  min: 0  sec: 24\n",
      "epoch: 1  batch: 24 / 226  loss: 0.02034500640972207  hr: 0  min: 0  sec: 24\n",
      "epoch: 1  batch: 25 / 226  loss: 0.020386884696781637  hr: 0  min: 0  sec: 24\n",
      "epoch: 1  batch: 26 / 226  loss: 0.020786180554960784  hr: 0  min: 0  sec: 23\n",
      "epoch: 1  batch: 27 / 226  loss: 0.020516932735012636  hr: 0  min: 0  sec: 23\n",
      "epoch: 1  batch: 28 / 226  loss: 0.020437065811295594  hr: 0  min: 0  sec: 23\n",
      "epoch: 1  batch: 29 / 226  loss: 0.0206362497511095  hr: 0  min: 0  sec: 23\n",
      "epoch: 1  batch: 30 / 226  loss: 0.020342546639343102  hr: 0  min: 0  sec: 23\n",
      "epoch: 1  batch: 31 / 226  loss: 0.020638345770778194  hr: 0  min: 0  sec: 23\n",
      "epoch: 1  batch: 32 / 226  loss: 0.02090484549989924  hr: 0  min: 0  sec: 23\n",
      "epoch: 1  batch: 33 / 226  loss: 0.020872155486634285  hr: 0  min: 0  sec: 23\n",
      "epoch: 1  batch: 34 / 226  loss: 0.020886324126930797  hr: 0  min: 0  sec: 22\n",
      "epoch: 1  batch: 35 / 226  loss: 0.02099031007715634  hr: 0  min: 0  sec: 22\n",
      "epoch: 1  batch: 36 / 226  loss: 0.021125667004121676  hr: 0  min: 0  sec: 22\n",
      "epoch: 1  batch: 37 / 226  loss: 0.02108716088775042  hr: 0  min: 0  sec: 22\n",
      "epoch: 1  batch: 38 / 226  loss: 0.020984268208083353  hr: 0  min: 0  sec: 22\n",
      "epoch: 1  batch: 39 / 226  loss: 0.020717552051139183  hr: 0  min: 0  sec: 22\n",
      "epoch: 1  batch: 40 / 226  loss: 0.02062672229949385  hr: 0  min: 0  sec: 22\n",
      "epoch: 1  batch: 41 / 226  loss: 0.02056747500035094  hr: 0  min: 0  sec: 22\n",
      "epoch: 1  batch: 42 / 226  loss: 0.020685023295560052  hr: 0  min: 0  sec: 21\n",
      "epoch: 1  batch: 43 / 226  loss: 0.020483313973040082  hr: 0  min: 0  sec: 21\n",
      "epoch: 1  batch: 44 / 226  loss: 0.020834282993085006  hr: 0  min: 0  sec: 21\n",
      "epoch: 1  batch: 45 / 226  loss: 0.020920393926401933  hr: 0  min: 0  sec: 21\n",
      "epoch: 1  batch: 46 / 226  loss: 0.020729040200619595  hr: 0  min: 0  sec: 21\n",
      "epoch: 1  batch: 47 / 226  loss: 0.020732814921660625  hr: 0  min: 0  sec: 21\n",
      "epoch: 1  batch: 48 / 226  loss: 0.02070459156918029  hr: 0  min: 0  sec: 21\n",
      "epoch: 1  batch: 49 / 226  loss: 0.02072196795928235  hr: 0  min: 0  sec: 21\n",
      "epoch: 1  batch: 50 / 226  loss: 0.020629801526665686  hr: 0  min: 0  sec: 20\n",
      "epoch: 1  batch: 51 / 226  loss: 0.020742340524699174  hr: 0  min: 0  sec: 20\n",
      "epoch: 1  batch: 52 / 226  loss: 0.020602935584835134  hr: 0  min: 0  sec: 20\n",
      "epoch: 1  batch: 53 / 226  loss: 0.02057112705946531  hr: 0  min: 0  sec: 20\n",
      "epoch: 1  batch: 54 / 226  loss: 0.020592838198084523  hr: 0  min: 0  sec: 20\n",
      "epoch: 1  batch: 55 / 226  loss: 0.020736783217977395  hr: 0  min: 0  sec: 20\n",
      "epoch: 1  batch: 56 / 226  loss: 0.020820925760615085  hr: 0  min: 0  sec: 20\n",
      "epoch: 1  batch: 57 / 226  loss: 0.020870794509455823  hr: 0  min: 0  sec: 20\n",
      "epoch: 1  batch: 58 / 226  loss: 0.0210888860907791  hr: 0  min: 0  sec: 19\n",
      "epoch: 1  batch: 59 / 226  loss: 0.02104934571721291  hr: 0  min: 0  sec: 19\n",
      "epoch: 1  batch: 60 / 226  loss: 0.020897294658546648  hr: 0  min: 0  sec: 19\n",
      "epoch: 1  batch: 61 / 226  loss: 0.02093913670262841  hr: 0  min: 0  sec: 19\n",
      "epoch: 1  batch: 62 / 226  loss: 0.020882876094190345  hr: 0  min: 0  sec: 19\n",
      "epoch: 1  batch: 63 / 226  loss: 0.020856277529327644  hr: 0  min: 0  sec: 19\n",
      "epoch: 1  batch: 64 / 226  loss: 0.02100359603355173  hr: 0  min: 0  sec: 19\n",
      "epoch: 1  batch: 65 / 226  loss: 0.020833246066020085  hr: 0  min: 0  sec: 19\n",
      "epoch: 1  batch: 66 / 226  loss: 0.02083264785169652  hr: 0  min: 0  sec: 18\n",
      "epoch: 1  batch: 67 / 226  loss: 0.0207361215308531  hr: 0  min: 0  sec: 18\n",
      "epoch: 1  batch: 68 / 226  loss: 0.02068486563203966  hr: 0  min: 0  sec: 18\n",
      "epoch: 1  batch: 69 / 226  loss: 0.020617224653993828  hr: 0  min: 0  sec: 18\n",
      "epoch: 1  batch: 70 / 226  loss: 0.02061739904539926  hr: 0  min: 0  sec: 18\n",
      "epoch: 1  batch: 71 / 226  loss: 0.020788972331604486  hr: 0  min: 0  sec: 18\n",
      "epoch: 1  batch: 72 / 226  loss: 0.020713010531229276  hr: 0  min: 0  sec: 18\n",
      "epoch: 1  batch: 73 / 226  loss: 0.0206588067701214  hr: 0  min: 0  sec: 18\n",
      "epoch: 1  batch: 74 / 226  loss: 0.020596909802407026  hr: 0  min: 0  sec: 17\n",
      "epoch: 1  batch: 75 / 226  loss: 0.020524170870582264  hr: 0  min: 0  sec: 17\n",
      "epoch: 1  batch: 76 / 226  loss: 0.0206403346291106  hr: 0  min: 0  sec: 17\n",
      "epoch: 1  batch: 77 / 226  loss: 0.020636744144094454  hr: 0  min: 0  sec: 17\n",
      "epoch: 1  batch: 78 / 226  loss: 0.020571650578998603  hr: 0  min: 0  sec: 17\n",
      "epoch: 1  batch: 79 / 226  loss: 0.02065735402269454  hr: 0  min: 0  sec: 17\n",
      "epoch: 1  batch: 80 / 226  loss: 0.020644007786177098  hr: 0  min: 0  sec: 17\n",
      "epoch: 1  batch: 81 / 226  loss: 0.020649504537383716  hr: 0  min: 0  sec: 17\n",
      "epoch: 1  batch: 82 / 226  loss: 0.02074002095202847  hr: 0  min: 0  sec: 16\n",
      "epoch: 1  batch: 83 / 226  loss: 0.020697392029575556  hr: 0  min: 0  sec: 16\n",
      "epoch: 1  batch: 84 / 226  loss: 0.020690500824933962  hr: 0  min: 0  sec: 16\n",
      "epoch: 1  batch: 85 / 226  loss: 0.020581686507691356  hr: 0  min: 0  sec: 16\n",
      "epoch: 1  batch: 86 / 226  loss: 0.020609236484783335  hr: 0  min: 0  sec: 16\n",
      "epoch: 1  batch: 87 / 226  loss: 0.02065343772671346  hr: 0  min: 0  sec: 16\n",
      "epoch: 1  batch: 88 / 226  loss: 0.020732163038866765  hr: 0  min: 0  sec: 16\n",
      "epoch: 1  batch: 89 / 226  loss: 0.02064490993245599  hr: 0  min: 0  sec: 16\n",
      "epoch: 1  batch: 90 / 226  loss: 0.020583960517413086  hr: 0  min: 0  sec: 15\n",
      "epoch: 1  batch: 91 / 226  loss: 0.020572507078503513  hr: 0  min: 0  sec: 15\n",
      "epoch: 1  batch: 92 / 226  loss: 0.020500402735627216  hr: 0  min: 0  sec: 15\n",
      "epoch: 1  batch: 93 / 226  loss: 0.020455970739324886  hr: 0  min: 0  sec: 15\n",
      "epoch: 1  batch: 94 / 226  loss: 0.02040023102048547  hr: 0  min: 0  sec: 15\n",
      "epoch: 1  batch: 95 / 226  loss: 0.020414997313759828  hr: 0  min: 0  sec: 15\n",
      "epoch: 1  batch: 96 / 226  loss: 0.020379211239439126  hr: 0  min: 0  sec: 15\n",
      "epoch: 1  batch: 97 / 226  loss: 0.02035620744272913  hr: 0  min: 0  sec: 15\n",
      "epoch: 1  batch: 98 / 226  loss: 0.020288878833228836  hr: 0  min: 0  sec: 14\n",
      "epoch: 1  batch: 99 / 226  loss: 0.020308065623270744  hr: 0  min: 0  sec: 14\n",
      "epoch: 1  batch: 100 / 226  loss: 0.020440151123329996  hr: 0  min: 0  sec: 14\n",
      "epoch: 1  batch: 101 / 226  loss: 0.020470711716109573  hr: 0  min: 0  sec: 14\n",
      "epoch: 1  batch: 102 / 226  loss: 0.020467466044732752  hr: 0  min: 0  sec: 14\n",
      "epoch: 1  batch: 103 / 226  loss: 0.020394918011519516  hr: 0  min: 0  sec: 14\n",
      "epoch: 1  batch: 104 / 226  loss: 0.020479607664478514  hr: 0  min: 0  sec: 14\n",
      "epoch: 1  batch: 105 / 226  loss: 0.020577979957063994  hr: 0  min: 0  sec: 14\n",
      "epoch: 1  batch: 106 / 226  loss: 0.020602382034203916  hr: 0  min: 0  sec: 13\n",
      "epoch: 1  batch: 107 / 226  loss: 0.020591239505839125  hr: 0  min: 0  sec: 13\n",
      "epoch: 1  batch: 108 / 226  loss: 0.020555909033174866  hr: 0  min: 0  sec: 13\n",
      "epoch: 1  batch: 109 / 226  loss: 0.020627973686664476  hr: 0  min: 0  sec: 13\n",
      "epoch: 1  batch: 110 / 226  loss: 0.020654136010191657  hr: 0  min: 0  sec: 13\n",
      "epoch: 1  batch: 111 / 226  loss: 0.020690647415346927  hr: 0  min: 0  sec: 13\n",
      "epoch: 1  batch: 112 / 226  loss: 0.02073811905990754  hr: 0  min: 0  sec: 13\n",
      "epoch: 1  batch: 113 / 226  loss: 0.0208754981909178  hr: 0  min: 0  sec: 13\n",
      "epoch: 1  batch: 114 / 226  loss: 0.02084714548433559  hr: 0  min: 0  sec: 13\n",
      "epoch: 1  batch: 115 / 226  loss: 0.020928270904266317  hr: 0  min: 0  sec: 12\n",
      "epoch: 1  batch: 116 / 226  loss: 0.02089347097830012  hr: 0  min: 0  sec: 12\n",
      "epoch: 1  batch: 117 / 226  loss: 0.02092649579111837  hr: 0  min: 0  sec: 12\n",
      "epoch: 1  batch: 118 / 226  loss: 0.02089831341941983  hr: 0  min: 0  sec: 12\n",
      "epoch: 1  batch: 119 / 226  loss: 0.020880291520171807  hr: 0  min: 0  sec: 12\n",
      "epoch: 1  batch: 120 / 226  loss: 0.020869203113640346  hr: 0  min: 0  sec: 12\n",
      "epoch: 1  batch: 121 / 226  loss: 0.020903510203169398  hr: 0  min: 0  sec: 12\n",
      "epoch: 1  batch: 122 / 226  loss: 0.0209406633235392  hr: 0  min: 0  sec: 12\n",
      "epoch: 1  batch: 123 / 226  loss: 0.02085151714159221  hr: 0  min: 0  sec: 11\n",
      "epoch: 1  batch: 124 / 226  loss: 0.020835335156129252  hr: 0  min: 0  sec: 11\n",
      "epoch: 1  batch: 125 / 226  loss: 0.020817240685224534  hr: 0  min: 0  sec: 11\n",
      "epoch: 1  batch: 126 / 226  loss: 0.020848188327536696  hr: 0  min: 0  sec: 11\n",
      "epoch: 1  batch: 127 / 226  loss: 0.020915091184415216  hr: 0  min: 0  sec: 11\n",
      "epoch: 1  batch: 128 / 226  loss: 0.02095755180926062  hr: 0  min: 0  sec: 11\n",
      "epoch: 1  batch: 129 / 226  loss: 0.020944445978763493  hr: 0  min: 0  sec: 11\n",
      "epoch: 1  batch: 130 / 226  loss: 0.0208988666606064  hr: 0  min: 0  sec: 11\n",
      "epoch: 1  batch: 131 / 226  loss: 0.02085350308112288  hr: 0  min: 0  sec: 11\n",
      "epoch: 1  batch: 132 / 226  loss: 0.020850019522406386  hr: 0  min: 0  sec: 10\n",
      "epoch: 1  batch: 133 / 226  loss: 0.020858306472742914  hr: 0  min: 0  sec: 10\n",
      "epoch: 1  batch: 134 / 226  loss: 0.02080989024365571  hr: 0  min: 0  sec: 10\n",
      "epoch: 1  batch: 135 / 226  loss: 0.02083353269155379  hr: 0  min: 0  sec: 10\n",
      "epoch: 1  batch: 136 / 226  loss: 0.02080905349815593  hr: 0  min: 0  sec: 10\n",
      "epoch: 1  batch: 137 / 226  loss: 0.020775885300805968  hr: 0  min: 0  sec: 10\n",
      "epoch: 1  batch: 138 / 226  loss: 0.020860049320195896  hr: 0  min: 0  sec: 10\n",
      "epoch: 1  batch: 139 / 226  loss: 0.0208762245480534  hr: 0  min: 0  sec: 10\n",
      "epoch: 1  batch: 140 / 226  loss: 0.020879509526171854  hr: 0  min: 0  sec: 9\n",
      "epoch: 1  batch: 141 / 226  loss: 0.020941583875645983  hr: 0  min: 0  sec: 9\n",
      "epoch: 1  batch: 142 / 226  loss: 0.020879380509886945  hr: 0  min: 0  sec: 9\n",
      "epoch: 1  batch: 143 / 226  loss: 0.020894990869231158  hr: 0  min: 0  sec: 9\n",
      "epoch: 1  batch: 144 / 226  loss: 0.020852736682475854  hr: 0  min: 0  sec: 9\n",
      "epoch: 1  batch: 145 / 226  loss: 0.020818379412180392  hr: 0  min: 0  sec: 9\n",
      "epoch: 1  batch: 146 / 226  loss: 0.02079722376489272  hr: 0  min: 0  sec: 9\n",
      "epoch: 1  batch: 147 / 226  loss: 0.020801092624714992  hr: 0  min: 0  sec: 9\n",
      "epoch: 1  batch: 148 / 226  loss: 0.020799968989465286  hr: 0  min: 0  sec: 9\n",
      "epoch: 1  batch: 149 / 226  loss: 0.020832935541918212  hr: 0  min: 0  sec: 8\n",
      "epoch: 1  batch: 150 / 226  loss: 0.02090373114372293  hr: 0  min: 0  sec: 8\n",
      "epoch: 1  batch: 151 / 226  loss: 0.0208652438534214  hr: 0  min: 0  sec: 8\n",
      "epoch: 1  batch: 152 / 226  loss: 0.02081451387340693  hr: 0  min: 0  sec: 8\n",
      "epoch: 1  batch: 153 / 226  loss: 0.020839853893989832  hr: 0  min: 0  sec: 8\n",
      "epoch: 1  batch: 154 / 226  loss: 0.02092260331544396  hr: 0  min: 0  sec: 8\n",
      "epoch: 1  batch: 155 / 226  loss: 0.020961034093653002  hr: 0  min: 0  sec: 8\n",
      "epoch: 1  batch: 156 / 226  loss: 0.02094444436713671  hr: 0  min: 0  sec: 8\n",
      "epoch: 1  batch: 157 / 226  loss: 0.02089389067760129  hr: 0  min: 0  sec: 7\n",
      "epoch: 1  batch: 158 / 226  loss: 0.020845073192745825  hr: 0  min: 0  sec: 7\n",
      "epoch: 1  batch: 159 / 226  loss: 0.020804414021893865  hr: 0  min: 0  sec: 7\n",
      "epoch: 1  batch: 160 / 226  loss: 0.020736972586018965  hr: 0  min: 0  sec: 7\n",
      "epoch: 1  batch: 161 / 226  loss: 0.020696901513830475  hr: 0  min: 0  sec: 7\n",
      "epoch: 1  batch: 162 / 226  loss: 0.02065987093374133  hr: 0  min: 0  sec: 7\n",
      "epoch: 1  batch: 163 / 226  loss: 0.020737820990566463  hr: 0  min: 0  sec: 7\n",
      "epoch: 1  batch: 164 / 226  loss: 0.020697091291545004  hr: 0  min: 0  sec: 7\n",
      "epoch: 1  batch: 165 / 226  loss: 0.02070517757286628  hr: 0  min: 0  sec: 7\n",
      "epoch: 1  batch: 166 / 226  loss: 0.020657868449946482  hr: 0  min: 0  sec: 6\n",
      "epoch: 1  batch: 167 / 226  loss: 0.0206741725769407  hr: 0  min: 0  sec: 6\n",
      "epoch: 1  batch: 168 / 226  loss: 0.020666023084361638  hr: 0  min: 0  sec: 6\n",
      "epoch: 1  batch: 169 / 226  loss: 0.020641106836630042  hr: 0  min: 0  sec: 6\n",
      "epoch: 1  batch: 170 / 226  loss: 0.020656997852903956  hr: 0  min: 0  sec: 6\n",
      "epoch: 1  batch: 171 / 226  loss: 0.020654046537670476  hr: 0  min: 0  sec: 6\n",
      "epoch: 1  batch: 172 / 226  loss: 0.02068455948299447  hr: 0  min: 0  sec: 6\n",
      "epoch: 1  batch: 173 / 226  loss: 0.02074755260968484  hr: 0  min: 0  sec: 6\n",
      "epoch: 1  batch: 174 / 226  loss: 0.020694406028708506  hr: 0  min: 0  sec: 5\n",
      "epoch: 1  batch: 175 / 226  loss: 0.02067864236022745  hr: 0  min: 0  sec: 5\n",
      "epoch: 1  batch: 176 / 226  loss: 0.020654262784360486  hr: 0  min: 0  sec: 5\n",
      "epoch: 1  batch: 177 / 226  loss: 0.02064627978298287  hr: 0  min: 0  sec: 5\n",
      "epoch: 1  batch: 178 / 226  loss: 0.02063057502585181  hr: 0  min: 0  sec: 5\n",
      "epoch: 1  batch: 179 / 226  loss: 0.020589174177268698  hr: 0  min: 0  sec: 5\n",
      "epoch: 1  batch: 180 / 226  loss: 0.02064283719389803  hr: 0  min: 0  sec: 5\n",
      "epoch: 1  batch: 181 / 226  loss: 0.020651492104963375  hr: 0  min: 0  sec: 5\n",
      "epoch: 1  batch: 182 / 226  loss: 0.020683614368253684  hr: 0  min: 0  sec: 5\n",
      "epoch: 1  batch: 183 / 226  loss: 0.02073777078706873  hr: 0  min: 0  sec: 4\n",
      "epoch: 1  batch: 184 / 226  loss: 0.02072012614276584  hr: 0  min: 0  sec: 4\n",
      "epoch: 1  batch: 185 / 226  loss: 0.020725048106868524  hr: 0  min: 0  sec: 4\n",
      "epoch: 1  batch: 186 / 226  loss: 0.020745446920515068  hr: 0  min: 0  sec: 4\n",
      "epoch: 1  batch: 187 / 226  loss: 0.02077823603914224  hr: 0  min: 0  sec: 4\n",
      "epoch: 1  batch: 188 / 226  loss: 0.020838189468857772  hr: 0  min: 0  sec: 4\n",
      "epoch: 1  batch: 189 / 226  loss: 0.020922476056194496  hr: 0  min: 0  sec: 4\n",
      "epoch: 1  batch: 190 / 226  loss: 0.020864583512670114  hr: 0  min: 0  sec: 4\n",
      "epoch: 1  batch: 191 / 226  loss: 0.020815760097149468  hr: 0  min: 0  sec: 4\n",
      "epoch: 1  batch: 192 / 226  loss: 0.02081044790005156  hr: 0  min: 0  sec: 3\n",
      "epoch: 1  batch: 193 / 226  loss: 0.020773676740382  hr: 0  min: 0  sec: 3\n",
      "epoch: 1  batch: 194 / 226  loss: 0.02073310083738461  hr: 0  min: 0  sec: 3\n",
      "epoch: 1  batch: 195 / 226  loss: 0.020775643311058863  hr: 0  min: 0  sec: 3\n",
      "epoch: 1  batch: 196 / 226  loss: 0.020745499724788324  hr: 0  min: 0  sec: 3\n",
      "epoch: 1  batch: 197 / 226  loss: 0.0207196322416291  hr: 0  min: 0  sec: 3\n",
      "epoch: 1  batch: 198 / 226  loss: 0.020738026983283385  hr: 0  min: 0  sec: 3\n",
      "epoch: 1  batch: 199 / 226  loss: 0.020733354893985704  hr: 0  min: 0  sec: 3\n",
      "epoch: 1  batch: 200 / 226  loss: 0.020756224701181054  hr: 0  min: 0  sec: 2\n",
      "epoch: 1  batch: 201 / 226  loss: 0.020740595243092793  hr: 0  min: 0  sec: 2\n",
      "epoch: 1  batch: 202 / 226  loss: 0.02072066476218181  hr: 0  min: 0  sec: 2\n",
      "epoch: 1  batch: 203 / 226  loss: 0.020686617992781653  hr: 0  min: 0  sec: 2\n",
      "epoch: 1  batch: 204 / 226  loss: 0.020682002253392163  hr: 0  min: 0  sec: 2\n",
      "epoch: 1  batch: 205 / 226  loss: 0.020668829523208664  hr: 0  min: 0  sec: 2\n",
      "epoch: 1  batch: 206 / 226  loss: 0.020707244803966247  hr: 0  min: 0  sec: 2\n",
      "epoch: 1  batch: 207 / 226  loss: 0.020671711078336562  hr: 0  min: 0  sec: 2\n",
      "epoch: 1  batch: 208 / 226  loss: 0.02063261875614094  hr: 0  min: 0  sec: 2\n",
      "epoch: 1  batch: 209 / 226  loss: 0.020636576584330872  hr: 0  min: 0  sec: 1\n",
      "epoch: 1  batch: 210 / 226  loss: 0.020686867305388053  hr: 0  min: 0  sec: 1\n",
      "epoch: 1  batch: 211 / 226  loss: 0.02070464930492696  hr: 0  min: 0  sec: 1\n",
      "epoch: 1  batch: 212 / 226  loss: 0.02066729146600613  hr: 0  min: 0  sec: 1\n",
      "epoch: 1  batch: 213 / 226  loss: 0.020651259411458678  hr: 0  min: 0  sec: 1\n",
      "epoch: 1  batch: 214 / 226  loss: 0.020644025563775936  hr: 0  min: 0  sec: 1\n",
      "epoch: 1  batch: 215 / 226  loss: 0.020636859917363456  hr: 0  min: 0  sec: 1\n",
      "epoch: 1  batch: 216 / 226  loss: 0.020622437569761166  hr: 0  min: 0  sec: 1\n",
      "epoch: 1  batch: 217 / 226  loss: 0.020587328310695388  hr: 0  min: 0  sec: 1\n",
      "epoch: 1  batch: 218 / 226  loss: 0.020616046892086026  hr: 0  min: 0  sec: 0\n",
      "epoch: 1  batch: 219 / 226  loss: 0.02060000546973998  hr: 0  min: 0  sec: 0\n",
      "epoch: 1  batch: 220 / 226  loss: 0.020546121497384526  hr: 0  min: 0  sec: 0\n",
      "epoch: 1  batch: 221 / 226  loss: 0.020537020234028678  hr: 0  min: 0  sec: 0\n",
      "epoch: 1  batch: 222 / 226  loss: 0.020551240130386374  hr: 0  min: 0  sec: 0\n",
      "epoch: 1  batch: 223 / 226  loss: 0.020532192161198153  hr: 0  min: 0  sec: 0\n",
      "epoch: 1  batch: 224 / 226  loss: 0.020499538463939513  hr: 0  min: 0  sec: 0\n",
      "epoch: 1  batch: 225 / 226  loss: 0.020461808281640213  hr: 0  min: 0  sec: 0\n",
      "epoch: 1  batch: 226 / 226  loss: 0.02040286692873105  hr: 0  min: 0  sec: 0\n"
     ]
    }
   ],
   "source": [
    "train_model_ATE(train_loader, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ATE = load_model(model_ATE, 'models/bert_ATE.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 12 s\n",
      "Wall time: 12 s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99    116071\n",
      "           1       0.72      0.76      0.74      1791\n",
      "           2       0.60      0.57      0.58       410\n",
      "\n",
      "    accuracy                           0.99    118272\n",
      "   macro avg       0.77      0.77      0.77    118272\n",
      "weighted avg       0.99      0.99      0.99    118272\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%time x, y = test_model_ATE(test_loader)\n",
    "print(classification_report(x, y, target_names=[str(i) for i in range(3)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aspect polarity classification (APC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = dataset_APC(pd.read_csv(\"dataset/arabic_train.csv\"), tokenizer)\n",
    "test_ds = dataset_APC(pd.read_csv(\"dataset/arabic_test.csv\"), tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[cls]', 'ساو', '##صي', 'بالت', '##اكيد', 'بموقع', 'المدينه', 'القديمه', 'الا', 'انه', 'عليك', 'الحذر', 'من', 'الاسعار', 'السياحي', '##ه', 'الاكثر', 'ارتفاعا', '.', '[sep]', 'المدينه', 'القديمه', 'الاسعار', 'السياحي', '##ه']\n",
      "25\n",
      "tensor([    1, 23065,  3389,  2619, 23131, 19176,  8322, 15121,  1915,  2615,\n",
      "         2898, 17133,  1908,  9384, 13931,  1028,  9442, 23596,    18,     1,\n",
      "         8322, 15121,  9384, 13931,  1028])\n",
      "25\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
      "        1])\n",
      "25\n",
      "tensor(2)\n"
     ]
    }
   ],
   "source": [
    "w,x,y,z = train_ds.__getitem__(3)\n",
    "print(w)\n",
    "print(len(w))\n",
    "print(x)\n",
    "print(len(x))\n",
    "print(y)\n",
    "print(len(y))\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mini_batch2(samples):\n",
    "    ids_tensors = [s[1] for s in samples]\n",
    "    ids_tensors = torch.Tensor(pad_features(ids_tensors, 128)).long()\n",
    "\n",
    "    segments_tensors = [s[2] for s in samples]\n",
    "    segments_tensors = torch.Tensor(pad_features(segments_tensors, 128)).long()\n",
    "\n",
    "    label_ids = torch.stack([s[3] for s in samples])\n",
    "\n",
    "    masks_tensors = torch.zeros(ids_tensors.shape, dtype=torch.long)\n",
    "    masks_tensors = masks_tensors.masked_fill(ids_tensors != 0, 1)\n",
    "\n",
    "    return ids_tensors, segments_tensors, masks_tensors, label_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_ds, batch_size=16, collate_fn=create_mini_batch2, shuffle = True)\n",
    "test_loader = DataLoader(test_ds, batch_size=50, collate_fn=create_mini_batch2, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for batch in train_loader:\n",
    "#     w,x,y,z = batch\n",
    "#     print(w)\n",
    "#     print(w.size())\n",
    "#     print(x)\n",
    "#     print(x.size())\n",
    "#     print(y)\n",
    "#     print(y.size())\n",
    "#     print(z)\n",
    "#     print(z.size())\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_APC(loader, epochs):\n",
    "    all_data = len(loader)\n",
    "    for epoch in range(epochs):\n",
    "        finish_data = 0\n",
    "        losses = []\n",
    "        current_times = []\n",
    "        correct_predictions = 0\n",
    "        \n",
    "        for data in loader:\n",
    "            t0 = time.time()\n",
    "            ids_tensors, segments_tensors, masks_tensors, label_ids = data\n",
    "            ids_tensors = ids_tensors.to(DEVICE)\n",
    "            segments_tensors = segments_tensors.to(DEVICE)\n",
    "            label_ids = label_ids.to(DEVICE)\n",
    "            masks_tensors = masks_tensors.to(DEVICE)\n",
    "\n",
    "            loss = model_APC(ids_tensors=ids_tensors, lable_tensors=label_ids, masks_tensors=masks_tensors, segments_tensors=segments_tensors)\n",
    "            losses.append(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer_APC.step()\n",
    "            optimizer_APC.zero_grad()\n",
    "\n",
    "            finish_data += 1\n",
    "            current_times.append(round(time.time()-t0,3))\n",
    "            current = np.mean(current_times)\n",
    "            hr, min, sec = evl_time(current*(all_data-finish_data) + current*all_data*(epochs-epoch-1))\n",
    "            print('epoch:', epoch, \" batch:\", finish_data, \"/\" , all_data, \" loss:\", np.mean(losses), \" hr:\", hr, \" min:\", min,\" sec:\", sec)         \n",
    "\n",
    "        save_model(model_APC, 'models/bert_APC.pt')\n",
    "        \n",
    "def test_model_APC(loader):\n",
    "    pred = []\n",
    "    trueth = []\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "\n",
    "            ids_tensors, segments_tensors, masks_tensors, label_ids = data\n",
    "            ids_tensors = ids_tensors.to(DEVICE)\n",
    "            segments_tensors = segments_tensors.to(DEVICE)\n",
    "            masks_tensors = masks_tensors.to(DEVICE)\n",
    "\n",
    "            outputs = model_APC(ids_tensors, None, masks_tensors=masks_tensors, segments_tensors=segments_tensors)\n",
    "            \n",
    "            _, predictions = torch.max(outputs, dim=1)\n",
    "\n",
    "            pred += list([int(i) for i in predictions])\n",
    "            trueth += list([int(i) for i in label_ids])\n",
    "\n",
    "    return trueth, pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2.59 s\n",
      "Wall time: 2.59 s\n",
      "learning rate: 0.0001\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.91      0.92       464\n",
      "           1       0.44      0.22      0.29        50\n",
      "           2       0.85      0.92      0.88       410\n",
      "\n",
      "    accuracy                           0.88       924\n",
      "   macro avg       0.74      0.68      0.70       924\n",
      "weighted avg       0.87      0.88      0.87       924\n",
      "\n",
      "CPU times: total: 2.58 s\n",
      "Wall time: 2.58 s\n",
      "learning rate: 0.0002\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.83      0.86       464\n",
      "           1       0.00      0.00      0.00        50\n",
      "           2       0.77      0.92      0.84       410\n",
      "\n",
      "    accuracy                           0.83       924\n",
      "   macro avg       0.55      0.58      0.57       924\n",
      "weighted avg       0.79      0.83      0.80       924\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\meshari\\nexus_ai\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\meshari\\nexus_ai\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\meshari\\nexus_ai\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2.53 s\n",
      "Wall time: 2.53 s\n",
      "learning rate: 0.0003\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       464\n",
      "           1       0.00      0.00      0.00        50\n",
      "           2       0.44      1.00      0.61       410\n",
      "\n",
      "    accuracy                           0.44       924\n",
      "   macro avg       0.15      0.33      0.20       924\n",
      "weighted avg       0.20      0.44      0.27       924\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\meshari\\nexus_ai\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\meshari\\nexus_ai\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\meshari\\nexus_ai\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2.52 s\n",
      "Wall time: 2.5 s\n",
      "learning rate: 0.0004\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67       464\n",
      "           1       0.00      0.00      0.00        50\n",
      "           2       0.00      0.00      0.00       410\n",
      "\n",
      "    accuracy                           0.50       924\n",
      "   macro avg       0.17      0.33      0.22       924\n",
      "weighted avg       0.25      0.50      0.34       924\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\meshari\\nexus_ai\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\meshari\\nexus_ai\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\meshari\\nexus_ai\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2.5 s\n",
      "Wall time: 2.5 s\n",
      "learning rate: 0.0005\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       464\n",
      "           1       0.00      0.00      0.00        50\n",
      "           2       0.44      1.00      0.61       410\n",
      "\n",
      "    accuracy                           0.44       924\n",
      "   macro avg       0.15      0.33      0.20       924\n",
      "weighted avg       0.20      0.44      0.27       924\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\meshari\\nexus_ai\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\meshari\\nexus_ai\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\meshari\\nexus_ai\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2.52 s\n",
      "Wall time: 2.51 s\n",
      "learning rate: 0.0006\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67       464\n",
      "           1       0.00      0.00      0.00        50\n",
      "           2       0.00      0.00      0.00       410\n",
      "\n",
      "    accuracy                           0.50       924\n",
      "   macro avg       0.17      0.33      0.22       924\n",
      "weighted avg       0.25      0.50      0.34       924\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\meshari\\nexus_ai\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\meshari\\nexus_ai\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\meshari\\nexus_ai\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2.52 s\n",
      "Wall time: 2.51 s\n",
      "learning rate: 0.0007\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       464\n",
      "           1       0.00      0.00      0.00        50\n",
      "           2       0.44      1.00      0.61       410\n",
      "\n",
      "    accuracy                           0.44       924\n",
      "   macro avg       0.15      0.33      0.20       924\n",
      "weighted avg       0.20      0.44      0.27       924\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\meshari\\nexus_ai\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\meshari\\nexus_ai\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\meshari\\nexus_ai\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2.5 s\n",
      "Wall time: 2.5 s\n",
      "learning rate: 0.0008\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       464\n",
      "           1       0.00      0.00      0.00        50\n",
      "           2       0.44      1.00      0.61       410\n",
      "\n",
      "    accuracy                           0.44       924\n",
      "   macro avg       0.15      0.33      0.20       924\n",
      "weighted avg       0.20      0.44      0.27       924\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\meshari\\nexus_ai\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\meshari\\nexus_ai\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\meshari\\nexus_ai\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2.5 s\n",
      "Wall time: 2.51 s\n",
      "learning rate: 0.0009\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       464\n",
      "           1       0.00      0.00      0.00        50\n",
      "           2       0.44      1.00      0.61       410\n",
      "\n",
      "    accuracy                           0.44       924\n",
      "   macro avg       0.15      0.33      0.20       924\n",
      "weighted avg       0.20      0.44      0.27       924\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\meshari\\nexus_ai\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\meshari\\nexus_ai\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\meshari\\nexus_ai\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2.5 s\n",
      "Wall time: 2.51 s\n",
      "learning rate: 1e-05\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.94      0.91       464\n",
      "           1       0.00      0.00      0.00        50\n",
      "           2       0.87      0.91      0.89       410\n",
      "\n",
      "    accuracy                           0.88       924\n",
      "   macro avg       0.58      0.62      0.60       924\n",
      "weighted avg       0.83      0.88      0.85       924\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\meshari\\nexus_ai\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\meshari\\nexus_ai\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\meshari\\nexus_ai\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2.52 s\n",
      "Wall time: 2.5 s\n",
      "learning rate: 2e-05\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.92       464\n",
      "           1       0.28      0.32      0.30        50\n",
      "           2       0.90      0.88      0.89       410\n",
      "\n",
      "    accuracy                           0.87       924\n",
      "   macro avg       0.70      0.71      0.70       924\n",
      "weighted avg       0.87      0.87      0.87       924\n",
      "\n",
      "CPU times: total: 2.5 s\n",
      "Wall time: 2.51 s\n",
      "learning rate: 3e-05\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92       464\n",
      "           1       0.34      0.20      0.25        50\n",
      "           2       0.88      0.89      0.88       410\n",
      "\n",
      "    accuracy                           0.88       924\n",
      "   macro avg       0.71      0.68      0.69       924\n",
      "weighted avg       0.86      0.88      0.87       924\n",
      "\n",
      "CPU times: total: 2.52 s\n",
      "Wall time: 2.5 s\n",
      "learning rate: 4e-05\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       464\n",
      "           1       0.00      0.00      0.00        50\n",
      "           2       0.87      0.92      0.89       410\n",
      "\n",
      "    accuracy                           0.88       924\n",
      "   macro avg       0.59      0.62      0.61       924\n",
      "weighted avg       0.84      0.88      0.86       924\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\meshari\\nexus_ai\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\meshari\\nexus_ai\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\meshari\\nexus_ai\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2.5 s\n",
      "Wall time: 2.5 s\n",
      "learning rate: 5e-05\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92       464\n",
      "           1       0.29      0.04      0.07        50\n",
      "           2       0.88      0.92      0.90       410\n",
      "\n",
      "    accuracy                           0.88       924\n",
      "   macro avg       0.69      0.63      0.63       924\n",
      "weighted avg       0.86      0.88      0.86       924\n",
      "\n",
      "CPU times: total: 2.52 s\n",
      "Wall time: 2.52 s\n",
      "learning rate: 6e-05\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.88      0.89       464\n",
      "           1       0.25      0.02      0.04        50\n",
      "           2       0.81      0.93      0.87       410\n",
      "\n",
      "    accuracy                           0.86       924\n",
      "   macro avg       0.66      0.61      0.60       924\n",
      "weighted avg       0.83      0.86      0.84       924\n",
      "\n",
      "CPU times: total: 2.5 s\n",
      "Wall time: 2.5 s\n",
      "learning rate: 7e-05\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.89      0.91       464\n",
      "           1       0.00      0.00      0.00        50\n",
      "           2       0.81      0.95      0.87       410\n",
      "\n",
      "    accuracy                           0.87       924\n",
      "   macro avg       0.58      0.61      0.60       924\n",
      "weighted avg       0.83      0.87      0.85       924\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\meshari\\nexus_ai\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\meshari\\nexus_ai\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\meshari\\nexus_ai\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2.48 s\n",
      "Wall time: 2.49 s\n",
      "learning rate: 8e-05\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92       464\n",
      "           1       0.34      0.32      0.33        50\n",
      "           2       0.90      0.86      0.88       410\n",
      "\n",
      "    accuracy                           0.87       924\n",
      "   macro avg       0.71      0.71      0.71       924\n",
      "weighted avg       0.87      0.87      0.87       924\n",
      "\n",
      "CPU times: total: 2.52 s\n",
      "Wall time: 2.52 s\n",
      "learning rate: 9e-05\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.85      0.89       464\n",
      "           1       0.29      0.10      0.15        50\n",
      "           2       0.80      0.94      0.86       410\n",
      "\n",
      "    accuracy                           0.85       924\n",
      "   macro avg       0.67      0.63      0.63       924\n",
      "weighted avg       0.84      0.85      0.84       924\n",
      "\n",
      "CPU times: total: 2.59 s\n",
      "Wall time: 2.59 s\n",
      "learning rate: 1e-06\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.87      0.85       464\n",
      "           1       0.00      0.00      0.00        50\n",
      "           2       0.80      0.87      0.83       410\n",
      "\n",
      "    accuracy                           0.82       924\n",
      "   macro avg       0.55      0.58      0.56       924\n",
      "weighted avg       0.78      0.82      0.80       924\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\meshari\\nexus_ai\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\meshari\\nexus_ai\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\meshari\\nexus_ai\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2.56 s\n",
      "Wall time: 2.56 s\n",
      "learning rate: 2e-06\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.91      0.88       464\n",
      "           1       0.00      0.00      0.00        50\n",
      "           2       0.84      0.88      0.86       410\n",
      "\n",
      "    accuracy                           0.85       924\n",
      "   macro avg       0.56      0.60      0.58       924\n",
      "weighted avg       0.80      0.85      0.82       924\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\meshari\\nexus_ai\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\meshari\\nexus_ai\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\meshari\\nexus_ai\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2.56 s\n",
      "Wall time: 2.58 s\n",
      "learning rate: 3e-06\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.91      0.88       464\n",
      "           1       0.00      0.00      0.00        50\n",
      "           2       0.84      0.89      0.86       410\n",
      "\n",
      "    accuracy                           0.85       924\n",
      "   macro avg       0.57      0.60      0.58       924\n",
      "weighted avg       0.80      0.85      0.82       924\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\meshari\\nexus_ai\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\meshari\\nexus_ai\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\meshari\\nexus_ai\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2.5 s\n",
      "Wall time: 2.49 s\n",
      "learning rate: 4e-06\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.90      0.89       464\n",
      "           1       0.00      0.00      0.00        50\n",
      "           2       0.83      0.91      0.87       410\n",
      "\n",
      "    accuracy                           0.86       924\n",
      "   macro avg       0.57      0.60      0.59       924\n",
      "weighted avg       0.81      0.86      0.83       924\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\meshari\\nexus_ai\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\meshari\\nexus_ai\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\meshari\\nexus_ai\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2.42 s\n",
      "Wall time: 2.42 s\n",
      "learning rate: 5e-06\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.88      0.89       464\n",
      "           1       0.00      0.00      0.00        50\n",
      "           2       0.81      0.93      0.87       410\n",
      "\n",
      "    accuracy                           0.86       924\n",
      "   macro avg       0.57      0.60      0.59       924\n",
      "weighted avg       0.81      0.86      0.83       924\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\meshari\\nexus_ai\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\meshari\\nexus_ai\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\meshari\\nexus_ai\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2.42 s\n",
      "Wall time: 2.43 s\n",
      "learning rate: 6e-06\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.90      0.88       464\n",
      "           1       0.00      0.00      0.00        50\n",
      "           2       0.84      0.89      0.86       410\n",
      "\n",
      "    accuracy                           0.85       924\n",
      "   macro avg       0.56      0.60      0.58       924\n",
      "weighted avg       0.80      0.85      0.82       924\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\meshari\\nexus_ai\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\meshari\\nexus_ai\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\meshari\\nexus_ai\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2.44 s\n",
      "Wall time: 2.43 s\n",
      "learning rate: 7e-06\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.91      0.90       464\n",
      "           1       0.50      0.06      0.11        50\n",
      "           2       0.85      0.92      0.88       410\n",
      "\n",
      "    accuracy                           0.87       924\n",
      "   macro avg       0.75      0.63      0.63       924\n",
      "weighted avg       0.85      0.87      0.85       924\n",
      "\n",
      "CPU times: total: 2.42 s\n",
      "Wall time: 2.43 s\n",
      "learning rate: 8e-06\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.91      0.90       464\n",
      "           1       0.24      0.08      0.12        50\n",
      "           2       0.86      0.90      0.88       410\n",
      "\n",
      "    accuracy                           0.86       924\n",
      "   macro avg       0.66      0.63      0.63       924\n",
      "weighted avg       0.84      0.86      0.85       924\n",
      "\n",
      "CPU times: total: 2.5 s\n",
      "Wall time: 2.5 s\n",
      "learning rate: 9e-06\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.95      0.92       464\n",
      "           1       0.44      0.08      0.14        50\n",
      "           2       0.89      0.91      0.90       410\n",
      "\n",
      "    accuracy                           0.89       924\n",
      "   macro avg       0.74      0.65      0.65       924\n",
      "weighted avg       0.87      0.89      0.87       924\n",
      "\n"
     ]
    }
   ],
   "source": [
    "set_seed(12)\n",
    "lr_list = [\n",
    "    1e-4, 2e-4, 3e-4, 4e-4, 5e-4, 6e-4, 7e-4, 8e-4, 9e-4,\n",
    "    1e-5, 2e-5, 3e-5, 4e-5, 5e-5, 6e-5, 7e-5, 8e-5, 9e-5,\n",
    "    1e-6, 2e-6, 3e-6, 4e-6, 5e-6, 6e-6, 7e-6, 8e-6, 9e-6,\n",
    "]\n",
    "for lr in lr_list:\n",
    "    torch.cuda.empty_cache()\n",
    "    with io.capture_output() as captured:\n",
    "        model_APC = bert_APC(pretrain_model_name).to(DEVICE)\n",
    "        optimizer_APC = torch.optim.AdamW(model_APC.parameters(), lr=lr)\n",
    "        train_model_APC(train_loader, 2)\n",
    "    %time x, y = test_model_APC(test_loader)\n",
    "    print(f'learning rate: {lr}')\n",
    "    print(classification_report(x, y, target_names=[str(i) for i in range(3)]))\n",
    "    torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 2e-5\n",
    "model_APC = bert_APC(pretrain_model_name).to(DEVICE) \n",
    "optimizer_APC = torch.optim.AdamW(model_APC.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0  batch: 1 / 226  loss: 1.1813442707061768  hr: 0  min: 16  sec: 10\n",
      "epoch: 0  batch: 2 / 226  loss: 1.093517005443573  hr: 0  min: 9  sec: 3\n",
      "epoch: 0  batch: 3 / 226  loss: 1.0027076800664265  hr: 0  min: 6  sec: 44\n",
      "epoch: 0  batch: 4 / 226  loss: 0.9596229046583176  hr: 0  min: 5  sec: 34\n",
      "epoch: 0  batch: 5 / 226  loss: 0.9134316563606262  hr: 0  min: 4  sec: 52\n",
      "epoch: 0  batch: 6 / 226  loss: 0.8612467845280966  hr: 0  min: 4  sec: 24\n",
      "epoch: 0  batch: 7 / 226  loss: 0.8169203911508832  hr: 0  min: 4  sec: 4\n",
      "epoch: 0  batch: 8 / 226  loss: 0.8205685019493103  hr: 0  min: 3  sec: 48\n",
      "epoch: 0  batch: 9 / 226  loss: 0.8196925123532613  hr: 0  min: 3  sec: 36\n",
      "epoch: 0  batch: 10 / 226  loss: 0.7957261741161347  hr: 0  min: 3  sec: 26\n",
      "epoch: 0  batch: 11 / 226  loss: 0.7882357022979043  hr: 0  min: 3  sec: 18\n",
      "epoch: 0  batch: 12 / 226  loss: 0.7562475477655729  hr: 0  min: 3  sec: 11\n",
      "epoch: 0  batch: 13 / 226  loss: 0.7399227504546826  hr: 0  min: 3  sec: 6\n",
      "epoch: 0  batch: 14 / 226  loss: 0.704680112855775  hr: 0  min: 3  sec: 1\n",
      "epoch: 0  batch: 15 / 226  loss: 0.6883827884991963  hr: 0  min: 2  sec: 57\n",
      "epoch: 0  batch: 16 / 226  loss: 0.6659338399767876  hr: 0  min: 2  sec: 53\n",
      "epoch: 0  batch: 17 / 226  loss: 0.6594919807770673  hr: 0  min: 2  sec: 49\n",
      "epoch: 0  batch: 18 / 226  loss: 0.642423775460985  hr: 0  min: 2  sec: 46\n",
      "epoch: 0  batch: 19 / 226  loss: 0.6480203365024767  hr: 0  min: 2  sec: 44\n",
      "epoch: 0  batch: 20 / 226  loss: 0.6439020365476609  hr: 0  min: 2  sec: 41\n",
      "epoch: 0  batch: 21 / 226  loss: 0.6315959933258238  hr: 0  min: 2  sec: 39\n",
      "epoch: 0  batch: 22 / 226  loss: 0.6398414116014134  hr: 0  min: 2  sec: 37\n",
      "epoch: 0  batch: 23 / 226  loss: 0.645386225503424  hr: 0  min: 2  sec: 35\n",
      "epoch: 0  batch: 24 / 226  loss: 0.6247978626439968  hr: 0  min: 2  sec: 33\n",
      "epoch: 0  batch: 25 / 226  loss: 0.621519359946251  hr: 0  min: 2  sec: 31\n",
      "epoch: 0  batch: 26 / 226  loss: 0.6180214669841987  hr: 0  min: 2  sec: 30\n",
      "epoch: 0  batch: 27 / 226  loss: 0.6138659202390246  hr: 0  min: 2  sec: 28\n",
      "epoch: 0  batch: 28 / 226  loss: 0.6187729532165187  hr: 0  min: 2  sec: 27\n",
      "epoch: 0  batch: 29 / 226  loss: 0.6030268617745104  hr: 0  min: 2  sec: 26\n",
      "epoch: 0  batch: 30 / 226  loss: 0.5992985417445501  hr: 0  min: 2  sec: 24\n",
      "epoch: 0  batch: 31 / 226  loss: 0.5997314366602129  hr: 0  min: 2  sec: 23\n",
      "epoch: 0  batch: 32 / 226  loss: 0.6042358530685306  hr: 0  min: 2  sec: 22\n",
      "epoch: 0  batch: 33 / 226  loss: 0.6076208488507704  hr: 0  min: 2  sec: 21\n",
      "epoch: 0  batch: 34 / 226  loss: 0.6019334617783042  hr: 0  min: 2  sec: 20\n",
      "epoch: 0  batch: 35 / 226  loss: 0.5963643380573818  hr: 0  min: 2  sec: 20\n",
      "epoch: 0  batch: 36 / 226  loss: 0.5998168637355169  hr: 0  min: 2  sec: 18\n",
      "epoch: 0  batch: 37 / 226  loss: 0.5921423636578225  hr: 0  min: 2  sec: 17\n",
      "epoch: 0  batch: 38 / 226  loss: 0.6004771143198013  hr: 0  min: 2  sec: 16\n",
      "epoch: 0  batch: 39 / 226  loss: 0.6025415406777308  hr: 0  min: 2  sec: 15\n",
      "epoch: 0  batch: 40 / 226  loss: 0.6062287263572216  hr: 0  min: 2  sec: 14\n",
      "epoch: 0  batch: 41 / 226  loss: 0.6051390251008476  hr: 0  min: 2  sec: 13\n",
      "epoch: 0  batch: 42 / 226  loss: 0.6001211631865728  hr: 0  min: 2  sec: 12\n",
      "epoch: 0  batch: 43 / 226  loss: 0.5915838888911313  hr: 0  min: 2  sec: 11\n",
      "epoch: 0  batch: 44 / 226  loss: 0.594159838150848  hr: 0  min: 2  sec: 9\n",
      "epoch: 0  batch: 45 / 226  loss: 0.594437172015508  hr: 0  min: 2  sec: 8\n",
      "epoch: 0  batch: 46 / 226  loss: 0.5893108248710632  hr: 0  min: 2  sec: 7\n",
      "epoch: 0  batch: 47 / 226  loss: 0.5912562038036103  hr: 0  min: 2  sec: 7\n",
      "epoch: 0  batch: 48 / 226  loss: 0.587906718874971  hr: 0  min: 2  sec: 6\n",
      "epoch: 0  batch: 49 / 226  loss: 0.5842016813706379  hr: 0  min: 2  sec: 5\n",
      "epoch: 0  batch: 50 / 226  loss: 0.5813222056627274  hr: 0  min: 2  sec: 4\n",
      "epoch: 0  batch: 51 / 226  loss: 0.5841005076380337  hr: 0  min: 2  sec: 3\n",
      "epoch: 0  batch: 52 / 226  loss: 0.5853148188728553  hr: 0  min: 2  sec: 2\n",
      "epoch: 0  batch: 53 / 226  loss: 0.5823069715274954  hr: 0  min: 2  sec: 1\n",
      "epoch: 0  batch: 54 / 226  loss: 0.5808315635831268  hr: 0  min: 2  sec: 0\n",
      "epoch: 0  batch: 55 / 226  loss: 0.5746027055111799  hr: 0  min: 2  sec: 0\n",
      "epoch: 0  batch: 56 / 226  loss: 0.5702962148934603  hr: 0  min: 1  sec: 59\n",
      "epoch: 0  batch: 57 / 226  loss: 0.5639188754976842  hr: 0  min: 1  sec: 58\n",
      "epoch: 0  batch: 58 / 226  loss: 0.5613592554782999  hr: 0  min: 1  sec: 58\n",
      "epoch: 0  batch: 59 / 226  loss: 0.56043446266045  hr: 0  min: 1  sec: 57\n",
      "epoch: 0  batch: 60 / 226  loss: 0.5644144763549169  hr: 0  min: 1  sec: 56\n",
      "epoch: 0  batch: 61 / 226  loss: 0.5579777247593051  hr: 0  min: 1  sec: 56\n",
      "epoch: 0  batch: 62 / 226  loss: 0.5544439506146216  hr: 0  min: 1  sec: 55\n",
      "epoch: 0  batch: 63 / 226  loss: 0.5473262485530641  hr: 0  min: 1  sec: 54\n",
      "epoch: 0  batch: 64 / 226  loss: 0.5458375287707895  hr: 0  min: 1  sec: 54\n",
      "epoch: 0  batch: 65 / 226  loss: 0.540758111843696  hr: 0  min: 1  sec: 53\n",
      "epoch: 0  batch: 66 / 226  loss: 0.5458410228743698  hr: 0  min: 1  sec: 52\n",
      "epoch: 0  batch: 67 / 226  loss: 0.5423290987512959  hr: 0  min: 1  sec: 52\n",
      "epoch: 0  batch: 68 / 226  loss: 0.5409740814391304  hr: 0  min: 1  sec: 51\n",
      "epoch: 0  batch: 69 / 226  loss: 0.5429650398268215  hr: 0  min: 1  sec: 51\n",
      "epoch: 0  batch: 70 / 226  loss: 0.552255529165268  hr: 0  min: 1  sec: 50\n",
      "epoch: 0  batch: 71 / 226  loss: 0.5537645371866898  hr: 0  min: 1  sec: 49\n",
      "epoch: 0  batch: 72 / 226  loss: 0.5506148222419951  hr: 0  min: 1  sec: 49\n",
      "epoch: 0  batch: 73 / 226  loss: 0.5501378162266457  hr: 0  min: 1  sec: 48\n",
      "epoch: 0  batch: 74 / 226  loss: 0.5497379858751554  hr: 0  min: 1  sec: 48\n",
      "epoch: 0  batch: 75 / 226  loss: 0.549580697218577  hr: 0  min: 1  sec: 47\n",
      "epoch: 0  batch: 76 / 226  loss: 0.5460878783150723  hr: 0  min: 1  sec: 47\n",
      "epoch: 0  batch: 77 / 226  loss: 0.5425966482657891  hr: 0  min: 1  sec: 46\n",
      "epoch: 0  batch: 78 / 226  loss: 0.5403160930444033  hr: 0  min: 1  sec: 46\n",
      "epoch: 0  batch: 79 / 226  loss: 0.5382170556466791  hr: 0  min: 1  sec: 45\n",
      "epoch: 0  batch: 80 / 226  loss: 0.5388027682900429  hr: 0  min: 1  sec: 45\n",
      "epoch: 0  batch: 81 / 226  loss: 0.5362854412308445  hr: 0  min: 1  sec: 44\n",
      "epoch: 0  batch: 82 / 226  loss: 0.538014614363996  hr: 0  min: 1  sec: 44\n",
      "epoch: 0  batch: 83 / 226  loss: 0.5388982723276299  hr: 0  min: 1  sec: 43\n",
      "epoch: 0  batch: 84 / 226  loss: 0.5350489320144767  hr: 0  min: 1  sec: 43\n",
      "epoch: 0  batch: 85 / 226  loss: 0.5348033983917797  hr: 0  min: 1  sec: 42\n",
      "epoch: 0  batch: 86 / 226  loss: 0.5311211054754812  hr: 0  min: 1  sec: 42\n",
      "epoch: 0  batch: 87 / 226  loss: 0.5277860570570518  hr: 0  min: 1  sec: 41\n",
      "epoch: 0  batch: 88 / 226  loss: 0.5330140423029661  hr: 0  min: 1  sec: 41\n",
      "epoch: 0  batch: 89 / 226  loss: 0.5319866784168094  hr: 0  min: 1  sec: 41\n",
      "epoch: 0  batch: 90 / 226  loss: 0.5354568440053198  hr: 0  min: 1  sec: 40\n",
      "epoch: 0  batch: 91 / 226  loss: 0.5325837444800597  hr: 0  min: 1  sec: 40\n",
      "epoch: 0  batch: 92 / 226  loss: 0.5366417683013107  hr: 0  min: 1  sec: 39\n",
      "epoch: 0  batch: 93 / 226  loss: 0.5392328213940385  hr: 0  min: 1  sec: 39\n",
      "epoch: 0  batch: 94 / 226  loss: 0.5400437891800353  hr: 0  min: 1  sec: 38\n",
      "epoch: 0  batch: 95 / 226  loss: 0.5394010379126197  hr: 0  min: 1  sec: 38\n",
      "epoch: 0  batch: 96 / 226  loss: 0.5410518650896847  hr: 0  min: 1  sec: 38\n",
      "epoch: 0  batch: 97 / 226  loss: 0.5395330136891493  hr: 0  min: 1  sec: 37\n",
      "epoch: 0  batch: 98 / 226  loss: 0.5371249134139139  hr: 0  min: 1  sec: 37\n",
      "epoch: 0  batch: 99 / 226  loss: 0.5362288101453974  hr: 0  min: 1  sec: 36\n",
      "epoch: 0  batch: 100 / 226  loss: 0.5363003830611706  hr: 0  min: 1  sec: 36\n",
      "epoch: 0  batch: 101 / 226  loss: 0.5367376206829997  hr: 0  min: 1  sec: 35\n",
      "epoch: 0  batch: 102 / 226  loss: 0.5374496022568029  hr: 0  min: 1  sec: 35\n",
      "epoch: 0  batch: 103 / 226  loss: 0.5370099002007142  hr: 0  min: 1  sec: 35\n",
      "epoch: 0  batch: 104 / 226  loss: 0.5386649388819933  hr: 0  min: 1  sec: 34\n",
      "epoch: 0  batch: 105 / 226  loss: 0.5380036165316899  hr: 0  min: 1  sec: 34\n",
      "epoch: 0  batch: 106 / 226  loss: 0.5358804114303499  hr: 0  min: 1  sec: 34\n",
      "epoch: 0  batch: 107 / 226  loss: 0.5350031778912678  hr: 0  min: 1  sec: 33\n",
      "epoch: 0  batch: 108 / 226  loss: 0.5319891425746458  hr: 0  min: 1  sec: 33\n",
      "epoch: 0  batch: 109 / 226  loss: 0.531891666147687  hr: 0  min: 1  sec: 32\n",
      "epoch: 0  batch: 110 / 226  loss: 0.5311618043617768  hr: 0  min: 1  sec: 32\n",
      "epoch: 0  batch: 111 / 226  loss: 0.5303369975304818  hr: 0  min: 1  sec: 32\n",
      "epoch: 0  batch: 112 / 226  loss: 0.5330503907586847  hr: 0  min: 1  sec: 31\n",
      "epoch: 0  batch: 113 / 226  loss: 0.5348460046590957  hr: 0  min: 1  sec: 31\n",
      "epoch: 0  batch: 114 / 226  loss: 0.5329143705598095  hr: 0  min: 1  sec: 31\n",
      "epoch: 0  batch: 115 / 226  loss: 0.5309794812098794  hr: 0  min: 1  sec: 30\n",
      "epoch: 0  batch: 116 / 226  loss: 0.5304242724488522  hr: 0  min: 1  sec: 30\n",
      "epoch: 0  batch: 117 / 226  loss: 0.5292015006909003  hr: 0  min: 1  sec: 30\n",
      "epoch: 0  batch: 118 / 226  loss: 0.5273157148543051  hr: 0  min: 1  sec: 29\n",
      "epoch: 0  batch: 119 / 226  loss: 0.5257431196064508  hr: 0  min: 1  sec: 29\n",
      "epoch: 0  batch: 120 / 226  loss: 0.5248975858092308  hr: 0  min: 1  sec: 29\n",
      "epoch: 0  batch: 121 / 226  loss: 0.5213332531496513  hr: 0  min: 1  sec: 28\n",
      "epoch: 0  batch: 122 / 226  loss: 0.5193115600430575  hr: 0  min: 1  sec: 28\n",
      "epoch: 0  batch: 123 / 226  loss: 0.5186823246076824  hr: 0  min: 1  sec: 28\n",
      "epoch: 0  batch: 124 / 226  loss: 0.519129315030671  hr: 0  min: 1  sec: 27\n",
      "epoch: 0  batch: 125 / 226  loss: 0.5168350736498832  hr: 0  min: 1  sec: 27\n",
      "epoch: 0  batch: 126 / 226  loss: 0.5179505733152231  hr: 0  min: 1  sec: 27\n",
      "epoch: 0  batch: 127 / 226  loss: 0.5165125917144647  hr: 0  min: 1  sec: 26\n",
      "epoch: 0  batch: 128 / 226  loss: 0.5173431888106279  hr: 0  min: 1  sec: 26\n",
      "epoch: 0  batch: 129 / 226  loss: 0.516740979785605  hr: 0  min: 1  sec: 26\n",
      "epoch: 0  batch: 130 / 226  loss: 0.5153250072437984  hr: 0  min: 1  sec: 25\n",
      "epoch: 0  batch: 131 / 226  loss: 0.5151808950623483  hr: 0  min: 1  sec: 25\n",
      "epoch: 0  batch: 132 / 226  loss: 0.51324687689317  hr: 0  min: 1  sec: 25\n",
      "epoch: 0  batch: 133 / 226  loss: 0.5149406048476248  hr: 0  min: 1  sec: 24\n",
      "epoch: 0  batch: 134 / 226  loss: 0.5134561317069317  hr: 0  min: 1  sec: 24\n",
      "epoch: 0  batch: 135 / 226  loss: 0.5157727614045143  hr: 0  min: 1  sec: 24\n",
      "epoch: 0  batch: 136 / 226  loss: 0.5140178899883348  hr: 0  min: 1  sec: 23\n",
      "epoch: 0  batch: 137 / 226  loss: 0.5137330865229133  hr: 0  min: 1  sec: 23\n",
      "epoch: 0  batch: 138 / 226  loss: 0.5144028453615265  hr: 0  min: 1  sec: 23\n",
      "epoch: 0  batch: 139 / 226  loss: 0.5148327433698469  hr: 0  min: 1  sec: 22\n",
      "epoch: 0  batch: 140 / 226  loss: 0.513382004786815  hr: 0  min: 1  sec: 22\n",
      "epoch: 0  batch: 141 / 226  loss: 0.51171884273595  hr: 0  min: 1  sec: 22\n",
      "epoch: 0  batch: 142 / 226  loss: 0.5110725153394988  hr: 0  min: 1  sec: 21\n",
      "epoch: 0  batch: 143 / 226  loss: 0.5105654261224754  hr: 0  min: 1  sec: 21\n",
      "epoch: 0  batch: 144 / 226  loss: 0.5085688202848865  hr: 0  min: 1  sec: 21\n",
      "epoch: 0  batch: 145 / 226  loss: 0.5079928723388705  hr: 0  min: 1  sec: 20\n",
      "epoch: 0  batch: 146 / 226  loss: 0.5076320604612566  hr: 0  min: 1  sec: 20\n",
      "epoch: 0  batch: 147 / 226  loss: 0.5064870263544881  hr: 0  min: 1  sec: 20\n",
      "epoch: 0  batch: 148 / 226  loss: 0.5042070099530188  hr: 0  min: 1  sec: 19\n",
      "epoch: 0  batch: 149 / 226  loss: 0.503077400560747  hr: 0  min: 1  sec: 19\n",
      "epoch: 0  batch: 150 / 226  loss: 0.5025890643894673  hr: 0  min: 1  sec: 19\n",
      "epoch: 0  batch: 151 / 226  loss: 0.5023387930547165  hr: 0  min: 1  sec: 18\n",
      "epoch: 0  batch: 152 / 226  loss: 0.5020678623236323  hr: 0  min: 1  sec: 18\n",
      "epoch: 0  batch: 153 / 226  loss: 0.5013376358969539  hr: 0  min: 1  sec: 18\n",
      "epoch: 0  batch: 154 / 226  loss: 0.4996230250538944  hr: 0  min: 1  sec: 18\n",
      "epoch: 0  batch: 155 / 226  loss: 0.5015464083321632  hr: 0  min: 1  sec: 17\n",
      "epoch: 0  batch: 156 / 226  loss: 0.500778656023053  hr: 0  min: 1  sec: 17\n",
      "epoch: 0  batch: 157 / 226  loss: 0.5005088619840373  hr: 0  min: 1  sec: 17\n",
      "epoch: 0  batch: 158 / 226  loss: 0.4985144627339478  hr: 0  min: 1  sec: 16\n",
      "epoch: 0  batch: 159 / 226  loss: 0.499512162457847  hr: 0  min: 1  sec: 16\n",
      "epoch: 0  batch: 160 / 226  loss: 0.4982405232731253  hr: 0  min: 1  sec: 16\n",
      "epoch: 0  batch: 161 / 226  loss: 0.4976777832793153  hr: 0  min: 1  sec: 15\n",
      "epoch: 0  batch: 162 / 226  loss: 0.4953946804650772  hr: 0  min: 1  sec: 15\n",
      "epoch: 0  batch: 163 / 226  loss: 0.4939027608263712  hr: 0  min: 1  sec: 15\n",
      "epoch: 0  batch: 164 / 226  loss: 0.4926479497424713  hr: 0  min: 1  sec: 14\n",
      "epoch: 0  batch: 165 / 226  loss: 0.49279126276572544  hr: 0  min: 1  sec: 14\n",
      "epoch: 0  batch: 166 / 226  loss: 0.49328335028994513  hr: 0  min: 1  sec: 14\n",
      "epoch: 0  batch: 167 / 226  loss: 0.4928740035006386  hr: 0  min: 1  sec: 14\n",
      "epoch: 0  batch: 168 / 226  loss: 0.4916726164963274  hr: 0  min: 1  sec: 13\n",
      "epoch: 0  batch: 169 / 226  loss: 0.49013926366553506  hr: 0  min: 1  sec: 13\n",
      "epoch: 0  batch: 170 / 226  loss: 0.48970031304394496  hr: 0  min: 1  sec: 13\n",
      "epoch: 0  batch: 171 / 226  loss: 0.4886869725863836  hr: 0  min: 1  sec: 13\n",
      "epoch: 0  batch: 172 / 226  loss: 0.4865684936386208  hr: 0  min: 1  sec: 12\n",
      "epoch: 0  batch: 173 / 226  loss: 0.4850425982923177  hr: 0  min: 1  sec: 12\n",
      "epoch: 0  batch: 174 / 226  loss: 0.4844369664788246  hr: 0  min: 1  sec: 12\n",
      "epoch: 0  batch: 175 / 226  loss: 0.48267414918967655  hr: 0  min: 1  sec: 12\n",
      "epoch: 0  batch: 176 / 226  loss: 0.4847514894367619  hr: 0  min: 1  sec: 11\n",
      "epoch: 0  batch: 177 / 226  loss: 0.4831565648822461  hr: 0  min: 1  sec: 11\n",
      "epoch: 0  batch: 178 / 226  loss: 0.4831642232249292  hr: 0  min: 1  sec: 11\n",
      "epoch: 0  batch: 179 / 226  loss: 0.48189352744118463  hr: 0  min: 1  sec: 11\n",
      "epoch: 0  batch: 180 / 226  loss: 0.4820275157690048  hr: 0  min: 1  sec: 11\n",
      "epoch: 0  batch: 181 / 226  loss: 0.48176875941002567  hr: 0  min: 1  sec: 10\n",
      "epoch: 0  batch: 182 / 226  loss: 0.48192275700333354  hr: 0  min: 1  sec: 10\n",
      "epoch: 0  batch: 183 / 226  loss: 0.4804794838031133  hr: 0  min: 1  sec: 10\n",
      "epoch: 0  batch: 184 / 226  loss: 0.480260099162874  hr: 0  min: 1  sec: 9\n",
      "epoch: 0  batch: 185 / 226  loss: 0.47796106503621955  hr: 0  min: 1  sec: 9\n",
      "epoch: 0  batch: 186 / 226  loss: 0.4778060182848925  hr: 0  min: 1  sec: 9\n",
      "epoch: 0  batch: 187 / 226  loss: 0.4779290761300587  hr: 0  min: 1  sec: 9\n",
      "epoch: 0  batch: 188 / 226  loss: 0.4776575186864493  hr: 0  min: 1  sec: 8\n",
      "epoch: 0  batch: 189 / 226  loss: 0.47764276421417007  hr: 0  min: 1  sec: 8\n",
      "epoch: 0  batch: 190 / 226  loss: 0.4773098335846474  hr: 0  min: 1  sec: 8\n",
      "epoch: 0  batch: 191 / 226  loss: 0.47566413828683773  hr: 0  min: 1  sec: 7\n",
      "epoch: 0  batch: 192 / 226  loss: 0.47459998055516434  hr: 0  min: 1  sec: 7\n",
      "epoch: 0  batch: 193 / 226  loss: 0.4736701322265857  hr: 0  min: 1  sec: 7\n",
      "epoch: 0  batch: 194 / 226  loss: 0.4725642426649934  hr: 0  min: 1  sec: 7\n",
      "epoch: 0  batch: 195 / 226  loss: 0.47468896473829564  hr: 0  min: 1  sec: 6\n",
      "epoch: 0  batch: 196 / 226  loss: 0.4743035742442827  hr: 0  min: 1  sec: 6\n",
      "epoch: 0  batch: 197 / 226  loss: 0.4737336630672973  hr: 0  min: 1  sec: 6\n",
      "epoch: 0  batch: 198 / 226  loss: 0.4746148680722473  hr: 0  min: 1  sec: 5\n",
      "epoch: 0  batch: 199 / 226  loss: 0.47371858219854796  hr: 0  min: 1  sec: 5\n",
      "epoch: 0  batch: 200 / 226  loss: 0.47330713700503113  hr: 0  min: 1  sec: 5\n",
      "epoch: 0  batch: 201 / 226  loss: 0.47274251256267824  hr: 0  min: 1  sec: 5\n",
      "epoch: 0  batch: 202 / 226  loss: 0.4719650687483868  hr: 0  min: 1  sec: 4\n",
      "epoch: 0  batch: 203 / 226  loss: 0.4712439961547922  hr: 0  min: 1  sec: 4\n",
      "epoch: 0  batch: 204 / 226  loss: 0.4695788506856736  hr: 0  min: 1  sec: 4\n",
      "epoch: 0  batch: 205 / 226  loss: 0.46798922895658307  hr: 0  min: 1  sec: 3\n",
      "epoch: 0  batch: 206 / 226  loss: 0.466744750991319  hr: 0  min: 1  sec: 3\n",
      "epoch: 0  batch: 207 / 226  loss: 0.46505467579272636  hr: 0  min: 1  sec: 3\n",
      "epoch: 0  batch: 208 / 226  loss: 0.46712229021180135  hr: 0  min: 1  sec: 3\n",
      "epoch: 0  batch: 209 / 226  loss: 0.4660461625556626  hr: 0  min: 1  sec: 2\n",
      "epoch: 0  batch: 210 / 226  loss: 0.4653970263543583  hr: 0  min: 1  sec: 2\n",
      "epoch: 0  batch: 211 / 226  loss: 0.46374108970730227  hr: 0  min: 1  sec: 2\n",
      "epoch: 0  batch: 212 / 226  loss: 0.4628239841253128  hr: 0  min: 1  sec: 1\n",
      "epoch: 0  batch: 213 / 226  loss: 0.461549741841258  hr: 0  min: 1  sec: 1\n",
      "epoch: 0  batch: 214 / 226  loss: 0.4598253831685146  hr: 0  min: 1  sec: 1\n",
      "epoch: 0  batch: 215 / 226  loss: 0.45948037962580834  hr: 0  min: 1  sec: 1\n",
      "epoch: 0  batch: 216 / 226  loss: 0.45945923071768546  hr: 0  min: 1  sec: 0\n",
      "epoch: 0  batch: 217 / 226  loss: 0.4603600583043516  hr: 0  min: 1  sec: 0\n",
      "epoch: 0  batch: 218 / 226  loss: 0.45923456064331425  hr: 0  min: 1  sec: 0\n",
      "epoch: 0  batch: 219 / 226  loss: 0.45896399109603064  hr: 0  min: 1  sec: 0\n",
      "epoch: 0  batch: 220 / 226  loss: 0.45847091952508146  hr: 0  min: 0  sec: 59\n",
      "epoch: 0  batch: 221 / 226  loss: 0.45704269328268404  hr: 0  min: 0  sec: 59\n",
      "epoch: 0  batch: 222 / 226  loss: 0.4570179911884102  hr: 0  min: 0  sec: 59\n",
      "epoch: 0  batch: 223 / 226  loss: 0.45552374863571116  hr: 0  min: 0  sec: 58\n",
      "epoch: 0  batch: 224 / 226  loss: 0.45469737112788217  hr: 0  min: 0  sec: 58\n",
      "epoch: 0  batch: 225 / 226  loss: 0.4539974092774921  hr: 0  min: 0  sec: 58\n",
      "epoch: 0  batch: 226 / 226  loss: 0.45220934757880404  hr: 0  min: 0  sec: 58\n",
      "epoch: 1  batch: 1 / 226  loss: 0.34664157032966614  hr: 0  min: 0  sec: 22\n",
      "epoch: 1  batch: 2 / 226  loss: 0.3457190841436386  hr: 0  min: 0  sec: 38\n",
      "epoch: 1  batch: 3 / 226  loss: 0.30099717279275257  hr: 0  min: 0  sec: 43\n",
      "epoch: 1  batch: 4 / 226  loss: 0.2734641432762146  hr: 0  min: 0  sec: 45\n",
      "epoch: 1  batch: 5 / 226  loss: 0.2608581006526947  hr: 0  min: 0  sec: 46\n",
      "epoch: 1  batch: 6 / 226  loss: 0.2837957739830017  hr: 0  min: 0  sec: 47\n",
      "epoch: 1  batch: 7 / 226  loss: 0.26549805275031496  hr: 0  min: 0  sec: 48\n",
      "epoch: 1  batch: 8 / 226  loss: 0.27798922546207905  hr: 0  min: 0  sec: 48\n",
      "epoch: 1  batch: 9 / 226  loss: 0.2763703746928109  hr: 0  min: 0  sec: 48\n",
      "epoch: 1  batch: 10 / 226  loss: 0.28969436436891555  hr: 0  min: 0  sec: 48\n",
      "epoch: 1  batch: 11 / 226  loss: 0.2971799766475504  hr: 0  min: 0  sec: 48\n",
      "epoch: 1  batch: 12 / 226  loss: 0.27885407333572704  hr: 0  min: 0  sec: 48\n",
      "epoch: 1  batch: 13 / 226  loss: 0.26486351971442884  hr: 0  min: 0  sec: 48\n",
      "epoch: 1  batch: 14 / 226  loss: 0.2654034931744848  hr: 0  min: 0  sec: 48\n",
      "epoch: 1  batch: 15 / 226  loss: 0.2511014404396216  hr: 0  min: 0  sec: 48\n",
      "epoch: 1  batch: 16 / 226  loss: 0.2510276467073709  hr: 0  min: 0  sec: 48\n",
      "epoch: 1  batch: 17 / 226  loss: 0.25144414275008087  hr: 0  min: 0  sec: 48\n",
      "epoch: 1  batch: 18 / 226  loss: 0.25180728174746037  hr: 0  min: 0  sec: 48\n",
      "epoch: 1  batch: 19 / 226  loss: 0.25164820116601494  hr: 0  min: 0  sec: 48\n",
      "epoch: 1  batch: 20 / 226  loss: 0.2576739514246583  hr: 0  min: 0  sec: 48\n",
      "epoch: 1  batch: 21 / 226  loss: 0.25492023020273163  hr: 0  min: 0  sec: 48\n",
      "epoch: 1  batch: 22 / 226  loss: 0.2531258919360963  hr: 0  min: 0  sec: 49\n",
      "epoch: 1  batch: 23 / 226  loss: 0.2585422262225462  hr: 0  min: 0  sec: 49\n",
      "epoch: 1  batch: 24 / 226  loss: 0.27042604936286807  hr: 0  min: 0  sec: 49\n",
      "epoch: 1  batch: 25 / 226  loss: 0.2719151647388935  hr: 0  min: 0  sec: 49\n",
      "epoch: 1  batch: 26 / 226  loss: 0.26450573036877006  hr: 0  min: 0  sec: 49\n",
      "epoch: 1  batch: 27 / 226  loss: 0.2639420061475701  hr: 0  min: 0  sec: 49\n",
      "epoch: 1  batch: 28 / 226  loss: 0.26338009496352505  hr: 0  min: 0  sec: 49\n",
      "epoch: 1  batch: 29 / 226  loss: 0.2591080718256276  hr: 0  min: 0  sec: 49\n",
      "epoch: 1  batch: 30 / 226  loss: 0.25646906259159247  hr: 0  min: 0  sec: 48\n",
      "epoch: 1  batch: 31 / 226  loss: 0.26278851457661195  hr: 0  min: 0  sec: 48\n",
      "epoch: 1  batch: 32 / 226  loss: 0.2623972330475226  hr: 0  min: 0  sec: 48\n",
      "epoch: 1  batch: 33 / 226  loss: 0.25681457137971214  hr: 0  min: 0  sec: 48\n",
      "epoch: 1  batch: 34 / 226  loss: 0.26171748986577287  hr: 0  min: 0  sec: 48\n",
      "epoch: 1  batch: 35 / 226  loss: 0.25848499781319073  hr: 0  min: 0  sec: 48\n",
      "epoch: 1  batch: 36 / 226  loss: 0.26072543931918013  hr: 0  min: 0  sec: 48\n",
      "epoch: 1  batch: 37 / 226  loss: 0.26525569757496986  hr: 0  min: 0  sec: 48\n",
      "epoch: 1  batch: 38 / 226  loss: 0.2631146761735803  hr: 0  min: 0  sec: 47\n",
      "epoch: 1  batch: 39 / 226  loss: 0.26037019519851756  hr: 0  min: 0  sec: 47\n",
      "epoch: 1  batch: 40 / 226  loss: 0.25848580403253435  hr: 0  min: 0  sec: 47\n",
      "epoch: 1  batch: 41 / 226  loss: 0.26616275119708804  hr: 0  min: 0  sec: 47\n",
      "epoch: 1  batch: 42 / 226  loss: 0.264035028627231  hr: 0  min: 0  sec: 47\n",
      "epoch: 1  batch: 43 / 226  loss: 0.2756340263714624  hr: 0  min: 0  sec: 47\n",
      "epoch: 1  batch: 44 / 226  loss: 0.27134437833658676  hr: 0  min: 0  sec: 46\n",
      "epoch: 1  batch: 45 / 226  loss: 0.26812471590108344  hr: 0  min: 0  sec: 46\n",
      "epoch: 1  batch: 46 / 226  loss: 0.2657114456043295  hr: 0  min: 0  sec: 46\n",
      "epoch: 1  batch: 47 / 226  loss: 0.26101424394452827  hr: 0  min: 0  sec: 46\n",
      "epoch: 1  batch: 48 / 226  loss: 0.25997761411902803  hr: 0  min: 0  sec: 46\n",
      "epoch: 1  batch: 49 / 226  loss: 0.2570092332150255  hr: 0  min: 0  sec: 45\n",
      "epoch: 1  batch: 50 / 226  loss: 0.25360071547329427  hr: 0  min: 0  sec: 45\n",
      "epoch: 1  batch: 51 / 226  loss: 0.25151897126845285  hr: 0  min: 0  sec: 45\n",
      "epoch: 1  batch: 52 / 226  loss: 0.24941583185528332  hr: 0  min: 0  sec: 45\n",
      "epoch: 1  batch: 53 / 226  loss: 0.2500792913982328  hr: 0  min: 0  sec: 45\n",
      "epoch: 1  batch: 54 / 226  loss: 0.25071140771938694  hr: 0  min: 0  sec: 44\n",
      "epoch: 1  batch: 55 / 226  loss: 0.25091330659660427  hr: 0  min: 0  sec: 44\n",
      "epoch: 1  batch: 56 / 226  loss: 0.25182293175852727  hr: 0  min: 0  sec: 44\n",
      "epoch: 1  batch: 57 / 226  loss: 0.24914178311040527  hr: 0  min: 0  sec: 44\n",
      "epoch: 1  batch: 58 / 226  loss: 0.2453657621838923  hr: 0  min: 0  sec: 43\n",
      "epoch: 1  batch: 59 / 226  loss: 0.24421124078207096  hr: 0  min: 0  sec: 43\n",
      "epoch: 1  batch: 60 / 226  loss: 0.24416301591942707  hr: 0  min: 0  sec: 43\n",
      "epoch: 1  batch: 61 / 226  loss: 0.24119192319082433  hr: 0  min: 0  sec: 43\n",
      "epoch: 1  batch: 62 / 226  loss: 0.24017757808248844  hr: 0  min: 0  sec: 42\n",
      "epoch: 1  batch: 63 / 226  loss: 0.2425134296100291  hr: 0  min: 0  sec: 42\n",
      "epoch: 1  batch: 64 / 226  loss: 0.2417619748157449  hr: 0  min: 0  sec: 42\n",
      "epoch: 1  batch: 65 / 226  loss: 0.23889369844244077  hr: 0  min: 0  sec: 42\n",
      "epoch: 1  batch: 66 / 226  loss: 0.23947394452989101  hr: 0  min: 0  sec: 41\n",
      "epoch: 1  batch: 67 / 226  loss: 0.24414449057249882  hr: 0  min: 0  sec: 41\n",
      "epoch: 1  batch: 68 / 226  loss: 0.24712473521118655  hr: 0  min: 0  sec: 41\n",
      "epoch: 1  batch: 69 / 226  loss: 0.2442090330456478  hr: 0  min: 0  sec: 41\n",
      "epoch: 1  batch: 70 / 226  loss: 0.24103263624544655  hr: 0  min: 0  sec: 41\n",
      "epoch: 1  batch: 71 / 226  loss: 0.24087522050339571  hr: 0  min: 0  sec: 40\n",
      "epoch: 1  batch: 72 / 226  loss: 0.23827401044157645  hr: 0  min: 0  sec: 40\n",
      "epoch: 1  batch: 73 / 226  loss: 0.24387585210983884  hr: 0  min: 0  sec: 40\n",
      "epoch: 1  batch: 74 / 226  loss: 0.24598249785501408  hr: 0  min: 0  sec: 40\n",
      "epoch: 1  batch: 75 / 226  loss: 0.24579307230810324  hr: 0  min: 0  sec: 39\n",
      "epoch: 1  batch: 76 / 226  loss: 0.2448178448616282  hr: 0  min: 0  sec: 39\n",
      "epoch: 1  batch: 77 / 226  loss: 0.2440687066984254  hr: 0  min: 0  sec: 39\n",
      "epoch: 1  batch: 78 / 226  loss: 0.24515291831145683  hr: 0  min: 0  sec: 39\n",
      "epoch: 1  batch: 79 / 226  loss: 0.2449707595655058  hr: 0  min: 0  sec: 38\n",
      "epoch: 1  batch: 80 / 226  loss: 0.2442371127428487  hr: 0  min: 0  sec: 38\n",
      "epoch: 1  batch: 81 / 226  loss: 0.2457488114129246  hr: 0  min: 0  sec: 38\n",
      "epoch: 1  batch: 82 / 226  loss: 0.2444347104330252  hr: 0  min: 0  sec: 38\n",
      "epoch: 1  batch: 83 / 226  loss: 0.2418561354055103  hr: 0  min: 0  sec: 37\n",
      "epoch: 1  batch: 84 / 226  loss: 0.24495421409873025  hr: 0  min: 0  sec: 37\n",
      "epoch: 1  batch: 85 / 226  loss: 0.24578339271247387  hr: 0  min: 0  sec: 37\n",
      "epoch: 1  batch: 86 / 226  loss: 0.2448039114431933  hr: 0  min: 0  sec: 37\n",
      "epoch: 1  batch: 87 / 226  loss: 0.24522874485059032  hr: 0  min: 0  sec: 36\n",
      "epoch: 1  batch: 88 / 226  loss: 0.24430016163651916  hr: 0  min: 0  sec: 36\n",
      "epoch: 1  batch: 89 / 226  loss: 0.24550720385872246  hr: 0  min: 0  sec: 36\n",
      "epoch: 1  batch: 90 / 226  loss: 0.25095386809358994  hr: 0  min: 0  sec: 36\n",
      "epoch: 1  batch: 91 / 226  loss: 0.2500984869119558  hr: 0  min: 0  sec: 35\n",
      "epoch: 1  batch: 92 / 226  loss: 0.24870936700102428  hr: 0  min: 0  sec: 35\n",
      "epoch: 1  batch: 93 / 226  loss: 0.24635867672341485  hr: 0  min: 0  sec: 35\n",
      "epoch: 1  batch: 94 / 226  loss: 0.2457378937248537  hr: 0  min: 0  sec: 34\n",
      "epoch: 1  batch: 95 / 226  loss: 0.2437495441225014  hr: 0  min: 0  sec: 34\n",
      "epoch: 1  batch: 96 / 226  loss: 0.24432313777894402  hr: 0  min: 0  sec: 34\n",
      "epoch: 1  batch: 97 / 226  loss: 0.24473525777689575  hr: 0  min: 0  sec: 34\n",
      "epoch: 1  batch: 98 / 226  loss: 0.2445858682942938  hr: 0  min: 0  sec: 33\n",
      "epoch: 1  batch: 99 / 226  loss: 0.24378306390435406  hr: 0  min: 0  sec: 33\n",
      "epoch: 1  batch: 100 / 226  loss: 0.2441519015468657  hr: 0  min: 0  sec: 33\n",
      "epoch: 1  batch: 101 / 226  loss: 0.242963618958498  hr: 0  min: 0  sec: 33\n",
      "epoch: 1  batch: 102 / 226  loss: 0.24138433802142448  hr: 0  min: 0  sec: 32\n",
      "epoch: 1  batch: 103 / 226  loss: 0.24047965529257231  hr: 0  min: 0  sec: 32\n",
      "epoch: 1  batch: 104 / 226  loss: 0.2395397514427224  hr: 0  min: 0  sec: 32\n",
      "epoch: 1  batch: 105 / 226  loss: 0.23864159578723568  hr: 0  min: 0  sec: 32\n",
      "epoch: 1  batch: 106 / 226  loss: 0.2389342118019484  hr: 0  min: 0  sec: 31\n",
      "epoch: 1  batch: 107 / 226  loss: 0.23717907191228085  hr: 0  min: 0  sec: 31\n",
      "epoch: 1  batch: 108 / 226  loss: 0.23788501386082284  hr: 0  min: 0  sec: 31\n",
      "epoch: 1  batch: 109 / 226  loss: 0.23793038310602718  hr: 0  min: 0  sec: 31\n",
      "epoch: 1  batch: 110 / 226  loss: 0.23767007882283492  hr: 0  min: 0  sec: 30\n",
      "epoch: 1  batch: 111 / 226  loss: 0.23930698520764038  hr: 0  min: 0  sec: 30\n",
      "epoch: 1  batch: 112 / 226  loss: 0.2414271543633991  hr: 0  min: 0  sec: 30\n",
      "epoch: 1  batch: 113 / 226  loss: 0.2411509939032582  hr: 0  min: 0  sec: 30\n",
      "epoch: 1  batch: 114 / 226  loss: 0.23920596057647153  hr: 0  min: 0  sec: 29\n",
      "epoch: 1  batch: 115 / 226  loss: 0.2382336742852045  hr: 0  min: 0  sec: 29\n",
      "epoch: 1  batch: 116 / 226  loss: 0.2392259817570448  hr: 0  min: 0  sec: 29\n",
      "epoch: 1  batch: 117 / 226  loss: 0.23949058258380646  hr: 0  min: 0  sec: 28\n",
      "epoch: 1  batch: 118 / 226  loss: 0.23815882426954932  hr: 0  min: 0  sec: 28\n",
      "epoch: 1  batch: 119 / 226  loss: 0.23745503163888676  hr: 0  min: 0  sec: 28\n",
      "epoch: 1  batch: 120 / 226  loss: 0.23741923812776805  hr: 0  min: 0  sec: 28\n",
      "epoch: 1  batch: 121 / 226  loss: 0.23582867591464815  hr: 0  min: 0  sec: 27\n",
      "epoch: 1  batch: 122 / 226  loss: 0.23504977114498615  hr: 0  min: 0  sec: 27\n",
      "epoch: 1  batch: 123 / 226  loss: 0.2346907506689308  hr: 0  min: 0  sec: 27\n",
      "epoch: 1  batch: 124 / 226  loss: 0.23314361727886623  hr: 0  min: 0  sec: 27\n",
      "epoch: 1  batch: 125 / 226  loss: 0.23409890076518058  hr: 0  min: 0  sec: 26\n",
      "epoch: 1  batch: 126 / 226  loss: 0.23263489525942577  hr: 0  min: 0  sec: 26\n",
      "epoch: 1  batch: 127 / 226  loss: 0.2329025823534943  hr: 0  min: 0  sec: 26\n",
      "epoch: 1  batch: 128 / 226  loss: 0.2322089682566002  hr: 0  min: 0  sec: 26\n",
      "epoch: 1  batch: 129 / 226  loss: 0.23062257434046546  hr: 0  min: 0  sec: 25\n",
      "epoch: 1  batch: 130 / 226  loss: 0.23154864127819355  hr: 0  min: 0  sec: 25\n",
      "epoch: 1  batch: 131 / 226  loss: 0.23255837691649225  hr: 0  min: 0  sec: 25\n",
      "epoch: 1  batch: 132 / 226  loss: 0.23103523048374688  hr: 0  min: 0  sec: 25\n",
      "epoch: 1  batch: 133 / 226  loss: 0.23049870892462873  hr: 0  min: 0  sec: 24\n",
      "epoch: 1  batch: 134 / 226  loss: 0.22897977205410378  hr: 0  min: 0  sec: 24\n",
      "epoch: 1  batch: 135 / 226  loss: 0.22760346538766665  hr: 0  min: 0  sec: 24\n",
      "epoch: 1  batch: 136 / 226  loss: 0.2260631194392986  hr: 0  min: 0  sec: 23\n",
      "epoch: 1  batch: 137 / 226  loss: 0.22591791685371504  hr: 0  min: 0  sec: 23\n",
      "epoch: 1  batch: 138 / 226  loss: 0.2250885777445375  hr: 0  min: 0  sec: 23\n",
      "epoch: 1  batch: 139 / 226  loss: 0.22429147735238075  hr: 0  min: 0  sec: 23\n",
      "epoch: 1  batch: 140 / 226  loss: 0.22287403330472963  hr: 0  min: 0  sec: 22\n",
      "epoch: 1  batch: 141 / 226  loss: 0.22220823661496875  hr: 0  min: 0  sec: 22\n",
      "epoch: 1  batch: 142 / 226  loss: 0.2221821687827018  hr: 0  min: 0  sec: 22\n",
      "epoch: 1  batch: 143 / 226  loss: 0.22080517509444195  hr: 0  min: 0  sec: 22\n",
      "epoch: 1  batch: 144 / 226  loss: 0.22023258085310873  hr: 0  min: 0  sec: 21\n",
      "epoch: 1  batch: 145 / 226  loss: 0.21897868769692963  hr: 0  min: 0  sec: 21\n",
      "epoch: 1  batch: 146 / 226  loss: 0.21758044252733458  hr: 0  min: 0  sec: 21\n",
      "epoch: 1  batch: 147 / 226  loss: 0.21972173003188403  hr: 0  min: 0  sec: 21\n",
      "epoch: 1  batch: 148 / 226  loss: 0.21944120211048504  hr: 0  min: 0  sec: 20\n",
      "epoch: 1  batch: 149 / 226  loss: 0.2198766884675262  hr: 0  min: 0  sec: 20\n",
      "epoch: 1  batch: 150 / 226  loss: 0.2233969885793825  hr: 0  min: 0  sec: 20\n",
      "epoch: 1  batch: 151 / 226  loss: 0.22210595334281788  hr: 0  min: 0  sec: 20\n",
      "epoch: 1  batch: 152 / 226  loss: 0.2235715189936424  hr: 0  min: 0  sec: 19\n",
      "epoch: 1  batch: 153 / 226  loss: 0.22303041910107424  hr: 0  min: 0  sec: 19\n",
      "epoch: 1  batch: 154 / 226  loss: 0.2253496700764767  hr: 0  min: 0  sec: 19\n",
      "epoch: 1  batch: 155 / 226  loss: 0.22589157547561392  hr: 0  min: 0  sec: 18\n",
      "epoch: 1  batch: 156 / 226  loss: 0.22673917119391263  hr: 0  min: 0  sec: 18\n",
      "epoch: 1  batch: 157 / 226  loss: 0.2268512560007204  hr: 0  min: 0  sec: 18\n",
      "epoch: 1  batch: 158 / 226  loss: 0.22755668054723852  hr: 0  min: 0  sec: 18\n",
      "epoch: 1  batch: 159 / 226  loss: 0.22702866461737164  hr: 0  min: 0  sec: 17\n",
      "epoch: 1  batch: 160 / 226  loss: 0.22645570949534885  hr: 0  min: 0  sec: 17\n",
      "epoch: 1  batch: 161 / 226  loss: 0.2260011091816777  hr: 0  min: 0  sec: 17\n",
      "epoch: 1  batch: 162 / 226  loss: 0.2250227574661466  hr: 0  min: 0  sec: 17\n",
      "epoch: 1  batch: 163 / 226  loss: 0.22472465163428176  hr: 0  min: 0  sec: 16\n",
      "epoch: 1  batch: 164 / 226  loss: 0.22394461663462584  hr: 0  min: 0  sec: 16\n",
      "epoch: 1  batch: 165 / 226  loss: 0.22310578057147337  hr: 0  min: 0  sec: 16\n",
      "epoch: 1  batch: 166 / 226  loss: 0.22221411245661865  hr: 0  min: 0  sec: 16\n",
      "epoch: 1  batch: 167 / 226  loss: 0.22315371573573636  hr: 0  min: 0  sec: 15\n",
      "epoch: 1  batch: 168 / 226  loss: 0.22373047330793702  hr: 0  min: 0  sec: 15\n",
      "epoch: 1  batch: 169 / 226  loss: 0.22319766439872205  hr: 0  min: 0  sec: 15\n",
      "epoch: 1  batch: 170 / 226  loss: 0.22198976752183894  hr: 0  min: 0  sec: 14\n",
      "epoch: 1  batch: 171 / 226  loss: 0.22263546192702668  hr: 0  min: 0  sec: 14\n",
      "epoch: 1  batch: 172 / 226  loss: 0.22339227501584522  hr: 0  min: 0  sec: 14\n",
      "epoch: 1  batch: 173 / 226  loss: 0.22224742410478393  hr: 0  min: 0  sec: 14\n",
      "epoch: 1  batch: 174 / 226  loss: 0.22321676757807532  hr: 0  min: 0  sec: 13\n",
      "epoch: 1  batch: 175 / 226  loss: 0.22274779612996748  hr: 0  min: 0  sec: 13\n",
      "epoch: 1  batch: 176 / 226  loss: 0.22218152016549456  hr: 0  min: 0  sec: 13\n",
      "epoch: 1  batch: 177 / 226  loss: 0.2212941439843363  hr: 0  min: 0  sec: 13\n",
      "epoch: 1  batch: 178 / 226  loss: 0.2212648117506688  hr: 0  min: 0  sec: 12\n",
      "epoch: 1  batch: 179 / 226  loss: 0.22023642345659394  hr: 0  min: 0  sec: 12\n",
      "epoch: 1  batch: 180 / 226  loss: 0.22040593275903828  hr: 0  min: 0  sec: 12\n",
      "epoch: 1  batch: 181 / 226  loss: 0.22093717251178804  hr: 0  min: 0  sec: 12\n",
      "epoch: 1  batch: 182 / 226  loss: 0.21983504929364875  hr: 0  min: 0  sec: 11\n",
      "epoch: 1  batch: 183 / 226  loss: 0.21900223268328306  hr: 0  min: 0  sec: 11\n",
      "epoch: 1  batch: 184 / 226  loss: 0.21918016331493045  hr: 0  min: 0  sec: 11\n",
      "epoch: 1  batch: 185 / 226  loss: 0.21934826276894356  hr: 0  min: 0  sec: 10\n",
      "epoch: 1  batch: 186 / 226  loss: 0.21988230045904877  hr: 0  min: 0  sec: 10\n",
      "epoch: 1  batch: 187 / 226  loss: 0.22028413063841548  hr: 0  min: 0  sec: 10\n",
      "epoch: 1  batch: 188 / 226  loss: 0.22065873348471174  hr: 0  min: 0  sec: 10\n",
      "epoch: 1  batch: 189 / 226  loss: 0.22026681497436826  hr: 0  min: 0  sec: 9\n",
      "epoch: 1  batch: 190 / 226  loss: 0.22122203495451495  hr: 0  min: 0  sec: 9\n",
      "epoch: 1  batch: 191 / 226  loss: 0.2206410152389039  hr: 0  min: 0  sec: 9\n",
      "epoch: 1  batch: 192 / 226  loss: 0.22002792513133804  hr: 0  min: 0  sec: 9\n",
      "epoch: 1  batch: 193 / 226  loss: 0.22017096445794396  hr: 0  min: 0  sec: 8\n",
      "epoch: 1  batch: 194 / 226  loss: 0.22058386493416637  hr: 0  min: 0  sec: 8\n",
      "epoch: 1  batch: 195 / 226  loss: 0.22148622495528214  hr: 0  min: 0  sec: 8\n",
      "epoch: 1  batch: 196 / 226  loss: 0.22220426652941624  hr: 0  min: 0  sec: 8\n",
      "epoch: 1  batch: 197 / 226  loss: 0.2218775513917586  hr: 0  min: 0  sec: 7\n",
      "epoch: 1  batch: 198 / 226  loss: 0.22158665932018798  hr: 0  min: 0  sec: 7\n",
      "epoch: 1  batch: 199 / 226  loss: 0.22177350528107667  hr: 0  min: 0  sec: 7\n",
      "epoch: 1  batch: 200 / 226  loss: 0.22206120274495333  hr: 0  min: 0  sec: 6\n",
      "epoch: 1  batch: 201 / 226  loss: 0.2218067714925948  hr: 0  min: 0  sec: 6\n",
      "epoch: 1  batch: 202 / 226  loss: 0.22342579265466272  hr: 0  min: 0  sec: 6\n",
      "epoch: 1  batch: 203 / 226  loss: 0.22314528357054064  hr: 0  min: 0  sec: 6\n",
      "epoch: 1  batch: 204 / 226  loss: 0.22234057528697246  hr: 0  min: 0  sec: 5\n",
      "epoch: 1  batch: 205 / 226  loss: 0.22331251076354486  hr: 0  min: 0  sec: 5\n",
      "epoch: 1  batch: 206 / 226  loss: 0.22280332452879803  hr: 0  min: 0  sec: 5\n",
      "epoch: 1  batch: 207 / 226  loss: 0.22192141935139317  hr: 0  min: 0  sec: 5\n",
      "epoch: 1  batch: 208 / 226  loss: 0.2210289881734822  hr: 0  min: 0  sec: 4\n",
      "epoch: 1  batch: 209 / 226  loss: 0.22184023759706598  hr: 0  min: 0  sec: 4\n",
      "epoch: 1  batch: 210 / 226  loss: 0.2213687224712755  hr: 0  min: 0  sec: 4\n",
      "epoch: 1  batch: 211 / 226  loss: 0.22051052985297984  hr: 0  min: 0  sec: 4\n",
      "epoch: 1  batch: 212 / 226  loss: 0.22195791399967418  hr: 0  min: 0  sec: 3\n",
      "epoch: 1  batch: 213 / 226  loss: 0.2229970923358216  hr: 0  min: 0  sec: 3\n",
      "epoch: 1  batch: 214 / 226  loss: 0.2227579618751933  hr: 0  min: 0  sec: 3\n",
      "epoch: 1  batch: 215 / 226  loss: 0.22416021341761183  hr: 0  min: 0  sec: 2\n",
      "epoch: 1  batch: 216 / 226  loss: 0.22355277666873816  hr: 0  min: 0  sec: 2\n",
      "epoch: 1  batch: 217 / 226  loss: 0.22268681524724868  hr: 0  min: 0  sec: 2\n",
      "epoch: 1  batch: 218 / 226  loss: 0.22284339656711583  hr: 0  min: 0  sec: 2\n",
      "epoch: 1  batch: 219 / 226  loss: 0.221989080815929  hr: 0  min: 0  sec: 1\n",
      "epoch: 1  batch: 220 / 226  loss: 0.2211166393985464  hr: 0  min: 0  sec: 1\n",
      "epoch: 1  batch: 221 / 226  loss: 0.22041315827687266  hr: 0  min: 0  sec: 1\n",
      "epoch: 1  batch: 222 / 226  loss: 0.2195433729982658  hr: 0  min: 0  sec: 1\n",
      "epoch: 1  batch: 223 / 226  loss: 0.21981727663060074  hr: 0  min: 0  sec: 0\n",
      "epoch: 1  batch: 224 / 226  loss: 0.22068355765077285  hr: 0  min: 0  sec: 0\n",
      "epoch: 1  batch: 225 / 226  loss: 0.22051663313060998  hr: 0  min: 0  sec: 0\n",
      "epoch: 1  batch: 226 / 226  loss: 0.21962237871969037  hr: 0  min: 0  sec: 0\n"
     ]
    }
   ],
   "source": [
    "train_model_APC(train_loader, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ABSA = load_model(model_APC, 'models/bert_APC.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2.59 s\n",
      "Wall time: 2.59 s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.95      0.92       464\n",
      "           1       0.42      0.26      0.32        50\n",
      "           2       0.90      0.87      0.89       410\n",
      "\n",
      "    accuracy                           0.88       924\n",
      "   macro avg       0.74      0.70      0.71       924\n",
      "weighted avg       0.87      0.88      0.87       924\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%time x, y = test_model_APC(test_loader)\n",
    "print(classification_report(x, y, target_names=[str(i) for i in range(3)]))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f1d4d6eb2abe3fb4049954bd206a32ef86aac931501ef1b113439c6e56c2b586"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
