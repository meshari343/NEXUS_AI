{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import transformers\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset\n",
    "from transformers import AutoModelForMaskedLM\n",
    "from transformers import AutoTokenizer, AutoConfig\n",
    "from transformers import BertForMaskedLM, DistilBertForMaskedLM\n",
    "from transformers import BertTokenizer, DistilBertTokenizer\n",
    "from transformers import RobertaTokenizer, RobertaForMaskedLM\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "from tokenizers import BertWordPieceTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HYPERPARAMS\n",
    "SEED_SPLIT = 0\n",
    "SEED_TRAIN = 0\n",
    "\n",
    "MAX_SEQ_LEN = 128\n",
    "TRAIN_BATCH_SIZE = 16\n",
    "EVAL_BATCH_SIZE = 16\n",
    "LEARNING_RATE = 2e-5 \n",
    "LR_WARMUP_STEPS = 100\n",
    "WEIGHT_DECAY = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "dtf_mlm = pd.read_pickle('data/yelp_dataset_reviews.pkl')\n",
    "\n",
    "# Train/Valid Split\n",
    "df_train, df_valid = train_test_split(\n",
    "    dtf_mlm, test_size=0.15, random_state=SEED_SPLIT\n",
    ")\n",
    "\n",
    "len(df_train), len(df_valid)\n",
    "\n",
    "# Convert to Dataset object\n",
    "train_dataset = Dataset.from_pandas(df_train[['text']].dropna())\n",
    "valid_dataset = Dataset.from_pandas(df_valid[['text']].dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "MODEL = 'bert'\n",
    "bert_type = 'bert-base-cased'\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\n",
    "            bert_type, use_fast=True, do_lower_case=False, max_len=MAX_SEQ_LEN\n",
    "            )\n",
    "model = BertForMaskedLM.from_pretrained(bert_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aac0c16313a049f4b38137a9ca248d4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5942 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a97a7275742497bad1f8f78d2bc404c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1049 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize_function(row):\n",
    "    return tokenizer(\n",
    "        row['text'],\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        max_length=MAX_SEQ_LEN,\n",
    "        return_special_tokens_mask=True)\n",
    "  \n",
    "column_names = train_dataset.column_names\n",
    "\n",
    "train_dataset = train_dataset.map(\n",
    "    tokenize_function,\n",
    "    batched=True,\n",
    "    remove_columns=column_names,\n",
    ")\n",
    "\n",
    "valid_dataset = valid_dataset.map(\n",
    "    tokenize_function,\n",
    "    batched=True,\n",
    "    remove_columns=column_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer, mlm=True, mlm_probability=0.15\n",
    ")\n",
    "\n",
    "\n",
    "steps_per_epoch = int(len(train_dataset) / TRAIN_BATCH_SIZE)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='args/bert-restaurants',\n",
    "    logging_dir='logs/LMlogs',             \n",
    "    num_train_epochs=2,\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    per_device_train_batch_size=TRAIN_BATCH_SIZE,\n",
    "    per_device_eval_batch_size=EVAL_BATCH_SIZE,\n",
    "    warmup_steps=LR_WARMUP_STEPS,\n",
    "    save_steps=steps_per_epoch,\n",
    "    save_total_limit=3,\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    "    learning_rate=LEARNING_RATE, \n",
    "    evaluation_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='loss', \n",
    "    greater_is_better=False,\n",
    "    seed=SEED_TRAIN\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: special_tokens_mask. If special_tokens_mask are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n",
      "c:\\Users\\meshari\\nexus_ai\\venv\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 5941738\n",
      "  Num Epochs = 2\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 742718\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df0502998fe147e084647f23de485d34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/742718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.3546, 'learning_rate': 1.998922730125044e-05, 'epoch': 0.0}\n",
      "{'loss': 2.2162, 'learning_rate': 1.9975761427813495e-05, 'epoch': 0.0}\n",
      "{'loss': 2.1548, 'learning_rate': 1.9962295554376545e-05, 'epoch': 0.0}\n",
      "{'loss': 2.1012, 'learning_rate': 1.9948829680939595e-05, 'epoch': 0.01}\n",
      "{'loss': 2.0666, 'learning_rate': 1.993536380750265e-05, 'epoch': 0.01}\n",
      "{'loss': 2.0747, 'learning_rate': 1.99218979340657e-05, 'epoch': 0.01}\n",
      "{'loss': 2.025, 'learning_rate': 1.990843206062875e-05, 'epoch': 0.01}\n",
      "{'loss': 2.0242, 'learning_rate': 1.9894966187191803e-05, 'epoch': 0.01}\n",
      "{'loss': 1.9964, 'learning_rate': 1.9881500313754854e-05, 'epoch': 0.01}\n",
      "{'loss': 1.9874, 'learning_rate': 1.9868034440317904e-05, 'epoch': 0.01}\n",
      "{'loss': 1.996, 'learning_rate': 1.9854568566880958e-05, 'epoch': 0.01}\n",
      "{'loss': 1.9793, 'learning_rate': 1.9841102693444005e-05, 'epoch': 0.02}\n",
      "{'loss': 1.9656, 'learning_rate': 1.9827636820007058e-05, 'epoch': 0.02}\n",
      "{'loss': 1.9495, 'learning_rate': 1.981417094657011e-05, 'epoch': 0.02}\n",
      "{'loss': 1.9307, 'learning_rate': 1.980070507313316e-05, 'epoch': 0.02}\n",
      "{'loss': 1.9392, 'learning_rate': 1.9787239199696212e-05, 'epoch': 0.02}\n",
      "{'loss': 1.9233, 'learning_rate': 1.9773773326259263e-05, 'epoch': 0.02}\n",
      "{'loss': 1.9202, 'learning_rate': 1.9760307452822313e-05, 'epoch': 0.02}\n",
      "{'loss': 1.9029, 'learning_rate': 1.9746841579385367e-05, 'epoch': 0.03}\n",
      "{'loss': 1.9103, 'learning_rate': 1.9733375705948417e-05, 'epoch': 0.03}\n",
      "{'loss': 1.898, 'learning_rate': 1.9719909832511467e-05, 'epoch': 0.03}\n",
      "{'loss': 1.8945, 'learning_rate': 1.970644395907452e-05, 'epoch': 0.03}\n",
      "{'loss': 1.9036, 'learning_rate': 1.969297808563757e-05, 'epoch': 0.03}\n",
      "{'loss': 1.882, 'learning_rate': 1.967951221220062e-05, 'epoch': 0.03}\n",
      "{'loss': 1.879, 'learning_rate': 1.9666046338763675e-05, 'epoch': 0.03}\n",
      "{'loss': 1.8743, 'learning_rate': 1.9652580465326725e-05, 'epoch': 0.04}\n",
      "{'loss': 1.8788, 'learning_rate': 1.9639114591889776e-05, 'epoch': 0.04}\n",
      "{'loss': 1.8732, 'learning_rate': 1.9625648718452826e-05, 'epoch': 0.04}\n",
      "{'loss': 1.853, 'learning_rate': 1.9612182845015876e-05, 'epoch': 0.04}\n",
      "{'loss': 1.8512, 'learning_rate': 1.9598716971578927e-05, 'epoch': 0.04}\n",
      "{'loss': 1.8625, 'learning_rate': 1.958525109814198e-05, 'epoch': 0.04}\n",
      "{'loss': 1.8467, 'learning_rate': 1.957178522470503e-05, 'epoch': 0.04}\n",
      "{'loss': 1.8559, 'learning_rate': 1.955831935126808e-05, 'epoch': 0.04}\n",
      "{'loss': 1.8753, 'learning_rate': 1.9544853477831135e-05, 'epoch': 0.05}\n",
      "{'loss': 1.8513, 'learning_rate': 1.9531387604394185e-05, 'epoch': 0.05}\n",
      "{'loss': 1.8386, 'learning_rate': 1.9517921730957235e-05, 'epoch': 0.05}\n",
      "{'loss': 1.8317, 'learning_rate': 1.950445585752029e-05, 'epoch': 0.05}\n",
      "{'loss': 1.8329, 'learning_rate': 1.949098998408334e-05, 'epoch': 0.05}\n",
      "{'loss': 1.8112, 'learning_rate': 1.947752411064639e-05, 'epoch': 0.05}\n",
      "{'loss': 1.8263, 'learning_rate': 1.9464058237209443e-05, 'epoch': 0.05}\n",
      "{'loss': 1.8117, 'learning_rate': 1.9450592363772493e-05, 'epoch': 0.06}\n",
      "{'loss': 1.8244, 'learning_rate': 1.9437126490335544e-05, 'epoch': 0.06}\n",
      "{'loss': 1.8061, 'learning_rate': 1.9423660616898597e-05, 'epoch': 0.06}\n",
      "{'loss': 1.7991, 'learning_rate': 1.9410194743461648e-05, 'epoch': 0.06}\n",
      "{'loss': 1.8206, 'learning_rate': 1.9396728870024698e-05, 'epoch': 0.06}\n",
      "{'loss': 1.796, 'learning_rate': 1.9383262996587748e-05, 'epoch': 0.06}\n",
      "{'loss': 1.7918, 'learning_rate': 1.93697971231508e-05, 'epoch': 0.06}\n",
      "{'loss': 1.8117, 'learning_rate': 1.9356331249713852e-05, 'epoch': 0.06}\n",
      "{'loss': 1.793, 'learning_rate': 1.9342865376276902e-05, 'epoch': 0.07}\n",
      "{'loss': 1.8042, 'learning_rate': 1.9329399502839953e-05, 'epoch': 0.07}\n",
      "{'loss': 1.7933, 'learning_rate': 1.9315933629403006e-05, 'epoch': 0.07}\n",
      "{'loss': 1.8078, 'learning_rate': 1.9302467755966057e-05, 'epoch': 0.07}\n",
      "{'loss': 1.8167, 'learning_rate': 1.9289001882529107e-05, 'epoch': 0.07}\n",
      "{'loss': 1.7777, 'learning_rate': 1.927553600909216e-05, 'epoch': 0.07}\n",
      "{'loss': 1.7693, 'learning_rate': 1.926207013565521e-05, 'epoch': 0.07}\n",
      "{'loss': 1.7867, 'learning_rate': 1.924860426221826e-05, 'epoch': 0.08}\n",
      "{'loss': 1.7762, 'learning_rate': 1.9235138388781315e-05, 'epoch': 0.08}\n",
      "{'loss': 1.7615, 'learning_rate': 1.9221672515344365e-05, 'epoch': 0.08}\n",
      "{'loss': 1.7756, 'learning_rate': 1.9208206641907415e-05, 'epoch': 0.08}\n",
      "{'loss': 1.7722, 'learning_rate': 1.919474076847047e-05, 'epoch': 0.08}\n",
      "{'loss': 1.7668, 'learning_rate': 1.9181274895033516e-05, 'epoch': 0.08}\n",
      "{'loss': 1.7638, 'learning_rate': 1.916780902159657e-05, 'epoch': 0.08}\n",
      "{'loss': 1.7518, 'learning_rate': 1.915434314815962e-05, 'epoch': 0.08}\n",
      "{'loss': 1.7561, 'learning_rate': 1.914087727472267e-05, 'epoch': 0.09}\n",
      "{'loss': 1.7692, 'learning_rate': 1.9127411401285724e-05, 'epoch': 0.09}\n",
      "{'loss': 1.7618, 'learning_rate': 1.9113945527848774e-05, 'epoch': 0.09}\n",
      "{'loss': 1.7442, 'learning_rate': 1.9100479654411824e-05, 'epoch': 0.09}\n",
      "{'loss': 1.7455, 'learning_rate': 1.9087013780974878e-05, 'epoch': 0.09}\n",
      "{'loss': 1.7509, 'learning_rate': 1.907354790753793e-05, 'epoch': 0.09}\n",
      "{'loss': 1.748, 'learning_rate': 1.906008203410098e-05, 'epoch': 0.09}\n",
      "{'loss': 1.742, 'learning_rate': 1.9046616160664032e-05, 'epoch': 0.1}\n",
      "{'loss': 1.76, 'learning_rate': 1.9033150287227083e-05, 'epoch': 0.1}\n",
      "{'loss': 1.7568, 'learning_rate': 1.9019684413790133e-05, 'epoch': 0.1}\n",
      "{'loss': 1.7664, 'learning_rate': 1.9006218540353187e-05, 'epoch': 0.1}\n",
      "{'loss': 1.7492, 'learning_rate': 1.8992752666916237e-05, 'epoch': 0.1}\n",
      "{'loss': 1.7359, 'learning_rate': 1.8979286793479287e-05, 'epoch': 0.1}\n",
      "{'loss': 1.7483, 'learning_rate': 1.896582092004234e-05, 'epoch': 0.1}\n",
      "{'loss': 1.7383, 'learning_rate': 1.8952355046605388e-05, 'epoch': 0.11}\n",
      "{'loss': 1.7286, 'learning_rate': 1.893888917316844e-05, 'epoch': 0.11}\n",
      "{'loss': 1.7444, 'learning_rate': 1.8925423299731492e-05, 'epoch': 0.11}\n",
      "{'loss': 1.724, 'learning_rate': 1.8911957426294542e-05, 'epoch': 0.11}\n",
      "{'loss': 1.7468, 'learning_rate': 1.8898491552857596e-05, 'epoch': 0.11}\n",
      "{'loss': 1.7423, 'learning_rate': 1.8885025679420646e-05, 'epoch': 0.11}\n",
      "{'loss': 1.73, 'learning_rate': 1.8871559805983696e-05, 'epoch': 0.11}\n",
      "{'loss': 1.7329, 'learning_rate': 1.8858093932546747e-05, 'epoch': 0.11}\n",
      "{'loss': 1.7292, 'learning_rate': 1.88446280591098e-05, 'epoch': 0.12}\n",
      "{'loss': 1.7184, 'learning_rate': 1.883116218567285e-05, 'epoch': 0.12}\n",
      "{'loss': 1.7303, 'learning_rate': 1.88176963122359e-05, 'epoch': 0.12}\n",
      "{'loss': 1.7222, 'learning_rate': 1.8804230438798954e-05, 'epoch': 0.12}\n",
      "{'loss': 1.7208, 'learning_rate': 1.8790764565362005e-05, 'epoch': 0.12}\n",
      "{'loss': 1.739, 'learning_rate': 1.8777298691925055e-05, 'epoch': 0.12}\n",
      "{'loss': 1.7136, 'learning_rate': 1.876383281848811e-05, 'epoch': 0.12}\n",
      "{'loss': 1.7129, 'learning_rate': 1.875036694505116e-05, 'epoch': 0.13}\n",
      "{'loss': 1.706, 'learning_rate': 1.873690107161421e-05, 'epoch': 0.13}\n",
      "{'loss': 1.7153, 'learning_rate': 1.872343519817726e-05, 'epoch': 0.13}\n",
      "{'loss': 1.7171, 'learning_rate': 1.870996932474031e-05, 'epoch': 0.13}\n",
      "{'loss': 1.6976, 'learning_rate': 1.8696503451303364e-05, 'epoch': 0.13}\n",
      "{'loss': 1.7117, 'learning_rate': 1.8683037577866414e-05, 'epoch': 0.13}\n",
      "{'loss': 1.7084, 'learning_rate': 1.8669571704429464e-05, 'epoch': 0.13}\n",
      "{'loss': 1.6938, 'learning_rate': 1.8656105830992518e-05, 'epoch': 0.13}\n",
      "{'loss': 1.7209, 'learning_rate': 1.8642639957555568e-05, 'epoch': 0.14}\n",
      "{'loss': 1.7136, 'learning_rate': 1.862917408411862e-05, 'epoch': 0.14}\n",
      "{'loss': 1.7077, 'learning_rate': 1.8615708210681672e-05, 'epoch': 0.14}\n",
      "{'loss': 1.7077, 'learning_rate': 1.8602242337244722e-05, 'epoch': 0.14}\n",
      "{'loss': 1.7012, 'learning_rate': 1.8588776463807773e-05, 'epoch': 0.14}\n",
      "{'loss': 1.7109, 'learning_rate': 1.8575310590370826e-05, 'epoch': 0.14}\n",
      "{'loss': 1.6895, 'learning_rate': 1.8561844716933877e-05, 'epoch': 0.14}\n",
      "{'loss': 1.6975, 'learning_rate': 1.8548378843496927e-05, 'epoch': 0.15}\n",
      "{'loss': 1.6947, 'learning_rate': 1.853491297005998e-05, 'epoch': 0.15}\n",
      "{'loss': 1.6897, 'learning_rate': 1.852144709662303e-05, 'epoch': 0.15}\n",
      "{'loss': 1.7042, 'learning_rate': 1.850798122318608e-05, 'epoch': 0.15}\n",
      "{'loss': 1.7255, 'learning_rate': 1.849451534974913e-05, 'epoch': 0.15}\n",
      "{'loss': 1.6967, 'learning_rate': 1.848104947631218e-05, 'epoch': 0.15}\n",
      "{'loss': 1.697, 'learning_rate': 1.8467583602875235e-05, 'epoch': 0.15}\n",
      "{'loss': 1.7074, 'learning_rate': 1.8454117729438286e-05, 'epoch': 0.15}\n",
      "{'loss': 1.6969, 'learning_rate': 1.8440651856001336e-05, 'epoch': 0.16}\n",
      "{'loss': 1.6735, 'learning_rate': 1.842718598256439e-05, 'epoch': 0.16}\n",
      "{'loss': 1.6905, 'learning_rate': 1.841372010912744e-05, 'epoch': 0.16}\n",
      "{'loss': 1.6933, 'learning_rate': 1.840025423569049e-05, 'epoch': 0.16}\n",
      "{'loss': 1.7008, 'learning_rate': 1.8386788362253544e-05, 'epoch': 0.16}\n",
      "{'loss': 1.6784, 'learning_rate': 1.8373322488816594e-05, 'epoch': 0.16}\n",
      "{'loss': 1.6986, 'learning_rate': 1.8359856615379644e-05, 'epoch': 0.16}\n",
      "{'loss': 1.6855, 'learning_rate': 1.8346390741942698e-05, 'epoch': 0.17}\n",
      "{'loss': 1.7054, 'learning_rate': 1.833292486850575e-05, 'epoch': 0.17}\n",
      "{'loss': 1.6831, 'learning_rate': 1.83194589950688e-05, 'epoch': 0.17}\n",
      "{'loss': 1.6842, 'learning_rate': 1.8305993121631852e-05, 'epoch': 0.17}\n",
      "{'loss': 1.6839, 'learning_rate': 1.82925272481949e-05, 'epoch': 0.17}\n",
      "{'loss': 1.6848, 'learning_rate': 1.8279061374757953e-05, 'epoch': 0.17}\n",
      "{'loss': 1.6919, 'learning_rate': 1.8265595501321003e-05, 'epoch': 0.17}\n",
      "{'loss': 1.6814, 'learning_rate': 1.8252129627884053e-05, 'epoch': 0.18}\n",
      "{'loss': 1.6808, 'learning_rate': 1.8238663754447107e-05, 'epoch': 0.18}\n",
      "{'loss': 1.6719, 'learning_rate': 1.8225197881010157e-05, 'epoch': 0.18}\n",
      "{'loss': 1.6871, 'learning_rate': 1.8211732007573208e-05, 'epoch': 0.18}\n",
      "{'loss': 1.6783, 'learning_rate': 1.819826613413626e-05, 'epoch': 0.18}\n",
      "{'loss': 1.6816, 'learning_rate': 1.8184800260699312e-05, 'epoch': 0.18}\n",
      "{'loss': 1.6902, 'learning_rate': 1.8171334387262362e-05, 'epoch': 0.18}\n",
      "{'loss': 1.6706, 'learning_rate': 1.8157868513825416e-05, 'epoch': 0.18}\n",
      "{'loss': 1.6707, 'learning_rate': 1.8144402640388466e-05, 'epoch': 0.19}\n",
      "{'loss': 1.6616, 'learning_rate': 1.8130936766951516e-05, 'epoch': 0.19}\n",
      "{'loss': 1.6857, 'learning_rate': 1.811747089351457e-05, 'epoch': 0.19}\n",
      "{'loss': 1.653, 'learning_rate': 1.810400502007762e-05, 'epoch': 0.19}\n",
      "{'loss': 1.6684, 'learning_rate': 1.809053914664067e-05, 'epoch': 0.19}\n",
      "{'loss': 1.6421, 'learning_rate': 1.807707327320372e-05, 'epoch': 0.19}\n",
      "{'loss': 1.6703, 'learning_rate': 1.806360739976677e-05, 'epoch': 0.19}\n",
      "{'loss': 1.677, 'learning_rate': 1.805014152632982e-05, 'epoch': 0.2}\n",
      "{'loss': 1.6834, 'learning_rate': 1.8036675652892875e-05, 'epoch': 0.2}\n",
      "{'loss': 1.6821, 'learning_rate': 1.8023209779455925e-05, 'epoch': 0.2}\n",
      "{'loss': 1.6724, 'learning_rate': 1.8009743906018976e-05, 'epoch': 0.2}\n",
      "{'loss': 1.6709, 'learning_rate': 1.799627803258203e-05, 'epoch': 0.2}\n",
      "{'loss': 1.6679, 'learning_rate': 1.798281215914508e-05, 'epoch': 0.2}\n",
      "{'loss': 1.6815, 'learning_rate': 1.796934628570813e-05, 'epoch': 0.2}\n",
      "{'loss': 1.6526, 'learning_rate': 1.7955880412271184e-05, 'epoch': 0.2}\n",
      "{'loss': 1.6608, 'learning_rate': 1.7942414538834234e-05, 'epoch': 0.21}\n",
      "{'loss': 1.6456, 'learning_rate': 1.7928948665397284e-05, 'epoch': 0.21}\n",
      "{'loss': 1.6656, 'learning_rate': 1.7915482791960338e-05, 'epoch': 0.21}\n",
      "{'loss': 1.6624, 'learning_rate': 1.7902016918523388e-05, 'epoch': 0.21}\n",
      "{'loss': 1.6684, 'learning_rate': 1.788855104508644e-05, 'epoch': 0.21}\n",
      "{'loss': 1.6633, 'learning_rate': 1.7875085171649492e-05, 'epoch': 0.21}\n",
      "{'loss': 1.6648, 'learning_rate': 1.7861619298212542e-05, 'epoch': 0.21}\n",
      "{'loss': 1.6675, 'learning_rate': 1.7848153424775593e-05, 'epoch': 0.22}\n",
      "{'loss': 1.6568, 'learning_rate': 1.7834687551338643e-05, 'epoch': 0.22}\n",
      "{'loss': 1.6465, 'learning_rate': 1.7821221677901693e-05, 'epoch': 0.22}\n",
      "{'loss': 1.6565, 'learning_rate': 1.7807755804464747e-05, 'epoch': 0.22}\n",
      "{'loss': 1.6601, 'learning_rate': 1.7794289931027797e-05, 'epoch': 0.22}\n",
      "{'loss': 1.6539, 'learning_rate': 1.7780824057590847e-05, 'epoch': 0.22}\n",
      "{'loss': 1.6534, 'learning_rate': 1.77673581841539e-05, 'epoch': 0.22}\n",
      "{'loss': 1.6643, 'learning_rate': 1.775389231071695e-05, 'epoch': 0.22}\n",
      "{'loss': 1.6315, 'learning_rate': 1.774042643728e-05, 'epoch': 0.23}\n",
      "{'loss': 1.6482, 'learning_rate': 1.7726960563843055e-05, 'epoch': 0.23}\n",
      "{'loss': 1.6619, 'learning_rate': 1.7713494690406106e-05, 'epoch': 0.23}\n",
      "{'loss': 1.6287, 'learning_rate': 1.7700028816969156e-05, 'epoch': 0.23}\n",
      "{'loss': 1.6499, 'learning_rate': 1.768656294353221e-05, 'epoch': 0.23}\n",
      "{'loss': 1.6561, 'learning_rate': 1.767309707009526e-05, 'epoch': 0.23}\n",
      "{'loss': 1.6646, 'learning_rate': 1.765963119665831e-05, 'epoch': 0.23}\n",
      "{'loss': 1.6696, 'learning_rate': 1.7646165323221364e-05, 'epoch': 0.24}\n",
      "{'loss': 1.646, 'learning_rate': 1.763269944978441e-05, 'epoch': 0.24}\n",
      "{'loss': 1.6318, 'learning_rate': 1.7619233576347464e-05, 'epoch': 0.24}\n",
      "{'loss': 1.6583, 'learning_rate': 1.7605767702910515e-05, 'epoch': 0.24}\n",
      "{'loss': 1.6348, 'learning_rate': 1.7592301829473565e-05, 'epoch': 0.24}\n",
      "{'loss': 1.6237, 'learning_rate': 1.757883595603662e-05, 'epoch': 0.24}\n",
      "{'loss': 1.6337, 'learning_rate': 1.756537008259967e-05, 'epoch': 0.24}\n",
      "{'loss': 1.6578, 'learning_rate': 1.755190420916272e-05, 'epoch': 0.25}\n",
      "{'loss': 1.6431, 'learning_rate': 1.7538438335725773e-05, 'epoch': 0.25}\n",
      "{'loss': 1.6375, 'learning_rate': 1.7524972462288823e-05, 'epoch': 0.25}\n",
      "{'loss': 1.6339, 'learning_rate': 1.7511506588851873e-05, 'epoch': 0.25}\n",
      "{'loss': 1.6346, 'learning_rate': 1.7498040715414927e-05, 'epoch': 0.25}\n",
      "{'loss': 1.6521, 'learning_rate': 1.7484574841977977e-05, 'epoch': 0.25}\n",
      "{'loss': 1.6361, 'learning_rate': 1.7471108968541028e-05, 'epoch': 0.25}\n",
      "{'loss': 1.6314, 'learning_rate': 1.745764309510408e-05, 'epoch': 0.25}\n",
      "{'loss': 1.6352, 'learning_rate': 1.744417722166713e-05, 'epoch': 0.26}\n",
      "{'loss': 1.6336, 'learning_rate': 1.7430711348230182e-05, 'epoch': 0.26}\n",
      "{'loss': 1.6335, 'learning_rate': 1.7417245474793236e-05, 'epoch': 0.26}\n",
      "{'loss': 1.6426, 'learning_rate': 1.7403779601356283e-05, 'epoch': 0.26}\n",
      "{'loss': 1.6415, 'learning_rate': 1.7390313727919336e-05, 'epoch': 0.26}\n",
      "{'loss': 1.635, 'learning_rate': 1.7376847854482386e-05, 'epoch': 0.26}\n",
      "{'loss': 1.6541, 'learning_rate': 1.7363381981045437e-05, 'epoch': 0.26}\n",
      "{'loss': 1.6223, 'learning_rate': 1.734991610760849e-05, 'epoch': 0.27}\n",
      "{'loss': 1.6357, 'learning_rate': 1.733645023417154e-05, 'epoch': 0.27}\n",
      "{'loss': 1.6377, 'learning_rate': 1.732298436073459e-05, 'epoch': 0.27}\n",
      "{'loss': 1.6339, 'learning_rate': 1.730951848729764e-05, 'epoch': 0.27}\n",
      "{'loss': 1.6116, 'learning_rate': 1.7296052613860695e-05, 'epoch': 0.27}\n",
      "{'loss': 1.6265, 'learning_rate': 1.7282586740423745e-05, 'epoch': 0.27}\n",
      "{'loss': 1.6326, 'learning_rate': 1.7269120866986796e-05, 'epoch': 0.27}\n",
      "{'loss': 1.6148, 'learning_rate': 1.725565499354985e-05, 'epoch': 0.27}\n",
      "{'loss': 1.6352, 'learning_rate': 1.72421891201129e-05, 'epoch': 0.28}\n",
      "{'loss': 1.634, 'learning_rate': 1.722872324667595e-05, 'epoch': 0.28}\n",
      "{'loss': 1.6321, 'learning_rate': 1.7215257373239003e-05, 'epoch': 0.28}\n",
      "{'loss': 1.6233, 'learning_rate': 1.7201791499802054e-05, 'epoch': 0.28}\n",
      "{'loss': 1.6288, 'learning_rate': 1.7188325626365104e-05, 'epoch': 0.28}\n",
      "{'loss': 1.6402, 'learning_rate': 1.7174859752928154e-05, 'epoch': 0.28}\n",
      "{'loss': 1.6218, 'learning_rate': 1.7161393879491205e-05, 'epoch': 0.28}\n",
      "{'loss': 1.614, 'learning_rate': 1.7147928006054258e-05, 'epoch': 0.29}\n",
      "{'loss': 1.6055, 'learning_rate': 1.713446213261731e-05, 'epoch': 0.29}\n",
      "{'loss': 1.6285, 'learning_rate': 1.712099625918036e-05, 'epoch': 0.29}\n",
      "{'loss': 1.6468, 'learning_rate': 1.7107530385743413e-05, 'epoch': 0.29}\n",
      "{'loss': 1.6141, 'learning_rate': 1.7094064512306463e-05, 'epoch': 0.29}\n",
      "{'loss': 1.601, 'learning_rate': 1.7080598638869513e-05, 'epoch': 0.29}\n",
      "{'loss': 1.6172, 'learning_rate': 1.7067132765432567e-05, 'epoch': 0.29}\n",
      "{'loss': 1.6235, 'learning_rate': 1.7053666891995617e-05, 'epoch': 0.29}\n",
      "{'loss': 1.6057, 'learning_rate': 1.7040201018558667e-05, 'epoch': 0.3}\n",
      "{'loss': 1.6168, 'learning_rate': 1.702673514512172e-05, 'epoch': 0.3}\n",
      "{'loss': 1.6101, 'learning_rate': 1.701326927168477e-05, 'epoch': 0.3}\n",
      "{'loss': 1.623, 'learning_rate': 1.699980339824782e-05, 'epoch': 0.3}\n",
      "{'loss': 1.6137, 'learning_rate': 1.6986337524810875e-05, 'epoch': 0.3}\n",
      "{'loss': 1.5992, 'learning_rate': 1.6972871651373926e-05, 'epoch': 0.3}\n",
      "{'loss': 1.6321, 'learning_rate': 1.6959405777936976e-05, 'epoch': 0.3}\n",
      "{'loss': 1.6062, 'learning_rate': 1.6945939904500026e-05, 'epoch': 0.31}\n",
      "{'loss': 1.6205, 'learning_rate': 1.6932474031063076e-05, 'epoch': 0.31}\n",
      "{'loss': 1.6243, 'learning_rate': 1.691900815762613e-05, 'epoch': 0.31}\n",
      "{'loss': 1.6112, 'learning_rate': 1.690554228418918e-05, 'epoch': 0.31}\n",
      "{'loss': 1.6228, 'learning_rate': 1.689207641075223e-05, 'epoch': 0.31}\n",
      "{'loss': 1.6129, 'learning_rate': 1.6878610537315284e-05, 'epoch': 0.31}\n",
      "{'loss': 1.6283, 'learning_rate': 1.6865144663878335e-05, 'epoch': 0.31}\n",
      "{'loss': 1.6189, 'learning_rate': 1.6851678790441385e-05, 'epoch': 0.32}\n",
      "{'loss': 1.6253, 'learning_rate': 1.683821291700444e-05, 'epoch': 0.32}\n",
      "{'loss': 1.5851, 'learning_rate': 1.682474704356749e-05, 'epoch': 0.32}\n",
      "{'loss': 1.6168, 'learning_rate': 1.681128117013054e-05, 'epoch': 0.32}\n",
      "{'loss': 1.6045, 'learning_rate': 1.6797815296693593e-05, 'epoch': 0.32}\n",
      "{'loss': 1.6099, 'learning_rate': 1.6784349423256643e-05, 'epoch': 0.32}\n",
      "{'loss': 1.608, 'learning_rate': 1.6770883549819693e-05, 'epoch': 0.32}\n",
      "{'loss': 1.6012, 'learning_rate': 1.6757417676382747e-05, 'epoch': 0.32}\n",
      "{'loss': 1.6062, 'learning_rate': 1.6743951802945794e-05, 'epoch': 0.33}\n",
      "{'loss': 1.6086, 'learning_rate': 1.6730485929508848e-05, 'epoch': 0.33}\n",
      "{'loss': 1.6119, 'learning_rate': 1.6717020056071898e-05, 'epoch': 0.33}\n",
      "{'loss': 1.6167, 'learning_rate': 1.6703554182634948e-05, 'epoch': 0.33}\n",
      "{'loss': 1.6132, 'learning_rate': 1.6690088309198002e-05, 'epoch': 0.33}\n",
      "{'loss': 1.5997, 'learning_rate': 1.6676622435761052e-05, 'epoch': 0.33}\n",
      "{'loss': 1.6141, 'learning_rate': 1.6663156562324102e-05, 'epoch': 0.33}\n",
      "{'loss': 1.6044, 'learning_rate': 1.6649690688887156e-05, 'epoch': 0.34}\n",
      "{'loss': 1.6069, 'learning_rate': 1.6636224815450206e-05, 'epoch': 0.34}\n",
      "{'loss': 1.6091, 'learning_rate': 1.6622758942013257e-05, 'epoch': 0.34}\n",
      "{'loss': 1.5943, 'learning_rate': 1.660929306857631e-05, 'epoch': 0.34}\n",
      "{'loss': 1.5975, 'learning_rate': 1.659582719513936e-05, 'epoch': 0.34}\n",
      "{'loss': 1.599, 'learning_rate': 1.658236132170241e-05, 'epoch': 0.34}\n",
      "{'loss': 1.5998, 'learning_rate': 1.656889544826546e-05, 'epoch': 0.34}\n",
      "{'loss': 1.6088, 'learning_rate': 1.6555429574828515e-05, 'epoch': 0.34}\n",
      "{'loss': 1.6095, 'learning_rate': 1.6541963701391565e-05, 'epoch': 0.35}\n",
      "{'loss': 1.607, 'learning_rate': 1.6528497827954616e-05, 'epoch': 0.35}\n",
      "{'loss': 1.5955, 'learning_rate': 1.6515031954517666e-05, 'epoch': 0.35}\n",
      "{'loss': 1.5965, 'learning_rate': 1.6501566081080716e-05, 'epoch': 0.35}\n",
      "{'loss': 1.5791, 'learning_rate': 1.648810020764377e-05, 'epoch': 0.35}\n",
      "{'loss': 1.5981, 'learning_rate': 1.647463433420682e-05, 'epoch': 0.35}\n",
      "{'loss': 1.6002, 'learning_rate': 1.646116846076987e-05, 'epoch': 0.35}\n",
      "{'loss': 1.5958, 'learning_rate': 1.6447702587332924e-05, 'epoch': 0.36}\n",
      "{'loss': 1.5904, 'learning_rate': 1.6434236713895974e-05, 'epoch': 0.36}\n",
      "{'loss': 1.6021, 'learning_rate': 1.6420770840459025e-05, 'epoch': 0.36}\n",
      "{'loss': 1.5872, 'learning_rate': 1.6407304967022078e-05, 'epoch': 0.36}\n",
      "{'loss': 1.6009, 'learning_rate': 1.639383909358513e-05, 'epoch': 0.36}\n",
      "{'loss': 1.5729, 'learning_rate': 1.638037322014818e-05, 'epoch': 0.36}\n",
      "{'loss': 1.6026, 'learning_rate': 1.6366907346711233e-05, 'epoch': 0.36}\n",
      "{'loss': 1.5982, 'learning_rate': 1.6353441473274283e-05, 'epoch': 0.36}\n",
      "{'loss': 1.5809, 'learning_rate': 1.6339975599837333e-05, 'epoch': 0.37}\n",
      "{'loss': 1.5965, 'learning_rate': 1.6326509726400387e-05, 'epoch': 0.37}\n",
      "{'loss': 1.6106, 'learning_rate': 1.6313043852963437e-05, 'epoch': 0.37}\n",
      "{'loss': 1.5943, 'learning_rate': 1.6299577979526487e-05, 'epoch': 0.37}\n",
      "{'loss': 1.5891, 'learning_rate': 1.6286112106089538e-05, 'epoch': 0.37}\n",
      "{'loss': 1.5911, 'learning_rate': 1.6272646232652588e-05, 'epoch': 0.37}\n",
      "{'loss': 1.6077, 'learning_rate': 1.625918035921564e-05, 'epoch': 0.37}\n",
      "{'loss': 1.598, 'learning_rate': 1.6245714485778692e-05, 'epoch': 0.38}\n",
      "{'loss': 1.6016, 'learning_rate': 1.6232248612341742e-05, 'epoch': 0.38}\n",
      "{'loss': 1.5925, 'learning_rate': 1.6218782738904796e-05, 'epoch': 0.38}\n",
      "{'loss': 1.5751, 'learning_rate': 1.6205316865467846e-05, 'epoch': 0.38}\n",
      "{'loss': 1.5775, 'learning_rate': 1.6191850992030896e-05, 'epoch': 0.38}\n",
      "{'loss': 1.5825, 'learning_rate': 1.617838511859395e-05, 'epoch': 0.38}\n",
      "{'loss': 1.5888, 'learning_rate': 1.6164919245157e-05, 'epoch': 0.38}\n",
      "{'loss': 1.6059, 'learning_rate': 1.615145337172005e-05, 'epoch': 0.39}\n",
      "{'loss': 1.5756, 'learning_rate': 1.6137987498283104e-05, 'epoch': 0.39}\n",
      "{'loss': 1.5735, 'learning_rate': 1.6124521624846155e-05, 'epoch': 0.39}\n",
      "{'loss': 1.568, 'learning_rate': 1.6111055751409205e-05, 'epoch': 0.39}\n",
      "{'loss': 1.6029, 'learning_rate': 1.609758987797226e-05, 'epoch': 0.39}\n",
      "{'loss': 1.5992, 'learning_rate': 1.6084124004535305e-05, 'epoch': 0.39}\n",
      "{'loss': 1.5725, 'learning_rate': 1.607065813109836e-05, 'epoch': 0.39}\n",
      "{'loss': 1.6027, 'learning_rate': 1.605719225766141e-05, 'epoch': 0.39}\n",
      "{'loss': 1.569, 'learning_rate': 1.604372638422446e-05, 'epoch': 0.4}\n",
      "{'loss': 1.5724, 'learning_rate': 1.6030260510787513e-05, 'epoch': 0.4}\n",
      "{'loss': 1.5981, 'learning_rate': 1.6016794637350564e-05, 'epoch': 0.4}\n",
      "{'loss': 1.5921, 'learning_rate': 1.6003328763913614e-05, 'epoch': 0.4}\n",
      "{'loss': 1.5617, 'learning_rate': 1.5989862890476668e-05, 'epoch': 0.4}\n",
      "{'loss': 1.5876, 'learning_rate': 1.5976397017039718e-05, 'epoch': 0.4}\n",
      "{'loss': 1.5753, 'learning_rate': 1.5962931143602768e-05, 'epoch': 0.4}\n",
      "{'loss': 1.5878, 'learning_rate': 1.5949465270165822e-05, 'epoch': 0.41}\n",
      "{'loss': 1.5878, 'learning_rate': 1.5935999396728872e-05, 'epoch': 0.41}\n",
      "{'loss': 1.5921, 'learning_rate': 1.5922533523291922e-05, 'epoch': 0.41}\n",
      "{'loss': 1.5865, 'learning_rate': 1.5909067649854976e-05, 'epoch': 0.41}\n",
      "{'loss': 1.5823, 'learning_rate': 1.5895601776418026e-05, 'epoch': 0.41}\n",
      "{'loss': 1.5801, 'learning_rate': 1.5882135902981077e-05, 'epoch': 0.41}\n",
      "{'loss': 1.5573, 'learning_rate': 1.586867002954413e-05, 'epoch': 0.41}\n",
      "{'loss': 1.5773, 'learning_rate': 1.5855204156107177e-05, 'epoch': 0.41}\n",
      "{'loss': 1.5802, 'learning_rate': 1.584173828267023e-05, 'epoch': 0.42}\n",
      "{'loss': 1.5849, 'learning_rate': 1.582827240923328e-05, 'epoch': 0.42}\n",
      "{'loss': 1.6005, 'learning_rate': 1.581480653579633e-05, 'epoch': 0.42}\n",
      "{'loss': 1.5836, 'learning_rate': 1.5801340662359382e-05, 'epoch': 0.42}\n",
      "{'loss': 1.5824, 'learning_rate': 1.5787874788922435e-05, 'epoch': 0.42}\n",
      "{'loss': 1.5811, 'learning_rate': 1.5774408915485486e-05, 'epoch': 0.42}\n",
      "{'loss': 1.575, 'learning_rate': 1.5760943042048536e-05, 'epoch': 0.42}\n",
      "{'loss': 1.5737, 'learning_rate': 1.574747716861159e-05, 'epoch': 0.43}\n",
      "{'loss': 1.5824, 'learning_rate': 1.573401129517464e-05, 'epoch': 0.43}\n",
      "{'loss': 1.5621, 'learning_rate': 1.572054542173769e-05, 'epoch': 0.43}\n",
      "{'loss': 1.5719, 'learning_rate': 1.5707079548300744e-05, 'epoch': 0.43}\n",
      "{'loss': 1.5723, 'learning_rate': 1.5693613674863794e-05, 'epoch': 0.43}\n",
      "{'loss': 1.5825, 'learning_rate': 1.5680147801426845e-05, 'epoch': 0.43}\n",
      "{'loss': 1.5744, 'learning_rate': 1.5666681927989898e-05, 'epoch': 0.43}\n",
      "{'loss': 1.5807, 'learning_rate': 1.565321605455295e-05, 'epoch': 0.43}\n",
      "{'loss': 1.5776, 'learning_rate': 1.5639750181116e-05, 'epoch': 0.44}\n",
      "{'loss': 1.559, 'learning_rate': 1.562628430767905e-05, 'epoch': 0.44}\n",
      "{'loss': 1.566, 'learning_rate': 1.56128184342421e-05, 'epoch': 0.44}\n",
      "{'loss': 1.5749, 'learning_rate': 1.5599352560805153e-05, 'epoch': 0.44}\n",
      "{'loss': 1.5743, 'learning_rate': 1.5585886687368203e-05, 'epoch': 0.44}\n",
      "{'loss': 1.583, 'learning_rate': 1.5572420813931254e-05, 'epoch': 0.44}\n",
      "{'loss': 1.5729, 'learning_rate': 1.5558954940494307e-05, 'epoch': 0.44}\n",
      "{'loss': 1.5756, 'learning_rate': 1.5545489067057358e-05, 'epoch': 0.45}\n",
      "{'loss': 1.5713, 'learning_rate': 1.5532023193620408e-05, 'epoch': 0.45}\n",
      "{'loss': 1.5723, 'learning_rate': 1.551855732018346e-05, 'epoch': 0.45}\n",
      "{'loss': 1.5932, 'learning_rate': 1.5505091446746512e-05, 'epoch': 0.45}\n",
      "{'loss': 1.5782, 'learning_rate': 1.5491625573309562e-05, 'epoch': 0.45}\n",
      "{'loss': 1.5669, 'learning_rate': 1.5478159699872616e-05, 'epoch': 0.45}\n",
      "{'loss': 1.5818, 'learning_rate': 1.5464693826435666e-05, 'epoch': 0.45}\n",
      "{'loss': 1.5721, 'learning_rate': 1.5451227952998716e-05, 'epoch': 0.46}\n",
      "{'loss': 1.5637, 'learning_rate': 1.543776207956177e-05, 'epoch': 0.46}\n",
      "{'loss': 1.5675, 'learning_rate': 1.5424296206124817e-05, 'epoch': 0.46}\n",
      "{'loss': 1.5621, 'learning_rate': 1.541083033268787e-05, 'epoch': 0.46}\n",
      "{'loss': 1.5865, 'learning_rate': 1.539736445925092e-05, 'epoch': 0.46}\n",
      "{'loss': 1.5765, 'learning_rate': 1.538389858581397e-05, 'epoch': 0.46}\n",
      "{'loss': 1.5535, 'learning_rate': 1.5370432712377025e-05, 'epoch': 0.46}\n",
      "{'loss': 1.5628, 'learning_rate': 1.5356966838940075e-05, 'epoch': 0.46}\n",
      "{'loss': 1.5428, 'learning_rate': 1.5343500965503125e-05, 'epoch': 0.47}\n",
      "{'loss': 1.5592, 'learning_rate': 1.533003509206618e-05, 'epoch': 0.47}\n",
      "{'loss': 1.5614, 'learning_rate': 1.531656921862923e-05, 'epoch': 0.47}\n",
      "{'loss': 1.5645, 'learning_rate': 1.530310334519228e-05, 'epoch': 0.47}\n",
      "{'loss': 1.5756, 'learning_rate': 1.5289637471755333e-05, 'epoch': 0.47}\n",
      "{'loss': 1.5452, 'learning_rate': 1.5276171598318384e-05, 'epoch': 0.47}\n",
      "{'loss': 1.5611, 'learning_rate': 1.5262705724881434e-05, 'epoch': 0.47}\n",
      "{'loss': 1.5837, 'learning_rate': 1.5249239851444486e-05, 'epoch': 0.48}\n",
      "{'loss': 1.5629, 'learning_rate': 1.5235773978007538e-05, 'epoch': 0.48}\n",
      "{'loss': 1.5585, 'learning_rate': 1.5222308104570588e-05, 'epoch': 0.48}\n",
      "{'loss': 1.5721, 'learning_rate': 1.520884223113364e-05, 'epoch': 0.48}\n",
      "{'loss': 1.5576, 'learning_rate': 1.5195376357696689e-05, 'epoch': 0.48}\n",
      "{'loss': 1.5745, 'learning_rate': 1.518191048425974e-05, 'epoch': 0.48}\n",
      "{'loss': 1.5591, 'learning_rate': 1.5168444610822793e-05, 'epoch': 0.48}\n",
      "{'loss': 1.5619, 'learning_rate': 1.5154978737385843e-05, 'epoch': 0.48}\n",
      "{'loss': 1.576, 'learning_rate': 1.5141512863948895e-05, 'epoch': 0.49}\n",
      "{'loss': 1.571, 'learning_rate': 1.5128046990511947e-05, 'epoch': 0.49}\n",
      "{'loss': 1.5591, 'learning_rate': 1.5114581117074997e-05, 'epoch': 0.49}\n",
      "{'loss': 1.5545, 'learning_rate': 1.510111524363805e-05, 'epoch': 0.49}\n",
      "{'loss': 1.5597, 'learning_rate': 1.5087649370201101e-05, 'epoch': 0.49}\n",
      "{'loss': 1.5795, 'learning_rate': 1.5074183496764151e-05, 'epoch': 0.49}\n",
      "{'loss': 1.5618, 'learning_rate': 1.5060717623327203e-05, 'epoch': 0.49}\n",
      "{'loss': 1.5502, 'learning_rate': 1.5047251749890255e-05, 'epoch': 0.5}\n",
      "{'loss': 1.5709, 'learning_rate': 1.5033785876453306e-05, 'epoch': 0.5}\n",
      "{'loss': 1.576, 'learning_rate': 1.5020320003016358e-05, 'epoch': 0.5}\n",
      "{'loss': 1.5562, 'learning_rate': 1.500685412957941e-05, 'epoch': 0.5}\n",
      "{'loss': 1.5574, 'learning_rate': 1.499338825614246e-05, 'epoch': 0.5}\n",
      "{'loss': 1.5598, 'learning_rate': 1.497992238270551e-05, 'epoch': 0.5}\n",
      "{'loss': 1.5522, 'learning_rate': 1.496645650926856e-05, 'epoch': 0.5}\n",
      "{'loss': 1.5565, 'learning_rate': 1.4952990635831613e-05, 'epoch': 0.5}\n",
      "{'loss': 1.5653, 'learning_rate': 1.4939524762394665e-05, 'epoch': 0.51}\n",
      "{'loss': 1.5524, 'learning_rate': 1.4926058888957715e-05, 'epoch': 0.51}\n",
      "{'loss': 1.5645, 'learning_rate': 1.4912593015520767e-05, 'epoch': 0.51}\n",
      "{'loss': 1.5448, 'learning_rate': 1.4899127142083819e-05, 'epoch': 0.51}\n",
      "{'loss': 1.5625, 'learning_rate': 1.4885661268646869e-05, 'epoch': 0.51}\n",
      "{'loss': 1.5562, 'learning_rate': 1.4872195395209921e-05, 'epoch': 0.51}\n",
      "{'loss': 1.5484, 'learning_rate': 1.4858729521772971e-05, 'epoch': 0.51}\n",
      "{'loss': 1.5444, 'learning_rate': 1.4845263648336023e-05, 'epoch': 0.52}\n",
      "{'loss': 1.5584, 'learning_rate': 1.4831797774899075e-05, 'epoch': 0.52}\n",
      "{'loss': 1.5519, 'learning_rate': 1.4818331901462126e-05, 'epoch': 0.52}\n",
      "{'loss': 1.5518, 'learning_rate': 1.4804866028025178e-05, 'epoch': 0.52}\n",
      "{'loss': 1.5456, 'learning_rate': 1.479140015458823e-05, 'epoch': 0.52}\n",
      "{'loss': 1.547, 'learning_rate': 1.477793428115128e-05, 'epoch': 0.52}\n",
      "{'loss': 1.5401, 'learning_rate': 1.4764468407714332e-05, 'epoch': 0.52}\n",
      "{'loss': 1.5552, 'learning_rate': 1.475100253427738e-05, 'epoch': 0.53}\n",
      "{'loss': 1.5467, 'learning_rate': 1.4737536660840432e-05, 'epoch': 0.53}\n",
      "{'loss': 1.551, 'learning_rate': 1.4724070787403484e-05, 'epoch': 0.53}\n",
      "{'loss': 1.5381, 'learning_rate': 1.4710604913966535e-05, 'epoch': 0.53}\n",
      "{'loss': 1.5405, 'learning_rate': 1.4697139040529587e-05, 'epoch': 0.53}\n",
      "{'loss': 1.5547, 'learning_rate': 1.4683673167092639e-05, 'epoch': 0.53}\n",
      "{'loss': 1.555, 'learning_rate': 1.4670207293655689e-05, 'epoch': 0.53}\n",
      "{'loss': 1.5645, 'learning_rate': 1.4656741420218741e-05, 'epoch': 0.53}\n",
      "{'loss': 1.5387, 'learning_rate': 1.4643275546781793e-05, 'epoch': 0.54}\n",
      "{'loss': 1.5522, 'learning_rate': 1.4629809673344843e-05, 'epoch': 0.54}\n",
      "{'loss': 1.5465, 'learning_rate': 1.4616343799907895e-05, 'epoch': 0.54}\n",
      "{'loss': 1.558, 'learning_rate': 1.4602877926470947e-05, 'epoch': 0.54}\n",
      "{'loss': 1.5605, 'learning_rate': 1.4589412053033997e-05, 'epoch': 0.54}\n",
      "{'loss': 1.5276, 'learning_rate': 1.457594617959705e-05, 'epoch': 0.54}\n",
      "{'loss': 1.5557, 'learning_rate': 1.4562480306160101e-05, 'epoch': 0.54}\n",
      "{'loss': 1.552, 'learning_rate': 1.4549014432723152e-05, 'epoch': 0.55}\n",
      "{'loss': 1.5548, 'learning_rate': 1.4535548559286202e-05, 'epoch': 0.55}\n",
      "{'loss': 1.5476, 'learning_rate': 1.4522082685849252e-05, 'epoch': 0.55}\n",
      "{'loss': 1.5449, 'learning_rate': 1.4508616812412304e-05, 'epoch': 0.55}\n",
      "{'loss': 1.5628, 'learning_rate': 1.4495150938975354e-05, 'epoch': 0.55}\n",
      "{'loss': 1.5603, 'learning_rate': 1.4481685065538406e-05, 'epoch': 0.55}\n",
      "{'loss': 1.541, 'learning_rate': 1.4468219192101458e-05, 'epoch': 0.55}\n",
      "{'loss': 1.5393, 'learning_rate': 1.4454753318664509e-05, 'epoch': 0.55}\n",
      "{'loss': 1.5519, 'learning_rate': 1.444128744522756e-05, 'epoch': 0.56}\n",
      "{'loss': 1.5331, 'learning_rate': 1.4427821571790613e-05, 'epoch': 0.56}\n",
      "{'loss': 1.5396, 'learning_rate': 1.4414355698353663e-05, 'epoch': 0.56}\n",
      "{'loss': 1.5413, 'learning_rate': 1.4400889824916715e-05, 'epoch': 0.56}\n",
      "{'loss': 1.5599, 'learning_rate': 1.4387423951479767e-05, 'epoch': 0.56}\n",
      "{'loss': 1.5428, 'learning_rate': 1.4373958078042817e-05, 'epoch': 0.56}\n",
      "{'loss': 1.5482, 'learning_rate': 1.436049220460587e-05, 'epoch': 0.56}\n",
      "{'loss': 1.5387, 'learning_rate': 1.4347026331168921e-05, 'epoch': 0.57}\n",
      "{'loss': 1.5451, 'learning_rate': 1.4333560457731971e-05, 'epoch': 0.57}\n",
      "{'loss': 1.5489, 'learning_rate': 1.4320094584295022e-05, 'epoch': 0.57}\n",
      "{'loss': 1.5513, 'learning_rate': 1.4306628710858072e-05, 'epoch': 0.57}\n",
      "{'loss': 1.5264, 'learning_rate': 1.4293162837421124e-05, 'epoch': 0.57}\n",
      "{'loss': 1.5419, 'learning_rate': 1.4279696963984176e-05, 'epoch': 0.57}\n",
      "{'loss': 1.5464, 'learning_rate': 1.4266231090547226e-05, 'epoch': 0.57}\n",
      "{'loss': 1.5526, 'learning_rate': 1.4252765217110278e-05, 'epoch': 0.57}\n",
      "{'loss': 1.5245, 'learning_rate': 1.423929934367333e-05, 'epoch': 0.58}\n",
      "{'loss': 1.5424, 'learning_rate': 1.422583347023638e-05, 'epoch': 0.58}\n",
      "{'loss': 1.5584, 'learning_rate': 1.4212367596799433e-05, 'epoch': 0.58}\n",
      "{'loss': 1.558, 'learning_rate': 1.4198901723362484e-05, 'epoch': 0.58}\n",
      "{'loss': 1.5466, 'learning_rate': 1.4185435849925535e-05, 'epoch': 0.58}\n",
      "{'loss': 1.549, 'learning_rate': 1.4171969976488587e-05, 'epoch': 0.58}\n",
      "{'loss': 1.529, 'learning_rate': 1.4158504103051639e-05, 'epoch': 0.58}\n",
      "{'loss': 1.5313, 'learning_rate': 1.4145038229614689e-05, 'epoch': 0.59}\n",
      "{'loss': 1.5163, 'learning_rate': 1.4131572356177741e-05, 'epoch': 0.59}\n",
      "{'loss': 1.5382, 'learning_rate': 1.4118106482740791e-05, 'epoch': 0.59}\n",
      "{'loss': 1.5465, 'learning_rate': 1.4104640609303843e-05, 'epoch': 0.59}\n",
      "{'loss': 1.5268, 'learning_rate': 1.4091174735866892e-05, 'epoch': 0.59}\n",
      "{'loss': 1.5486, 'learning_rate': 1.4077708862429944e-05, 'epoch': 0.59}\n",
      "{'loss': 1.55, 'learning_rate': 1.4064242988992996e-05, 'epoch': 0.59}\n",
      "{'loss': 1.5482, 'learning_rate': 1.4050777115556046e-05, 'epoch': 0.6}\n",
      "{'loss': 1.5433, 'learning_rate': 1.4037311242119098e-05, 'epoch': 0.6}\n",
      "{'loss': 1.5452, 'learning_rate': 1.402384536868215e-05, 'epoch': 0.6}\n",
      "{'loss': 1.5473, 'learning_rate': 1.40103794952452e-05, 'epoch': 0.6}\n",
      "{'loss': 1.5496, 'learning_rate': 1.3996913621808252e-05, 'epoch': 0.6}\n",
      "{'loss': 1.5408, 'learning_rate': 1.3983447748371304e-05, 'epoch': 0.6}\n",
      "{'loss': 1.5342, 'learning_rate': 1.3969981874934355e-05, 'epoch': 0.6}\n",
      "{'loss': 1.5324, 'learning_rate': 1.3956516001497407e-05, 'epoch': 0.6}\n",
      "{'loss': 1.5352, 'learning_rate': 1.3943050128060459e-05, 'epoch': 0.61}\n",
      "{'loss': 1.5313, 'learning_rate': 1.3929584254623509e-05, 'epoch': 0.61}\n",
      "{'loss': 1.5347, 'learning_rate': 1.391611838118656e-05, 'epoch': 0.61}\n",
      "{'loss': 1.531, 'learning_rate': 1.3902652507749613e-05, 'epoch': 0.61}\n",
      "{'loss': 1.5445, 'learning_rate': 1.3889186634312663e-05, 'epoch': 0.61}\n",
      "{'loss': 1.5351, 'learning_rate': 1.3875720760875713e-05, 'epoch': 0.61}\n",
      "{'loss': 1.5355, 'learning_rate': 1.3862254887438764e-05, 'epoch': 0.61}\n",
      "{'loss': 1.5358, 'learning_rate': 1.3848789014001816e-05, 'epoch': 0.62}\n",
      "{'loss': 1.5593, 'learning_rate': 1.3835323140564868e-05, 'epoch': 0.62}\n",
      "{'loss': 1.5355, 'learning_rate': 1.3821857267127918e-05, 'epoch': 0.62}\n",
      "{'loss': 1.5337, 'learning_rate': 1.380839139369097e-05, 'epoch': 0.62}\n",
      "{'loss': 1.5303, 'learning_rate': 1.3794925520254022e-05, 'epoch': 0.62}\n",
      "{'loss': 1.5391, 'learning_rate': 1.3781459646817072e-05, 'epoch': 0.62}\n",
      "{'loss': 1.5202, 'learning_rate': 1.3767993773380124e-05, 'epoch': 0.62}\n",
      "{'loss': 1.5381, 'learning_rate': 1.3754527899943174e-05, 'epoch': 0.62}\n",
      "{'loss': 1.5238, 'learning_rate': 1.3741062026506226e-05, 'epoch': 0.63}\n",
      "{'loss': 1.5317, 'learning_rate': 1.3727596153069278e-05, 'epoch': 0.63}\n",
      "{'loss': 1.533, 'learning_rate': 1.3714130279632329e-05, 'epoch': 0.63}\n",
      "{'loss': 1.5343, 'learning_rate': 1.370066440619538e-05, 'epoch': 0.63}\n",
      "{'loss': 1.5282, 'learning_rate': 1.3687198532758433e-05, 'epoch': 0.63}\n",
      "{'loss': 1.5267, 'learning_rate': 1.3673732659321483e-05, 'epoch': 0.63}\n",
      "{'loss': 1.5155, 'learning_rate': 1.3660266785884535e-05, 'epoch': 0.63}\n",
      "{'loss': 1.5265, 'learning_rate': 1.3646800912447584e-05, 'epoch': 0.64}\n",
      "{'loss': 1.5381, 'learning_rate': 1.3633335039010635e-05, 'epoch': 0.64}\n",
      "{'loss': 1.5151, 'learning_rate': 1.3619869165573687e-05, 'epoch': 0.64}\n",
      "{'loss': 1.5405, 'learning_rate': 1.3606403292136738e-05, 'epoch': 0.64}\n",
      "{'loss': 1.5121, 'learning_rate': 1.359293741869979e-05, 'epoch': 0.64}\n",
      "{'loss': 1.5194, 'learning_rate': 1.3579471545262842e-05, 'epoch': 0.64}\n",
      "{'loss': 1.5255, 'learning_rate': 1.3566005671825892e-05, 'epoch': 0.64}\n",
      "{'loss': 1.5194, 'learning_rate': 1.3552539798388944e-05, 'epoch': 0.64}\n",
      "{'loss': 1.5282, 'learning_rate': 1.3539073924951996e-05, 'epoch': 0.65}\n",
      "{'loss': 1.5416, 'learning_rate': 1.3525608051515046e-05, 'epoch': 0.65}\n",
      "{'loss': 1.5346, 'learning_rate': 1.3512142178078098e-05, 'epoch': 0.65}\n",
      "{'loss': 1.5238, 'learning_rate': 1.349867630464115e-05, 'epoch': 0.65}\n",
      "{'loss': 1.5348, 'learning_rate': 1.34852104312042e-05, 'epoch': 0.65}\n",
      "{'loss': 1.5399, 'learning_rate': 1.3471744557767252e-05, 'epoch': 0.65}\n",
      "{'loss': 1.53, 'learning_rate': 1.3458278684330304e-05, 'epoch': 0.65}\n",
      "{'loss': 1.5187, 'learning_rate': 1.3444812810893355e-05, 'epoch': 0.66}\n",
      "{'loss': 1.5225, 'learning_rate': 1.3431346937456405e-05, 'epoch': 0.66}\n",
      "{'loss': 1.5418, 'learning_rate': 1.3417881064019455e-05, 'epoch': 0.66}\n",
      "{'loss': 1.5287, 'learning_rate': 1.3404415190582507e-05, 'epoch': 0.66}\n",
      "{'loss': 1.5216, 'learning_rate': 1.339094931714556e-05, 'epoch': 0.66}\n",
      "{'loss': 1.5258, 'learning_rate': 1.337748344370861e-05, 'epoch': 0.66}\n",
      "{'loss': 1.5332, 'learning_rate': 1.3364017570271662e-05, 'epoch': 0.66}\n",
      "{'loss': 1.531, 'learning_rate': 1.3350551696834712e-05, 'epoch': 0.67}\n",
      "{'loss': 1.5329, 'learning_rate': 1.3337085823397764e-05, 'epoch': 0.67}\n",
      "{'loss': 1.5225, 'learning_rate': 1.3323619949960816e-05, 'epoch': 0.67}\n",
      "{'loss': 1.5331, 'learning_rate': 1.3310154076523866e-05, 'epoch': 0.67}\n",
      "{'loss': 1.5347, 'learning_rate': 1.3296688203086918e-05, 'epoch': 0.67}\n",
      "{'loss': 1.523, 'learning_rate': 1.328322232964997e-05, 'epoch': 0.67}\n",
      "{'loss': 1.5333, 'learning_rate': 1.326975645621302e-05, 'epoch': 0.67}\n",
      "{'loss': 1.5344, 'learning_rate': 1.3256290582776072e-05, 'epoch': 0.67}\n",
      "{'loss': 1.5331, 'learning_rate': 1.3242824709339124e-05, 'epoch': 0.68}\n",
      "{'loss': 1.5167, 'learning_rate': 1.3229358835902175e-05, 'epoch': 0.68}\n",
      "{'loss': 1.5201, 'learning_rate': 1.3215892962465227e-05, 'epoch': 0.68}\n",
      "{'loss': 1.5335, 'learning_rate': 1.3202427089028275e-05, 'epoch': 0.68}\n",
      "{'loss': 1.5188, 'learning_rate': 1.3188961215591327e-05, 'epoch': 0.68}\n",
      "{'loss': 1.5234, 'learning_rate': 1.3175495342154379e-05, 'epoch': 0.68}\n",
      "{'loss': 1.5247, 'learning_rate': 1.316202946871743e-05, 'epoch': 0.68}\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=valid_dataset,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "trainer.save_model(\"models/restaurants_domain_adapted\") #save your custom model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normlize_bert_data_size(input_texts, max_size = 512):\n",
    "    '''\n",
    "    input_texts: a list of input texts.\n",
    "    max_size: the max size to truncate data to.\n",
    "    '''\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    new_input_texts = []\n",
    "    orginal_index = []\n",
    "    \n",
    "    for i, doc in enumerate(nlp.pipe(input_texts, disable=[\"tagger\", \"attribute_ruler\", \"lemmatizer\"])):\n",
    "        sentences = [sent.text for sent in doc.sents]\n",
    "        if any(len(x) > 512 for x in sentences):\n",
    "            new_sentences = []\n",
    "            for sent in sentences:\n",
    "                pass\n",
    "        else:\n",
    "            new_sentences = sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = input_texts[i].split()\n",
    "# any(len(x) > 512 for x in text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f1d4d6eb2abe3fb4049954bd206a32ef86aac931501ef1b113439c6e56c2b586"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
